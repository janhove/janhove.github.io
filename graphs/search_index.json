[["index.html", "Quantitative Methodology: Drawing plots Tips", " Quantitative Methodology: Drawing plots Jan Vanhove (jan.vanhove@unifr.ch, https://janhove.github.io) Autumn 2023 Tips You’ll learn more if you type all the commands rather than just copy-paste them from this site. After the first few weeks, the tutorials will contain some typos so that the commands won’t work if you just copy-paste them. If the software throws a bunch of errors at you, fix the first error first. Usually, the errors following it are just the result of this first error. If your code produces an error, first check out the appendix. If that doesn’t work, go through your code line by line and explain to yourself out loud what your code is supposed to achieve and what each line actually does. This process is known as rubber duck debugging and it’s highly effective. If you still run into difficulties, reduce your code to the minimum amount of code that still produces the error. This helps you identify exactly where the error occurs, making it easier for others to help you rectify the error. When asking for help, share this minimal example and its output. Above all, don’t despair and be patient with yourself. My code rarely runs from the first go, it’s just that after doing this for years, I can iron out the most common glitches pretty quickly. And should you ever be stuck on a problem for a couple of hours, go for a walk, run, ride, beer, or whatever else floats your boat and return to the problem with a clear head another time. "],["week-1-installing-and-configuring-r-and-rstudio.html", "1 Week 1: Installing and configuring R and RStudio 1.1 Goals 1.2 Software 1.3 Drawing a first scatterplot 1.4 Exercise", " 1 Week 1: Installing and configuring R and RStudio 1.1 Goals You’ll install the software you’ll need for this part of the class: R, RStudio, and tidyverse/ggplot2. You’ll tinker with the R and RStudio settings. You’ll draw and save your first graph, a scatterplot, to see if everything is working as it should be. 1.2 Software Download the free program R from https://r-project.org (Download, CRAN) and install it. In case you already had R installed before taking this course, please check that you have at least version 4.3.1. Download and install the free program RStudio: https://posit.co/products/open-source/rstudio/. Pick the free desktop version. RStudio offers a tidier user interface for R. Open RStudio. You should see four frames as in Figure 1.1 below. If you see only one frame on the left-hand side, click File, New File, R Script. Figure 1.1: RStudio. Top left: Script editor. This is where you can enter and edit commands and comments. Bottom left: R console. Commands that you copy from the script editor to this console will be evaluated by R. Top right: Here you’ll find a list of the objects currently available in R’s working memory (none at the moment). Bottom right: Plots (none at the moment), help pages etc. Go to Tools &gt; Global Options... &gt; General. Untick Restore .RData into workspace at startup and set Save workspace to .RData on exit to Never. This way, you’ll start with a clean slate each time you restart R, i.e., there won’t be any objects in the workspace from a previous session that could affect your computations in the current session. This, in turn, will help ensure that when other people run the same code as you, the results will be the same, too. Go to Tools &gt; Global Options...&gt; Code &gt; Saving. Set Default text encoding to UTF-8. Go to Tools &gt; Global Options...&gt; Code &gt; Editing. Tick Use native pipe operator. |&gt;. Enter the following line into the script editor (top left). Brackets, quotation marks, capitalisation, and the like all matter to computers, so pay attention to them. install.packages(&quot;tidyverse&quot;) Now put the cursor on this line in the script editor. Then click Code, Run Line(s). (Shortcut for Windows/Linux: ctrl + enter; Mac: command + enter.) This relays the command install.packages(\"tidyverse\") to R. This command adds the tidyverse suite to your installation of R. The tidyverse is a collection of useful add-ons that enable you to work more flexibly and more efficiently with datasets. One of these add-ons is the ggplot2 package, which features state-of-the-art functions for drawing graphics. You may need to select a server from a pop-up window. Any server should work. Wait as the add-on package is being installed. Install the here package using the same set of commands, i.e., run the line below. The here package facilitates working in a directory structure. install.packages(&quot;here&quot;) Do the same with the devtools package. Click on File &gt; New Project... &gt; New Directory. Navigate to somewhere on your computer where you want to create a new directory and give this directory a name (for instance, quantmeth_plots). You will use this directory to store the data and scripts that you’ll need for drawing the graphs in as well for saving the graphs themselves to. You don’t have to tick the other options. When you’re done, close RStudio. Navigate to the directory you’ve just created. You should find an .Rproj file there. Double-click it. If all is well, RStudio should fire up. Create the following subdirectories in the directory you’re currently in: data, scripts and figures. Now we’re good to go! 1.3 Drawing a first scatterplot I’ll assume that you’ve opened your newly created R project. If you haven’t, navigate to the directory you’ve just created and double-click the .Rproj file. Enter the commands below into the script editor (top left); do not enter them directly into the console (bottom left). While nothing terrible will happen if you do enter commands directly into the console, entering them into the script editor first is a good habit to get into: it’s much easier to spot errors, document your analysis, make tweaks to your code, and reuse old code in the editor than in the console. As for documenting your analysis, be sure to comment your R scripts. When you’re still starting out learning R, I suggest you use comments to keep track of pretty much every command. Once you’ve gained some more familiarity with R, you’ll be better able to make sense of what a line of R code accomplishes and your comments may become sparser. You can enter comments by prefixing a line with #. Everything on the same line after # will be ignored by R but will be visible to you and other people you’d like to share your scripts with (e.g., when asking for help). After you’ve installed the tidyverse suite and the here and devtools packages, you still need to load them in order to make their functions available. While you only need to install a package or suite once, you need to load its functions every time you start a new session. When you run this command, a number of messages will appear about packages that were attached and ‘conflicts’. You can safely ignore these. Loading the here package should make the current path appear at the prompt. # Load tidyverse package # (Lines prefaced with hashes serve as comments -- use them liberally at first) library(tidyverse) ## ── Attaching core tidyverse packages ────────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.2 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ ggplot2 3.4.2 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.2 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.1 ## ── Conflicts ──────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors # Load here package library(here) ## here() starts at /home/jan/ownCloud/QuantMeth_Graphs R comes with a number of pre-installed datasets, among which the iris dataset. This dataset contains measurements of 150 flowers. (Later we’ll work with linguistic datasets of our own.) Load this pre-installed dataset using data(): # Load iris dataset data(iris) Show this dataset by entering its name. Take note of how this dataset is laid out: it contains measurements of 150 flowers, with each flower being represented by one row. For each flower, 5 pieces of information (‘variables’) are available, among which 4 numeric ones (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) and one non-numeric (Species). Datasets constructed in this way (1 row per observation, different columns per variable) tend to be easier to analyse than datasets with other lay-outs (e.g., one row per variable, different columns for separate observations). # Show dataset iris ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## 11 5.4 3.7 1.5 0.2 setosa ## 12 4.8 3.4 1.6 0.2 setosa ## 13 4.8 3.0 1.4 0.1 setosa ## 14 4.3 3.0 1.1 0.1 setosa ## 15 5.8 4.0 1.2 0.2 setosa ## 16 5.7 4.4 1.5 0.4 setosa ## 17 5.4 3.9 1.3 0.4 setosa ## 18 5.1 3.5 1.4 0.3 setosa ## 19 5.7 3.8 1.7 0.3 setosa ## 20 5.1 3.8 1.5 0.3 setosa ## 21 5.4 3.4 1.7 0.2 setosa ## 22 5.1 3.7 1.5 0.4 setosa ## 23 4.6 3.6 1.0 0.2 setosa ## 24 5.1 3.3 1.7 0.5 setosa ## 25 4.8 3.4 1.9 0.2 setosa ## 26 5.0 3.0 1.6 0.2 setosa ## 27 5.0 3.4 1.6 0.4 setosa ## 28 5.2 3.5 1.5 0.2 setosa ## 29 5.2 3.4 1.4 0.2 setosa ## 30 4.7 3.2 1.6 0.2 setosa ## 31 4.8 3.1 1.6 0.2 setosa ## 32 5.4 3.4 1.5 0.4 setosa ## 33 5.2 4.1 1.5 0.1 setosa ## 34 5.5 4.2 1.4 0.2 setosa ## 35 4.9 3.1 1.5 0.2 setosa ## 36 5.0 3.2 1.2 0.2 setosa ## 37 5.5 3.5 1.3 0.2 setosa ## 38 4.9 3.6 1.4 0.1 setosa ## 39 4.4 3.0 1.3 0.2 setosa ## 40 5.1 3.4 1.5 0.2 setosa ## 41 5.0 3.5 1.3 0.3 setosa ## 42 4.5 2.3 1.3 0.3 setosa ## 43 4.4 3.2 1.3 0.2 setosa ## 44 5.0 3.5 1.6 0.6 setosa ## 45 5.1 3.8 1.9 0.4 setosa ## 46 4.8 3.0 1.4 0.3 setosa ## 47 5.1 3.8 1.6 0.2 setosa ## 48 4.6 3.2 1.4 0.2 setosa ## 49 5.3 3.7 1.5 0.2 setosa ## 50 5.0 3.3 1.4 0.2 setosa ## 51 7.0 3.2 4.7 1.4 versicolor ## 52 6.4 3.2 4.5 1.5 versicolor ## 53 6.9 3.1 4.9 1.5 versicolor ## 54 5.5 2.3 4.0 1.3 versicolor ## 55 6.5 2.8 4.6 1.5 versicolor ## 56 5.7 2.8 4.5 1.3 versicolor ## 57 6.3 3.3 4.7 1.6 versicolor ## 58 4.9 2.4 3.3 1.0 versicolor ## 59 6.6 2.9 4.6 1.3 versicolor ## 60 5.2 2.7 3.9 1.4 versicolor ## 61 5.0 2.0 3.5 1.0 versicolor ## 62 5.9 3.0 4.2 1.5 versicolor ## 63 6.0 2.2 4.0 1.0 versicolor ## 64 6.1 2.9 4.7 1.4 versicolor ## 65 5.6 2.9 3.6 1.3 versicolor ## 66 6.7 3.1 4.4 1.4 versicolor ## 67 5.6 3.0 4.5 1.5 versicolor ## 68 5.8 2.7 4.1 1.0 versicolor ## 69 6.2 2.2 4.5 1.5 versicolor ## 70 5.6 2.5 3.9 1.1 versicolor ## 71 5.9 3.2 4.8 1.8 versicolor ## 72 6.1 2.8 4.0 1.3 versicolor ## 73 6.3 2.5 4.9 1.5 versicolor ## 74 6.1 2.8 4.7 1.2 versicolor ## 75 6.4 2.9 4.3 1.3 versicolor ## 76 6.6 3.0 4.4 1.4 versicolor ## 77 6.8 2.8 4.8 1.4 versicolor ## 78 6.7 3.0 5.0 1.7 versicolor ## 79 6.0 2.9 4.5 1.5 versicolor ## 80 5.7 2.6 3.5 1.0 versicolor ## 81 5.5 2.4 3.8 1.1 versicolor ## 82 5.5 2.4 3.7 1.0 versicolor ## 83 5.8 2.7 3.9 1.2 versicolor ## 84 6.0 2.7 5.1 1.6 versicolor ## 85 5.4 3.0 4.5 1.5 versicolor ## 86 6.0 3.4 4.5 1.6 versicolor ## 87 6.7 3.1 4.7 1.5 versicolor ## 88 6.3 2.3 4.4 1.3 versicolor ## 89 5.6 3.0 4.1 1.3 versicolor ## 90 5.5 2.5 4.0 1.3 versicolor ## 91 5.5 2.6 4.4 1.2 versicolor ## 92 6.1 3.0 4.6 1.4 versicolor ## 93 5.8 2.6 4.0 1.2 versicolor ## 94 5.0 2.3 3.3 1.0 versicolor ## 95 5.6 2.7 4.2 1.3 versicolor ## 96 5.7 3.0 4.2 1.2 versicolor ## 97 5.7 2.9 4.2 1.3 versicolor ## 98 6.2 2.9 4.3 1.3 versicolor ## 99 5.1 2.5 3.0 1.1 versicolor ## 100 5.7 2.8 4.1 1.3 versicolor ## 101 6.3 3.3 6.0 2.5 virginica ## 102 5.8 2.7 5.1 1.9 virginica ## 103 7.1 3.0 5.9 2.1 virginica ## 104 6.3 2.9 5.6 1.8 virginica ## 105 6.5 3.0 5.8 2.2 virginica ## 106 7.6 3.0 6.6 2.1 virginica ## 107 4.9 2.5 4.5 1.7 virginica ## 108 7.3 2.9 6.3 1.8 virginica ## 109 6.7 2.5 5.8 1.8 virginica ## 110 7.2 3.6 6.1 2.5 virginica ## 111 6.5 3.2 5.1 2.0 virginica ## 112 6.4 2.7 5.3 1.9 virginica ## 113 6.8 3.0 5.5 2.1 virginica ## 114 5.7 2.5 5.0 2.0 virginica ## 115 5.8 2.8 5.1 2.4 virginica ## 116 6.4 3.2 5.3 2.3 virginica ## 117 6.5 3.0 5.5 1.8 virginica ## 118 7.7 3.8 6.7 2.2 virginica ## 119 7.7 2.6 6.9 2.3 virginica ## 120 6.0 2.2 5.0 1.5 virginica ## 121 6.9 3.2 5.7 2.3 virginica ## 122 5.6 2.8 4.9 2.0 virginica ## 123 7.7 2.8 6.7 2.0 virginica ## 124 6.3 2.7 4.9 1.8 virginica ## 125 6.7 3.3 5.7 2.1 virginica ## 126 7.2 3.2 6.0 1.8 virginica ## 127 6.2 2.8 4.8 1.8 virginica ## 128 6.1 3.0 4.9 1.8 virginica ## 129 6.4 2.8 5.6 2.1 virginica ## 130 7.2 3.0 5.8 1.6 virginica ## 131 7.4 2.8 6.1 1.9 virginica ## 132 7.9 3.8 6.4 2.0 virginica ## 133 6.4 2.8 5.6 2.2 virginica ## 134 6.3 2.8 5.1 1.5 virginica ## 135 6.1 2.6 5.6 1.4 virginica ## 136 7.7 3.0 6.1 2.3 virginica ## 137 6.3 3.4 5.6 2.4 virginica ## 138 6.4 3.1 5.5 1.8 virginica ## 139 6.0 3.0 4.8 1.8 virginica ## 140 6.9 3.1 5.4 2.1 virginica ## 141 6.7 3.1 5.6 2.4 virginica ## 142 6.9 3.1 5.1 2.3 virginica ## 143 5.8 2.7 5.1 1.9 virginica ## 144 6.8 3.2 5.9 2.3 virginica ## 145 6.7 3.3 5.7 2.5 virginica ## 146 6.7 3.0 5.2 2.3 virginica ## 147 6.3 2.5 5.0 1.9 virginica ## 148 6.5 3.0 5.2 2.0 virginica ## 149 6.2 3.4 5.4 2.3 virginica ## 150 5.9 3.0 5.1 1.8 virginica Draw a scatterplot using the following command, which plots the flowers’ Sepal.Length along the x axis and their Petal.Length along the y axis. Pay particular attention to the brackets, commas, pluses, capitalisation, etc.: The command won’t work if you type petal.length instead of Petal.Length or if you forget a bracket or the plus sign. The indentations aren’t important, but they’re useful to show the command’s structure. Emulate the coding style of this tutorial as best you can. Explanation: Line 1 specifies the name of the dataset as it’s known in R (data =). Lines 2–3 specify the variables to be plotted (the plot’s aesthetics, aes) and how they should be plotted (along the x and y axes). Line 4 specifies that the data should be plotted as points. ggplot(data = iris, # Specify the name of the dataset aes(x = Sepal.Length, # Variable for x axis (aes = &#39;aesthetics&#39;) y = Petal.Length)) + # Variable for y axis (don&#39;t forget the &#39;+&#39;) geom_point() # Plot the data as points If you’ve successfully run the commands above, you should see a graph displayed in the bottom right pane. Now save this figure to your computer using the following command. The figure will be saved in the subdirectory figures, and it will be a .png file. # This saves the plot to the figures subdirectory. ggsave(here(&quot;figures&quot;, &quot;01_first_scatterplot.png&quot;)) For those already familiar with R: ggsave() only works for saving the last figure drawn using ggplot(); it won’t work for figures drawn in base R. Add the following lines. They output the R, RStudio and package versions used as well as some additional information that can be useful when figuring out why something isn’t working as it should. # Software versions used devtools::session_info() Click File &gt; Compile Report.... Select HTML and store the script in the scripts directory as 01_first_scatterplot.R. If you’ve followed this tutorial to the letter, you will now find both an .R file and a corresponding .html file in your script directory. The .R file contains the command that you used to draw the plot, and the .html report nicely keeps track of both the commands and their output. If the report compiles without hiccoughs, anyone with the same data and the same software versions will be able to reproduce your analysis. 1.4 Exercise Create a new script with which you draw a scatterplot in which the Petal.Width variable from the irisdataset is plotting along the x-axis and the Sepal.Width variable is plotted along the y-axis. You don’t have to reinstall all the packages again, but you will need to load them. Give the script and the figure sensible names (something starting with 01_ would be good; use 02_, 03_ etc. in the following weeks), and save them to the appropriate subdirectories. Compile a HTML report. Hand in both the HTML report and the figure via Moodle. "],["week-2-reading-in-data-and-drawing-a-histogram.html", "2 Week 2: Reading in data and drawing a histogram 2.1 Goals 2.2 Importing CSV files into R 2.3 Drawing a histogram 2.4 Labelling axes 2.5 Adjusting the colour scheme 2.6 Exercise", " 2 Week 2: Reading in data and drawing a histogram 2.1 Goals You’ll learn what CSV files are and how you can import them into R. You’ll learn how to draw a histogram, a useful kind of graph for gauging how a variable is distributed. You’ll learn how to label your graphs’ axes. 2.2 Importing CSV files into R On Moodle you’ll find a file named Vanhove2015_Vpn.csv. This file contains a couple of pieces of information about the participants in an experiment that I conducted a couple of years ago: ID, scores on German, English and French vocabulary tests (Wortschatz, Englisch and Französisch, respectively), sex (Geschlecht), and age (Alter). Save the CSV file directly to the data subdirectory in the R project directory that you created last week. Do not open the file in Excel first to use its ‘save as’ function: On German- and French-language systems (among others), this tends to mess up the file’s internal structure. Open the CSV file using a text editor (e.g., Windows’ Wordpad or Gnu’s gedit) and note how the file is structured: There are separate columns for each variable, and each line contains data for one participant only. Different values are separated by commas (hence CSV: comma-separated values). You can also open the CSV file in Excel, LibreOffice Calc or other spreadsheet software, but be careful not to use the ‘save as’ function unless you know what you’re doing. If you use the ‘save as’ function in Excel on a non-English system, the commas will be replaced by semi-colons and chaos will ensue. (I prefer LibreOffice Calc, which is free software and which allows you to save CSV files as, well, CSV files.) Open the R project that you created last week, e.g., by double-clicking the .Rproj file. Create a new script (File &gt; New File &gt; R Script). Type the commands for loading the tidyverse and here packages in this script and run them. (See last week.) Note that you do not have to reinstall these packages; you just need to load them. Add and run the following command. It reads in the CSV file Vanhove2015_Vpn.csv stored in the data subdirectory and assigns its contents to a new object that can be referred to in R as d_hist. You can pick another name, but then you’ll have to make the necessary changes in the code that follows, too; I use d_hist because we’re working with a dataset and we’re going to draw a histogram. The ‘assignment operator’ is an arrow made up from a less than sign (&lt;) and a dash (-). (You can use the shortcurt alt + - on Windows/Linux or Option + - on Mac.) The output at the console is merely a message that tells you how the data were parsed: there is one column containing text (characters, chr) and four columns containing numeric information (in a double-precision floating-point format, hence dbl but that’s not relevant now). d_hist &lt;- read_csv(here(&quot;data&quot;, &quot;Vanhove2015_Vpn.csv&quot;)) ## Rows: 80 Columns: 6 ## ── Column specification ────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Geschlecht ## dbl (5): VPN, Wortschatz, Englisch, Französisch, Alter ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. If you type in the name of the newly created object (viz., d_hist) to the R prompt, you’ll see part of the dataset displayed. If you want to inspect the whole dataset, use the following command: view(d_hist) If that worked, congratulations: You’ve successfully imported the data set. If not: Double-check your steps (including downloading the dataset). If it still doesn’t work, upload the dataset as you’ve downloaded it as well as the R commands that you used to Moodle along with any error messages or warnings. 2.3 Drawing a histogram A histogram shows how a variable is distributed (see Johnson 2013). Histograms are particularly useful to check if there are any ‘univariate’ outliers (i.e., values that lie far from the bulk of the data if you consider only this one variable) and to see if the variale seems to be distributed approximately uniformly, normally, bimodally or more wonkily. Since you’ve already loaded the tidyverse and since you’ve already read in the data, we can start to draw some histograms. Like for last week’s scatterplot, we need to define the object and the variables we want to plot (lines 1–2). Instead of drawing points, we draw a histogram: ggplot(data = d_hist, # specify data set aes(x = Englisch)) + # variable to be drawn geom_histogram() # draw as histogram ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. The histogram shows, among other things, that there are 8 individuals with an English vocabulary score just below 0.7 and 4 with a score just below 0.6. By default, 30 such bins are drawn, but as the warning indicates (‘Pick better value’), there’s nothing special about this number. You can adjust the desired bin width: ggplot(data = d_hist, aes(x = Englisch)) + geom_histogram(binwidth = 0.2) # binwidth of 0.2 points ggplot(data = d_hist, aes(x = Englisch)) + geom_histogram(binwidth = 0.1) # binwidth of 0.1 points ggplot(data = d_hist, aes(x = Englisch)) + geom_histogram(binwidth = 0.05) # binwidth of 0.05 points ggplot(data = d_hist, aes(x = Englisch)) + geom_histogram(binwidth = 1/30) # binwidth of 1/30 points There aren’t any hard and fast rules for determining the optimal bin width. The default settings (1st plot) produce a histogram that seems to be a bit too fine-grained, whereas a bin width of 0.2 (2nd plot) results in too coarse a histogram. The other three histograms seem fine by me; I’d probably pick the 4th or 5th for a presentation or when writing a paper. 2.4 Labelling axes Use xlab() and ylab() to label axes. Don’t forget the quotation marks. ggplot(data = d_hist, aes(x = Englisch)) + geom_histogram(binwidth = 0.05) + xlab(&quot;English vocabulary score&quot;) + ylab(&quot;Number of participants&quot;) Important: Figure 2.1: Source: https://xkcd.com/833/. 2.5 Adjusting the colour scheme I’ve added two parameters to the geom_histogram() call. You can change these settings yourself. ggplot(data = d_hist, aes(x = Englisch)) + geom_histogram(binwidth = 0.05, colour = &quot;black&quot;, fill = &quot;darkgrey&quot;) + xlab(&quot;English vocabulary score&quot;) + ylab(&quot;Number of participants&quot;) 2.6 Exercise Create one new script with which you draw a suitable histogram for the Französisch variable as well as for the Wortschatz variable. This will require you to tinker with the binwidth setting. Don’t forget to adjust the axis labels. Use ggsave() (see last week) to save your preferred histogram for each of the two variables. Compile a HTML report. Hand in both the HTML report and the two figures via Moodle. References "],["week-3-drawing-a-boxplot.html", "3 Week 3: Drawing a boxplot 3.1 Reading in data 3.2 What are boxplots? 3.3 Drawing boxplots 3.4 Adjusting the appearance of plots 3.5 Computing summaries 3.6 Exercise", " 3 Week 3: Drawing a boxplot You’ll learn how to draw basic boxplots, which are useful for comparing groups on a numeric variable. You’ll tinker with the appearence of your graphs. You’ll learn how to compute basic summaries such as group means. 3.1 Reading in data Download the file VowelChoices_ij.csv from Moodle to the data subdirectory of your R project directory. This file contains a part of the results of a learning experiment (Vanhove 2016) in which 80 participants were assigned to one of two learning conditions (LearningCondition). The column PropCorrect contains the proportion of correct answers for each participant, and the question we want to answer concerns the difference in the performance between learners in the different conditions. Open your R project. Create a new script and copy the commands with which you loaded the packages and imported the dataset from last week’s script to this new script. Adapt the command for importing the data so that it’ll read in the file VowelChoices_ij.csv and that the dataset will be known in R as d_box. Execute these commands. From now on, I’ll assume that you won’t enter commands directly to the R console but that you’ll first enter them into a script which you’ll then execute (= much more efficient and manageable). Tip: Comment your code (with #). This way you’ll be able to understand what your code accomplishes in a few months’ time, which will make it easier to recycle your scripts. You don’t have to copy my comments verbatim. “Your closest collaborator is you six months ago but you don’t reply to email.” Inspect the dataset in R to check that it contains 80 rows and 3 labelled columns (Subject, LearningCondition, PropCorrect). 3.2 What are boxplots? Below you see a basic boxplot of the vocabulary test scores of the eighty participants in (Vanhove 2016). The median score is highlighted by a thick line. The 25th and 75th percentiles are highlighted by thinner lines and together form a box. The difference between the 75th and 25th percentile is called the inter-quartile range (IQR). The data points that don’t fall in the box, that is, the data points that don’t make up the middle 50% of the data, are represented by a line protruding from the upper part of the box and by a line protruding from the lower part of the box. However, data points whose distance to the box exceeds 1.5 times the inter-quartile range are plotted separately. If such data points exist, the lines protruding from the box only extend up to the lowest / highest data point whose distance to the box is lower than 1.5 times the IQR. From the boxplot below, we can glean that the IQR is \\(34 - 31 = 3\\). The highest data point has a value of 38. Since \\(38 &lt; 34 + 1.5 \\times 3 = 38.5\\), this data point is captured by the line protruding from the upper part of the box. The lowest data point has a value of 25. Since \\(25 &lt; 31 - 1.5 \\times 3 = 26.5\\), it lies too far from the box to be captured by the line protruding from the lower part of the box, so it gets drawn separately. 3.3 Drawing boxplots We can draw boxplots in order to compare the distribution of a variable in two groups. But you can also use boxplots to compare more than two groups. Next week we’ll add the individual data points to these boxplots which can make them more informative still. From now on, I’ll always assume that you’ve loaded the tidyverse and here packages. The following command plots the accuracy data (PropCorrect) using a separate boxplot for each condition (LearningCondition). You already know how the first three lines work; the fourth specifies that the data should be plotted using boxplots. # Boxplot PropCorrect vs. LearningCondition ggplot(data = d_box, aes(x = LearningCondition, y = PropCorrect)) + geom_boxplot() # summarise data with boxplots Label the x-axis as “Learning condition” and the y-axis as “Proportion correct answers”. I don’t provide the commands for doing so; you already know them from last week. 3.4 Adjusting the appearance of plots By default, ggplot2 (the part of the tidyverse that takes care of plotting) produces plots with a grey background (which doesn’t seem to please anyone save for its developer). This can be changed by appending the command theme_bw() (black and white) to the ggplot call: ggplot(data = d_box, aes(x = LearningCondition, y = PropCorrect)) + geom_boxplot() + xlab(&quot;Learning condition&quot;) + ylab(&quot;Proportion correct answers&quot;) + theme_bw() For other options, see https://ggplot2.tidyverse.org/reference/ggtheme.html. To change the font size, insert a number between the brackets of the theme_bw() command. Finding a suitable font size is a matter of trial and error. ggplot(data = d_box, aes(x = LearningCondition, y = PropCorrect)) + geom_boxplot() + xlab(&quot;Learning condition&quot;) + ylab(&quot;Proportion correct answers&quot;) + theme_bw(15) When you’re happy with a plot, you can save it using ggsave(). You can set the width and height of the figure using the width and height parameters, e.g., ggsave(here(&quot;figures&quot;, &quot;03_boxplot.png&quot;), width = 8, height = 4) Per default, the width and height numbers are in inches. See the help page (https://ggplot2.tidyverse.org/reference/ggsave.html) on how to override this. 3.5 Computing summaries While this is a tutorial on drawing graphs, it’s useful at this stage to know how to obtain some basic information about the datasets you’re working with. There are many ways to accomplish most things in R, and computing summaries is no exception. The alternative shown here is similar to the way plots are constructed in ggplot2, so hopefully it’s easy to pick up. First, let’s compute the number of observations in the d_box dataset as well as the mean of the PropCorrect variable. The code below can be read as follows: Take d_box, THEN summarise it as follows: compute the number of observations (n()) and store it as number and compute the mean of PropCorrect and store it as mean_PropCorrect. d_box |&gt; summarise(number = n(), mean_PropCorrect = mean(PropCorrect)) ## # A tibble: 1 × 2 ## number mean_PropCorrect ## &lt;int&gt; &lt;dbl&gt; ## 1 80 0.368 Thus we see that there are 80 observations in the dataset with a mean PropCorrect of about 0.37. If we want to compute the mean for the two learning conditions separately, we insert a corresponding group_by() statement. The code below can thus be read as Take d_box, THEN Group it by the values of LearningCondition, THEN For each group created, create a summary containing the mean of the PropCorrect variable. d_box |&gt; group_by(LearningCondition) |&gt; summarise(mean_PropCorrect = mean(PropCorrect)) ## # A tibble: 2 × 2 ## LearningCondition mean_PropCorrect ## &lt;chr&gt; &lt;dbl&gt; ## 1 &lt;ij&gt; participants 0.436 ## 2 &lt;oe&gt; participants 0.290 The word THEN is represented by a so-called pipe operator (|&gt;), a shortcut for which is ctrl+shift+m on Windows/Linux and cmd + shift + m on Mac. 3.6 Exercise The file Vanhove2014_CognateProfile.csv contains data from Vanhove (2014). 163 Swiss-Germans attempted to translate 45 written Swedish words, all of which had German, English and/or French cognates. To check which participants already had some minimal knowledge of Swedish, they also had to translate five words without cognates in German, English or French (e.g., älska ‘to love’); these are known as ‘profile words’. For the subsequent analysis, it was important to know (a) how many participants could translate at least one such profile word correctly; and (b) if participants who could translate at least one such profile word did better at translating cognates than those who couldn’t. The column CorrectCognates contains the number of correct cognate translations per participant; the column shows whether the participant in question was able to translate at least one profile word correctly (yes vs. no). In a new script, read in the dataset into R. Compute the number of participants who were able to correctly translate at least one profile word. Use a boxplot to compare the number of correctly translated cognate words between participants that could translate at least one profile word correctly and those that couldn’t. Label your axes appropriately. Compile the HTML report. Submit both the boxplot and the HTML report. References "],["week-4-boxplots-deluxe.html", "4 Week 4: Boxplots deluxe 4.1 Goals 4.2 Tutorial 4.3 Exercise", " 4 Week 4: Boxplots deluxe 4.1 Goals You’ll learn how to add the individual data points underlying a boxplot to this boxplot. This makes for more informative graphs, particularly for smallish datasets (up till 100–150 observations or so). To do this, we’ll use a technique known as jittering to make overlapping datapoints more visible. 4.2 Tutorial Plain boxplots are useful when you want to get a quick idea of the distribution of the data in different groups (see last week). However, identically looking boxplots can represent markedly different distributions! See http://goo.gl/v4vYvx for an example. For this reason, it can be useful to draw boxplots that also show the individual data points rather than merely the distribution’s quartiles. Such visualisations are particularly useful when the dataset isn’t prohibitively large, so that you can actually make out the different data points. In the following, I assume you’ll work within your R project and that you have the tidyverse and here packages. Always use scripts rather than typing your commands directly to the prompt. Read in the dataset VowelChoices_ij.csv (see last week). Draw the boxplot of last week’s tutorial again. ggplot(data = d_box, aes(x = LearningCondition, y = PropCorrect)) + geom_boxplot() + xlab(&quot;Learning condition&quot;) + ylab(&quot;Proportion correct answers&quot;) + theme_bw(12) We can add another layer to this graph by inserting the command geom_point() into the ggplot call. geom_point() draws the data points as, well, points and doesn’t summarise its quartiles like geom_boxplot() does. Since we insert geom_point() after geom_boxplot(), these points will be plotted on top of (rather than underneath) the boxplots. ggplot(data = d_box, aes(x = LearningCondition, y = PropCorrect)) + geom_boxplot() + geom_point() + # draw individual data points xlab(&quot;Learning condition&quot;) + ylab(&quot;Proportion correct answers&quot;) + theme_bw(12) If you count the number of points in this graph, you’ll notice that there are fewer points (28) than there were participants (80). The reason is that several participants obtained the same result, and their data are plotted on top of each other. For this reason, it makes sense to move the plotted points a bit apart (jittering). Here we can move the points apart horizontally. To do this, we need to specify the position parameter inside the geom_point() command. We can specify both width (horizontal jittering) and height (vertical jittering). Fiddle with the setting for width to see what happens if you change it. I’d leave the value for height set to 0 (= no vertical jittering) so that we don’t depict proportions of, say, 0.24 as 0.28. Notice that I’ve additionally specified the outlier.shape parameter in the geom_boxplot() command as NA (not available). This prevents the geom_boxplot() command from plotting outlying data points so that these points aren’t plotted twice (as part of the boxplot and as an individual data point). ggplot(data = d_box, aes(x = LearningCondition, y = PropCorrect)) + geom_boxplot(outlier.shape = NA) + # don&#39;t plot outliers twice geom_point(position = position_jitter(width = 0.2, # horizontal jittering height = 0)) + # but no vertical jittering xlab(&quot;Learning condition&quot;) + ylab(&quot;Proportion correct answers&quot;) + theme_bw(12) To make the individual data points more visually distinct, we can change the plotting symbol by changing the shape parameter. This overview shows which plotting symbols are available: Empty circles tend to work well (shape 1): ggplot(data = d_box, aes(x = LearningCondition, y = PropCorrect)) + geom_boxplot(outlier.shape = NA) + geom_point(position = position_jitter(width = 0.2, height = 0), shape = 1) + # 1 = empty circles xlab(&quot;Learning condition&quot;) + ylab(&quot;Proportion correct answers&quot;) + theme_bw(12) (Shapes 21 through 25 resemble shapes 1 through 5, but they can be coloured in.) More info: https://janhove.github.io/reporting/2016/06/21/drawing-a-boxplot. 4.3 Exercise The dataset Wagenmakers_Zeelenberg.csv contains data from a study by Wagenmakers et al. (2016).1 In this experiment, participants were instructed to either smile or pout (Condition) as they judged the funniness of four cartoons on a 10-point scale (0–9). The mean rating per participant can be found in the creatively named column MeanRating. The research question was if smiling participants gave higher funniness ratings than pouting ones. Your task: In a new script, compute the number of participants in each condition as well as the mean MeanRating per condition. Also draw boxplots (with individual data points) on the basis of which this research question can be answered. Label your axes appropriately. Save a graph you’re happy with using ggsave(). Submit both your graph and the compiled HTML report. References "],["week-5-line-charts.html", "5 Week 5: Line charts 5.1 Goals 5.2 Tutorial 5.3 About facetting 5.4 For those interested 5.5 Exercise", " 5 Week 5: Line charts 5.1 Goals You’ll learn how to draw line charts in R. Line charts are a popular choice for visualising temporal developments, but they can be used for other purposes, too. You’ll also learn how to split up a complex graph into several simpler graphs. This technique is known as facetting or creating small multiples. 5.2 Tutorial Line charts are a reasonable choice for presenting the results of more complex studies. They’re often used to depict temporal developments, but I don’t think their use should be restricted to this. I often use line charts to better understand complex results that are presented in a table. For instance, Slavin et al. (2011) presented their results in four tables (Tables 4–7). I entered the results pertaining to the PPVT (English) and TVIP (Spanish) post-tests into a CSV file (Peabody_Slavin2011.csv): slavin &lt;- read_csv(here(&quot;data&quot;, &quot;Peabody_Slavin2011.csv&quot;)) Grade: Grades 1 through 4. CourseType: EI (English immersion) or TBE (transitional bilingual education). Language: English or Spanish. Learners: Number of learners per class, language and course type. Mean: Mean score per class, language and course type. StDev: Standard deviation per class, language and course type. We can plot the development in the English and Spanish test scores for the two course types: ggplot(data = slavin, aes(x = Grade, y = Mean, colour = Language, # use different colours per language linetype = CourseType)) + # use different line types per course type geom_line() + # connect data points with a line geom_point() # add data points as points for good measure You should understand most of the R code above by now; if you don’t, please refer to the previous tutorials. What’s new is that you can specify more than just an x and a y parameter in the aes() call. When you associate colour and linetype with variables in the dataset, the data associated with different levels of these variables (i.e., English vs. Spanish; TBE vs. EI) will be plotted in a different colour or using a different line type. The colours and line types used here are ggplot’s default choices; we could override those, but that’ll be for some other time. The same goes for the appearance of the legends. Using different colours and line types is all good and well if you have a limited number of variables and a small number of levels per variable. But for more complex data, such graphs quickly become confusing. One useful technique is to plot different lines in separate graphs (small multiples) and show the different graphs side-by-side. This is known as facetting. The command facet_grid() can be used to specify the variables according to which the graph should be separated and how. Since the information regarding Language and CourseType is expressed in the facets, we don’t have to express it using colours and linetypes any more. (But feel free to do so if you think it makes things clearer!) We need to quote the names of the variables according to which the facets are to be drawn in a vars() call. ggplot(data = slavin, aes(x = Grade, y = Mean)) + geom_line() + geom_point() + facet_grid(rows = vars(CourseType), # TBE vs. EI in rows; cols = vars(Language)) # Span. vs. Eng. in columns Or you can combine facetting with using different colours or line types. In the next plot, the data for different languages are shown in separate panels, but each panel shows the data for both the TBE and EI pupils. This is particularly useful if we want to highlight differences (or similarities) between the TBE and EI pupils. If instead we wanted to highlight differences or similarities in the development of the pupils’ language skills in Spanish and English, we’d draw this graph the other way round. In addition to connecting the means with a line, this graph also visualises the means using a symbol in order to highlight that there were four discrete measurement times (i.e., no measurements between Grades 1 and 2). ggplot(data = slavin, aes(x = Grade, y = Mean, shape = CourseType, # different symbols by course type linetype = CourseType)) + geom_point() + geom_line() + facet_grid(cols = vars(Language)) # only split graph by column (Sp. vs. Eng.) 5.3 About facetting You can also use facetting for other types of plots. I’m sure you fondly remember your scatterplot from the first tutorial; here it is again but the different species are shown in separate panels: data(iris) ggplot(iris, aes(x = Sepal.Width, y = Sepal.Length)) + geom_point(shape = 1) + facet_grid(cols = vars(Species)) 5.4 For those interested For a longer example, see https://janhove.github.io/reporting/2016/06/13/drawing-a-linechart. 5.5 Exercise The dataset MorphologicalCues.csv contains data stemming from a learning task in which the participants had to associate a morphological form with a syntactic function. 70 learners were randomly assigned to one of three conditions (Condition): RuleBasedInput: In this condition, the input showed a perfect association between the morphological form and the syntactic function. StrongBias: The input showed a strong, but imperfect association between form and function. WeakBias: The input showed a weak (but non-zero) association between form and function. To track the learners’ progress throughout the task, the learners took part in three sorts of exercises: Comprehension, grammaticality judgement GJT and Production. They did this at four stages during the data collection (Block 1, 2, 3, 4), that is, after receiving a bit of input, some more input, etc. The column Accuracy shows the mean percentage of correct responses per Block, per Task and per Condition. The research question: How does Accuracy develop in the course of the data collection depending on the Task and Condition? Your task: Plot these data so that the research question can be answered. You will want to try out several graphs so that you can pick a graph that you find most comprehensible. You can only hand in a single graph, though. Save a graph you’re happy with using ggsave(). Submit both your graph and the compiled HTML report. References "],["week-6-dotplots.html", "6 Week 6: Dotplots 6.1 Goals 6.2 Pie charts, bar charts, and dotplots 6.3 Tutorial 6.4 For other kinds of data 6.5 Exercise", " 6 Week 6: Dotplots 6.1 Goals You’ll learn how to draw simple dotcharts… and why they’re better than pie charts. You’ll gain some experience in debugging R code with typos :) 6.2 Pie charts, bar charts, and dotplots The three graphs below all show the same data (the proportion of sales of a pie producer by pie taste).2 The graph on the left is a traditional pie chart. Though common, this type of graph has serious shortcomings, for which reason it should rarely be used: Pie charts aren’t very flexible: When the number of categories is larger than here, pie charts are hardly comprehensible. It’s also difficult to add additional information to pie charts (e.g., the proportion of sales by taste the year before; see below). Readers gauge the numbers (in this case: the proportions) that the pie chart represents less accurately than when they’re presented in a bar chart or in a dot plot (Cleveland &amp; McGill 1984). The graph in the middle is a bar chart, the one of the right a dot plot. Both are better choices than pie charts. For one things, they’re more flexible. For instance, you can add the sales from the year before to both graphs—as separate bars or by using different symbols. This would be difficult to accomplish in a pie chart: I prefer dot plots because it’s easier to visualise a large number of categories and I find them less ‘busy’. Tip: If you prefer bar charts: It’s usually better to plot the bars next to each other rather than to stack them on top of each other. Tip: Don’t use pie charts. Incidentally, if you enter the following command in R, the help page for the pie() function opens. Then scroll down to the section Note. # Help page for pie() ?pie 6.3 Tutorial We’ll use data from Vanhove (2017) (see Moodle). For this study, I recruited 175 native speakers of Dutch from Belgium and the Netherlands. I showed them 44 German words with Dutch cognates (e.g., Stadt (NL stad) or Schiff (NL schip)) and asked them to choose their gender-marked definitive article (der (masculine), die (feminine), das (neuter)). Dutch and German are closely related languages, but there are a number of cognates whose grammatical gender differs between both languages. The Dutch word strand (beach), for instance, is neuter, whereas the German word Strand is masculine. One of the research questions was if Belgian and Dutch participants were more likely to choose the neuter article das if the German word’s Dutch cognate is neuter than when it has common gender.3 Read in this dataset in R: dat &lt;- read_csv(here(&quot;data&quot;, &quot;GermanArticleChoices.csv&quot;)) ## Rows: 88 Columns: 6 ## ── Column specification ────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (5): Stimulus, Country, DutchCognate, GermanGender, DutchGender ## dbl (1): NeuterResponses ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. The first few rows should look as follows: head(dat) ## # A tibble: 6 × 6 ## Stimulus Country NeuterResponses DutchCognate GermanGender DutchGender ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Stadt Belgium 0 stad feminine common ## 2 Stadt The Netherlands 0 stad feminine common ## 3 Saal Belgium 0 zaal masculine common ## 4 Saal The Netherlands 0.0674 zaal masculine common ## 5 Nacht Belgium 0.0652 nacht feminine common ## 6 Nacht The Netherlands 0.0225 nacht feminine common The column NeuterResponses contains the proportion of neuter article (das) choices per German word (Stimulus) per (Country). The column GermanGender contains the word’s correct gender (in German); the column DutchGender contains the grammatical gender of the word’s Dutch cognate. 6.3.1 A first attempt We can plot the proportion of das choices per word separately per country (Belgium vs. the Netherlands). This will show us how strongly the response pattern varies per word and whether Belgian and Dutch speakers of Dutch show different preferences. The code and comments show how to build this dot plot: Tip: You’ll learn more by typing in these commands yourself and adding your own comments than by copy-pasting them. For this reason, I added a couple of typos and left out a couple of commas and brackets – all for you to find and fix, enjoy! ggplot(dat, aes(x = NeuteResponses, y = Stimulus, shape = Country)) + geom_point() 6.3.2 Highlight differences between different categories of stimuli The plot above doesn’t offer an answer to the research question since the difference between stimuli with different Dutch genders isn’t highlighted. To accomplish this, we can plot stimuli with neuter cognates and those with common-gender cognates in different boxes (facetting, see the tutorial on line charts). (To see what scales = \"free_y\" and space = \"free_y\" accomplish, leave these parameters out of the call, i.e., using just facet_grid(rows = vars(DutchGender)).) ggplot(dat, aes(x = NeuterResponses, y = Stimulus shape = Country)) + geom_point() + facet_grid(rows = vars(DutchGender), # split up vertically by Dutch gender scales = &quot;free_y&quot;, space = &quot;free_y&quot;) This graph shows pretty clearly that both Belgian and Dutch speakers of Dutch pick das more often if the German word has a neuter-gender cognate than when it has a common-gender cognate: The points in the lower box lie more to the right than those in the upper box. With a single exception (Boot), there is no overlap between these two distributions. Additionally, the responses of Belgian and Dutch participants don’t seem to vary much from one another. (For instance, we don’t observe that most triangles lie to the right of the circles or that Belgian participants prefer das for Wurst and Dutch participants don’t.) 6.3.3 A final attempt The previous graph is good enough. But we can do better still. German is taught in school in both Flanders and the Netherlands, and at least some participants will have known which words are neuter in German and which aren’t. So some of the variation between the stimuli will be attributable to the stimuli’s German gender. To highlight this, we can split up the graph not only by the words’ Dutch gender, but also by their German gender. And we still have to label the axes! ggplot(dat, aes(x = NeuterResponses, y = Stimulus, shape = Country)) + geom_point() facet_grid(rows = vars(DutchGender, GermanGender), # split up by Dutch and German gender scales = &quot;free_y&quot;, space = &quot;free_y&quot;) + xlab(&quot;Proportion &#39;das&#39;&quot;) + # axis label for x ylab(&quot;&quot;) # the y axis is self-explanatory The upper three boxes show feminine, masculine and neuter German words with common-gender cognates; the lower three boxes show feminine, masculine and neuter German words with neuter-gender cognates. The graph shows that the factor Dutch gender is the most important determinant of the participants’ article choices. But the factor German gender also plays a role: When a German word is neuter, both Belgian and Dutch people choose das more often than when it’s feminine or masculine. 6.3.4 Optional: Possible improvements and further information Now the words are sorted alphabetically in each box. But this order can be customised. The symbols used in the graph above are difficult to distinguish optically. They, too, can be changed. If you’re interested in these possibilities, please refer to https://janhove.github.io/reporting/2016/08/30/drawing-a-dotplot. The versatility and usefulness of dotplots in linguistics is highlighted by Sönning (2016). Another useful introduction is Jacoby (2006). I don’t expect you to carry out these additional steps. But perhaps they’re useful to you in the future. 6.4 For other kinds of data In the tutorial above, we worked with proportions. But you can use dot plots for other types of data, too. See http://perceptualedge.com/articles/b-eye/dot_plots.pdf for some examples. 6.5 Exercise Baten (2011) was interested in the acquisition of the German case system by Flemish pupils. He reported his results in elaborate tables; we’ll focus on the accuracy data for accusative and dative pronouns (e.g., dich vs. dir) that occur after prepositions. I tabulated the results in ErgebniseBaten2011.csv (Moodle). This data set contains 4 columns: Grade: Baten’s participants were pupils from 10th, 11th and 12th grade. TargetCase: The correct form was either an accusative or a dative pronoun. Position: Some pronouns occurred after a preposition that is either always followed by an accusative (e.g., bis) or always followed by a dative (e.g., nach); these are marked as fixed-preposition. Other pronouns occurred after a preposition that could be followed by both an accusative or a dative, depending on its meaning (e.g., in and auf; wechsel-preposition). Below you’ll find two graphs. Both highlight that there’s a huge leap in accuracy between 10th and 11th grade. Moreover, accuracy is higher for the ‘fixed’ prepositions than for the ‘Wechselpräpositionen’. (This is slightly clearer in the second graph, I think.) Your task: Draw both graphs yourself. Hand in the compiled HTML report. References "],["week-7-scatterplots.html", "7 Week 7: Scatterplots 7.1 Goals 7.2 Summarising datasets 7.3 Scatterplots 7.4 Exercise", " 7 Week 7: Scatterplots 7.1 Goals You’ll learn how to visualise the relationship between two continuous variables in a scatterplot. You’ll gain some experience with summarising and manipulating large datasets. 7.2 Summarising datasets Vanhove (2014) investigated how people’s ability to recognise written and spoken cognates in a related but unknown language develops throughout the lifespan and how it is related to linguistic and cognitive factors. The dataset Vanhove2014_Translations.csv contains the raw data of this study. For each of the 163 participants, this dataset contains 100 entries (one for each cognate), for a total of 16,300 rows. Each translation was rated as correct or incorrect. Additionally, the dataset contains some information about the participants (e.g., their performance on other tasks) as well as about the stimuli (e.g., a measure expressing its formal similarity to its French, German or English cognate). # Read in data d &lt;- read_csv(here(&quot;data&quot;, &quot;Vanhove2014_Translations.csv&quot;)) ## Rows: 16300 Columns: 15 ## ── Column specification ────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (5): Stimulus, Mode, Translation, Sex, Status ## dbl (10): Subject, Trial, Correct, Age, NrLang, DS.Total, WST.Right, Raven.R... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. The variables: Stimulus: The word to be translated. Subject: The participant’s ID. Mode: Whether the word was presented in its spoken (Auditory) or in its written form (Visual). Trial: The position of the word in the task. Translation: The participant’s translation attempt for the stimulus. Correct: Whether the translation was correct (1) or incorrect (0). Sex Age NrLang: The number of languages the participant spoken. DS.Total: The participant’s score on a working memory task. WST.Right: The participant’s score on a German vocabulary test. Raven.Right: The participant’s score on an intelligence test. English.Total: The participant’s score on an English-language test. Status: Whether the stimulus has a German, English, or French cognates (target) or not (profile). MinLev: The degree of formal discrepancy between the stimulus and its most similar German, English or French cognate. (lower = more similar) Missing values were labelled NA (not available). A rough summary can be obtained like so: summary(d) ## Stimulus Subject Mode Trial ## Length:16300 Min. : 64 Length:16300 Min. : 1.0 ## Class :character 1st Qu.:2909 Class :character 1st Qu.:13.0 ## Mode :character Median :5731 Mode :character Median :25.5 ## Mean :5317 Mean :25.5 ## 3rd Qu.:7794 3rd Qu.:38.0 ## Max. :9913 Max. :50.0 ## ## Translation Correct Sex Age ## Length:16300 Min. :0.0000 Length:16300 Min. :10.00 ## Class :character 1st Qu.:0.0000 Class :character 1st Qu.:16.00 ## Mode :character Median :0.0000 Mode :character Median :39.00 ## Mean :0.3523 Mean :40.28 ## 3rd Qu.:1.0000 3rd Qu.:60.00 ## Max. :1.0000 Max. :86.00 ## ## NrLang DS.Total WST.Right Raven.Right ## Min. :1.000 Min. : 2.000 Min. : 4.00 Min. : 0.0 ## 1st Qu.:2.000 1st Qu.: 5.000 1st Qu.:29.00 1st Qu.:12.0 ## Median :3.000 Median : 6.000 Median :34.00 Median :19.0 ## Mean :3.067 Mean : 6.374 Mean :30.24 Mean :17.8 ## 3rd Qu.:4.000 3rd Qu.: 8.000 3rd Qu.:36.00 3rd Qu.:24.0 ## Max. :9.000 Max. :12.000 Max. :41.00 Max. :35.0 ## NA&#39;s :100 ## English.Total Status MinLev ## Min. : 3.00 Length:16300 Min. :0.0000 ## 1st Qu.:20.75 Class :character 1st Qu.:0.2857 ## Median :31.00 Mode :character Median :0.4000 ## Mean :28.30 Mean :0.4566 ## 3rd Qu.:37.00 3rd Qu.:0.6062 ## Max. :44.00 Max. :1.0000 ## NA&#39;s :300 In order to be able to sensibly visualise these data, we need to first transform this dataset. If we’re interested in the relationship between the participants’ age, sex, and linguistic and cognitive test results on the one hand and their translation performance on the other hand, it seems useful to first compute the number of correct translations for spoken and written words per participant. There are a couple of ways you could do this in R; I find the method outlined below the most transparent one. Let’s start with a simple example. We’ll first compute the total number of correct responses in the entire dataset. The comments show you how you can read the R code out loud. # 1st attempt: Total number of correct answers # Take object &#39;d&#39; (our dataset), then d |&gt; # summarise it as follows: # - compute the sum of &#39;Correct&#39; and call this sum &#39;number_correct&#39; summarise(number_correct = sum(Correct)) ## # A tibble: 1 × 1 ## number_correct ## &lt;dbl&gt; ## 1 5743 The result is shown in the console. We can also save it as a separate object so that we can work with it later. Here I save it as an object called overall_accuracy: overall_accuracy &lt;- d |&gt; summarise(number_correct = sum(Correct)) (To type the symbol combination |&gt; (known as the pipe; read out loud as ‘and then’), you can also use the shortcut ctrl + shift + m.) The total number of correct answers in the entire dataset isn’t too useful to us: we need the number of correct answers per participant. # 2nd attempt: Number of correct answers per participant # Create new object &#39;per_part&#39; as follows: # take &#39;d&#39;, and then... per_part &lt;- d |&gt; # group it by Subject, and then... group_by(Subject) |&gt; # compute the sum of Correct within each group summarise(number_correct = sum(Correct)) # Show result per_part ## # A tibble: 163 × 2 ## Subject number_correct ## &lt;dbl&gt; &lt;dbl&gt; ## 1 64 49 ## 2 78 39 ## 3 134 36 ## 4 230 38 ## 5 288 21 ## 6 326 45 ## 7 447 47 ## 8 527 24 ## 9 545 33 ## 10 550 46 ## # ℹ 153 more rows Now we have the total number of correct translations per participant, but this figure contains both the responses to written and to spoken words. It’d be more useful to split this figure up by modality: # 3rd attempt: Number of correct translations per participant, # split up by modality. per_part2 &lt;- d |&gt; # group by Subject and Mode group_by(Subject, Mode) |&gt; summarise(number_correct = sum(Correct)) ## `summarise()` has grouped output by &#39;Subject&#39;. You can override using the ## `.groups` argument. per_part2 ## # A tibble: 326 × 3 ## # Groups: Subject [163] ## Subject Mode number_correct ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 64 Auditory 24 ## 2 64 Visual 25 ## 3 78 Auditory 19 ## 4 78 Visual 20 ## 5 134 Auditory 24 ## 6 134 Visual 12 ## 7 230 Auditory 12 ## 8 230 Visual 26 ## 9 288 Auditory 12 ## 10 288 Visual 9 ## # ℹ 316 more rows The message (summarise() has grouped output by ‘Subject’.) isn’t harmful, but you can get rid of it as follows: per_part2 &lt;- d |&gt; group_by(Subject, Mode) |&gt; summarise(number_correct = sum(Correct), .groups = &quot;drop&quot;) Our goal is to visualise the relationship between variables such as IQ, age, and L1 vocabulary skills on the one hand and the participants’ translation performance on the other hand. To do this, we need to add these variable to the summary. Again, there are several ways to do this; here’s one. # 4th attempt: Like above, but adding Age, etc. # Create a new object with participant-related information. # Take &#39;d&#39;, and then... part_info &lt;- d |&gt; # Select the following columns select(Subject, Age, Sex, WST.Right, Raven.Right, English.Total, NrLang, DS.Total) Like d, part_info consists of 16,300 rows. But each row is repeated 100 times. Using distinct(), the duplicates are deleted: part_info &lt;- part_info |&gt; distinct() Now we can add the information from part_info to per_part2: # Create new object &#39;per_part3&#39;. # Take object &#39;per_part2&#39;, and then... per_part3 &lt;- per_part2 |&gt; # join it with &#39;part_info&#39; using &#39;Subject&#39; as the &quot;zipper&quot; full_join(part_info, by = &quot;Subject&quot;) # Show result per_part3 ## # A tibble: 326 × 10 ## Subject Mode number_correct Age Sex WST.Right Raven.Right English.Total ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 64 Audit… 24 27 fema… 34 28 42 ## 2 64 Visual 25 27 fema… 34 28 42 ## 3 78 Audit… 19 47 fema… 33 26 27 ## 4 78 Visual 20 47 fema… 33 26 27 ## 5 134 Audit… 24 33 male 32 24 24 ## 6 134 Visual 12 33 male 32 24 24 ## 7 230 Audit… 12 84 male 37 20 31 ## 8 230 Visual 26 84 male 37 20 31 ## 9 288 Audit… 12 28 male 35 24 39 ## 10 288 Visual 9 28 male 35 24 39 ## # ℹ 316 more rows ## # ℹ 2 more variables: NrLang &lt;dbl&gt;, DS.Total &lt;dbl&gt; One final problem remains: The number of correct answers includes responses to both cognates and to non-cognates. We’re only interested in the responses to cognates, however. Using filter(), we only retain the responses that are of interest: # 5th attempt: Like above, but only consider target stimuli. per_part &lt;- d |&gt; # only consider target stimuli filter(Status == &quot;target&quot;) |&gt; # group by Subject and Mode group_by(Subject, Mode) |&gt; # Compute sum of Correct summarise(number_correct = sum(Correct), .groups = &quot;drop&quot;) |&gt; # Add the information from part_info using Subject as the &quot;zipper&quot; full_join(part_info, by = &quot;Subject&quot;) per_part ## # A tibble: 326 × 10 ## Subject Mode number_correct Age Sex WST.Right Raven.Right English.Total ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 64 Audit… 23 27 fema… 34 28 42 ## 2 64 Visual 25 27 fema… 34 28 42 ## 3 78 Audit… 19 47 fema… 33 26 27 ## 4 78 Visual 20 47 fema… 33 26 27 ## 5 134 Audit… 24 33 male 32 24 24 ## 6 134 Visual 12 33 male 32 24 24 ## 7 230 Audit… 12 84 male 37 20 31 ## 8 230 Visual 26 84 male 37 20 31 ## 9 288 Audit… 12 28 male 35 24 39 ## 10 288 Visual 9 28 male 35 24 39 ## # ℹ 316 more rows ## # ℹ 2 more variables: NrLang &lt;dbl&gt;, DS.Total &lt;dbl&gt; 7.3 Scatterplots To investigate the relationhip between, say, WST.Right and number_correct, we can plot these data in a scatterplot. While we’re at it, we can split up this graph into two panels: one for written words, and one for spoken words. ggplot(dat = per_part, aes(x = WST.Right, y = number_correct)) + # Incidentally, you can specify the shape and colour of the points yourself. geom_point(shape = 21, colour = &quot;darkblue&quot;, fill = &quot;green&quot;) + # Type in &quot;colours()&quot; to see which colour names are recognised by R. # Type in ?pch to see which &#39;shape&#39; values are accepted. xlab(&quot;L1 vocabulary test&quot;) + ylab(&quot;Number of correct translations\\n(out of 45)&quot;) + facet_grid(cols = vars(Mode)) + labs(title = &quot;A title of your choice&quot;, subtitle = &quot;(and perhaps even a subtitle)&quot;, caption = &quot;(and a caption)&quot;) ## Warning: Removed 2 rows containing missing values (`geom_point()`). (The warning concerns missing values in the WST variable. Inspect the dataset to find for how many participants the WST score is missing!) As we’ll discuss in class, scatterplots are the indispensable first (and sometimes final) step when analysing the relationship between two continuous variables. As for the decision which variable to put along which axis. By and large, put the variable that is most likely to be the cause of the relationship along the x axis and the variable that is most likely to be the effect along the y axis. In this case, it seems more likely that L1 skills affect one’s ability to recognise cognates in a foreign language than vice versa. Hence, put the variable representing L1 skills along the x axis. 7.4 Exercise Draw a scatterplot that shows the relationship between the participants’ score on the English-language test and the number of correct translations. How many participants’ data are shown? Hand in the compiled HTML report. Mention the number of participants whose data are shown in the R code. References "],["week-8-scatterplots-with-trend-lines.html", "8 Week 8: Scatterplots with trend lines 8.1 Goal 8.2 Drawing scatterplot smoothers 8.3 So what’s a scatterplot smoother anyway? 8.4 Examples of nonlinear relationships 8.5 Exercise", " 8 Week 8: Scatterplots with trend lines 8.1 Goal You’ll learn to highlight the trend in the relationship between two variables using scatterplot smoothers. 8.2 Drawing scatterplot smoothers ggplot(dat = per_part, aes(x = English.Total, y = number_correct)) + geom_point(shape = 1) + geom_smooth() + # add smoother xlab(&quot;Result English test&quot;) + ylab(&quot;Numer of correct translations&quot;) + facet_grid(cols = vars(Mode)) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## Warning: Removed 6 rows containing non-finite values (`stat_smooth()`). ## Warning: Removed 6 rows containing missing values (`geom_point()`). The blue line is the smoother; the grey ribbon around it is known as a (95%) confidence band and communicates our uncertainty about the precise location of the smoother (due to lack of data and variability in the data). Of course, you can change the colour of the line to suit your personal taste, and you can turn off the grey ribbon (se = FALSE; se is short for ‘standard error’, which is unfortunate – a standard error and a confidence band aren’t the same thing). We’re going to turn off the confidence band because it’s bound to be misinterpreted anyway. ggplot(dat = per_part, aes(x = English.Total, y = number_correct)) + geom_point(shape = 1) + geom_smooth(se = FALSE, colour = &quot;red&quot;) + xlab(&quot;Result English test&quot;) + ylab(&quot;Numer of correct translations&quot;) + facet_grid(cols = vars(Mode)) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## Warning: Removed 6 rows containing non-finite values (`stat_smooth()`). ## Warning: Removed 6 rows containing missing values (`geom_point()`). 8.3 So what’s a scatterplot smoother anyway? Scatterplot smoothers were developed to discover relationships (including nonlinear ones) between two variables that aren’t necessarily immediately obvious if the data are shown in a scatterplot. The points on the smoother are a kind of mean value of the \\(Y\\) variable for the respective \\(X\\) value. In the left panel, for instance, the average number of correct translations in the auditory mode for someone with an English test score of 30 is roughly 17–18, whereas the average number of correct translations for written words for participants with a score of 40 on the English test is about 25. We needn’t amuse ourselves with the maths behind these smoothers, but the following points are important: The trend line is nearly always a bit wiggly (to use the actual technical term). This is the case even when the relationship itself is as good as linear. The uncertainty about the smoother is larger at the extremes (high and low \\(x\\) values). The confidence band is correspondingly wider at these places. But again, we’re not going to plot the confidence bands in order not to confuse ourselves or our readership. The default settings for geom_smooth() tend to work fairly well, but sometimes it’s necessary to fiddle with them so that the smoother captures the trend in the data better. See next section. 8.4 Examples of nonlinear relationships This section serves to show you what true nonlinear relationships can look like and how you sometimes need to fiddle with geom_smooth()’s settings. In the first example, the red line was drawn with the default settings. This line doesn’t capture an important feature of the relationship (the data points go up and down). The blue line captures this trend much better. It was drawn using the command geom_smooth(span = 0.1). The span parameter determines how wiggly the curve may be (the smaller span, the wigglier the curve). By default, span is set to 0.75. Finding a decent span value is matter of trial and error. In the second example, the red line was drawn using geom_smooth(span = 0.1). This line is much too wiggly, and it essentially models random deviations from the general trend. The blue line, drawn with the default setting (span = 0.75), captures the general trend much more sensibly. The green line, by contrast, isn’t wiggly enough (span = 3). Summing up: Generally, the default settings work reasonably well. But when you notice that visually salient patterns in the scatterplot aren’t captured by the trend line, you need to fiddle a bit with the span parameter. More generally, data analysis and statistics aren’t a matter of blindly applying formulae and recipes. 8.5 Exercise Draw a scatterplot that shows the relationship between the participants’ age and their performance on the cognate translation task. How would you describe this relationship? Now add a smoother (default settings) to this scatterplot. Does it capture the trend that you identified in the scatterplot? Now fiddle with the span parameter (0.1, 0.2, 0.3 etc.) Hand in the graph you think works best as well as the compiled HTML report. "],["week-9-first-graded-assignment.html", "9 Week 9: First graded assignment", " 9 Week 9: First graded assignment The final plotti8ng assignments are free assignments. You’ll receive a dataset and a research question. Your task is to draw a graph with which you can answer the research question. You get to decide which graph you draw - but don’t choose your graph willy-nilly. We’ll discuss your graphs in class. The dataset for the first free assignment, PortugueseHeritageLanguage.csv, contains data from a project conducted at the Institute of Multilingualism. The project in question was a longitudinal one with three data collections that investigated (among other thing) the development of the narrative skills in Portuguese in children of Portuguese heritage living in German- and French-speaking Switzerland as well as in a comparison group of Portuguese children living in Portugal. The dataset contains the following pieces of information: VPNID: The child’s project ID. Each child occurs three times in the dataset (three data collections). NumberOfLanguages: The number of languages the child speaks. InputPortugueseSchool: How much Portuguese does the child speak in school? (questionnaire item, ranging from 0 to 100%) PortugueseFather, PortugueseMother: How well do the child’s father and mother speak Portuguese? (parents’ self-assessment, ranging from 1 (worst) to 6 (best)) PortugueseParents: The sum of PortugueseFather and PortugueseMother. EducationFather, EducationMother: A higher number reflects a higher level of parental education. EducationParents: Sum of EducationFather and EducationMother. LanguageGroup: Bilingual group (French) = Child of Portuguese heritage living in French-speaking Switzerland. Bilingual group (German) = Child of Portuguese heritage living in German-speaking Switzerland. Control group Portuguese = Child living in Portugal. BilingualControl: bilingual = child living in Switzerland; control = child living in Portugal. RegionalLanguage: French = French-speaking Switzerland, German = in German-speaking Switzerland, Portuguese = in Portugal. Time: T1, T2, T3 (first, second, third data collection) Result: Assessment of the child’s narrative skills in Portuguese at a given data collection. Several of these pieces information are mutually redudant: The information contained in RegionalLanguage can be derived from LanguageGroup as well, for instance. Missing values and null responses were coded as NA. Your task: Draw a graph with which the following question can be answered: How do the narrative skills in Portuguese of children of Portuguese heritage living in German- and French-speaking Switzerland as well as of children living in Portugal develop from data collection 1 through 3? This is a pretty difficult assignment, so take your time. Try out a couple of different graphs, and hand in the graph you think works best. Also hand in the compiled HTML report. "],["week-10-second-graded-assignment.html", "10 Week 10: Second graded assignment", " 10 Week 10: Second graded assignment This dataset stems from a study by Poarch, Vanhove &amp; Berthele (2019). The authors investigated to what extent the knowledge and use of both a dialect and standard variety confers a boost in executive function/cognitive control similar to the purported “bilingual advantage” (see Kirk et al. 2014). Their subjects were Swabian - Standard German bilinguals and took part in two tasks tapping into their cognitive control: The flanker task and the Simon task. They also filled out a questionnaire on the basis of which their dialect and standard knowledge and use were assessed. The files Poarch2018_long.csv and Poarch2018_wide.csv contain the same data, but arranged slightly differently (so you can use whichever arrangement you find easiest to work with). Poarch2018_long.csv contains the following variables: Subject: The participants’ ID (arbitrary). Age: Their age. Sex Education: Their level of education (larger number = higher degree). DominanceSwabian: A measure constructed on the basis of the questionnaire. Positive values essentially mean that the participant uses Swabian more often than Standard German and feels more comfortable talking Swabian than Standard German. Negative values mean that Standard German is the dominant language. Values around 0 mean that the participant is equally at ease with Swabian and Standard German. Note that this is a continuous variables (i.e., 30 is more dominant in Swabian than 10). Task: Whether the numbers in the next column concern the participants’ performance on the flanker or on the Simon task. meanSpeedDifference: The participants’ performance on the cognitive task expressed in trials per second. Values closer to 0 are assumed to reflect greater cognitive control capacities. Poarch2018_wide.csv contains the following variables: Subject, Age, Sex, Education, DominanceSwabian: as before. Flanker: the participants’ meanSpeedDifference on the Flanker task, expressed in trials per second. Simon: the participants’ meanSpeedDifference on the Simon task, expressed in trials per second. The authors were interested in knowing whether “balanced bidialectals” (= DominanceSwabian near 0) show greater cognitive control than non-balanced bidialects. Your task: Draw one or more graphs with which to answer their research question. Also hand in the compiled HTML report. References "],["week-12-third-graded-assignment.html", "11 Week 12: Third graded assignment", " 11 Week 12: Third graded assignment For the final plotting assignment, your task is to visualise the results from a study by Gibson et al. (2017), Don’t underestimate the benefits of being misunderstood. (I hate the title, but the topic’s interesting, I think.) We’ll focus on just their first experiment. In this experiment, they investigated how native speakers of English interpret sentences such as “The mother gave the candle to the daughter” (with the recipient as a prepositional object (PO)) and “The mother gave the daughter the candle” (with the recipient as an indirect object; the so-called double-object construction (DO)). In the experiment, the participants heard implausible spoken sentences, such as The mother gave the daughter to the candle. The mother gave the candle the daughter. Interpreted literally, these sentences are semantically implausible. But if listeners have reasons to suspect that the linguistic signal has been corrupted (e.g., because of bad acoustic conditions or because their interlocutor doesn’t speak English well), they may tend to reinterpret such sentences more plausibly (i.e., The mother gave the daughter the candle and The mother gave the candle to the daughter). Gibson et al. investigated if such reinterpretation does indeed occur, and if DO constructions are more readily reinterpreted as PO constructions than vice versa (for theoretical reasons we needn’t concern ourselves with). To this end, each listener was assigned to one of two accent conditions: none vs. accent. In the “none” condition (sic.), the sentences were read in a North-American accent. In the “accent” condition they were read in either a Hindi or an Israeli accent. The sentences were recorded by two actors: Idan (Israeli and North-American) and Nezar (Hindi and North-American). So, to summarise: 1/4 of participants heard sentences recorded by Idan in an Israeli accent. 1/4 of participants heard sentences recorded by Idan in a North-American accent. 1/4 of participants heard sentences recorded by Nizar in a Hindi accent. 1/4 of participants heard sentences recorded by Nizar in a North-American accent. Each participant heard 10 implausible sentences per construction (DO or PO). Each sentence was followed by a comprehension question, the answer to which hinged on whether the listeners interpreted the sentence as a DO or PO sentence. The assumption is that listeners gave fewer correct responses when the sentences were read with a non-native accent, more so for DO sentences. Your task: Visualise these data to check whether this assumption is borne out. Hand in at most three graphs. Also hand in the compiled HTML report. I’ve prepared the data in three csv files. Depending on which graph(s) you’d like to draw, it’ll be easier to work with one file than with another. Gibson2017_dopo_jv.csv: The individual answers per participant. Because of data loss (see article), not all participants provided 10 responses. Gibson2017_dopo_perParticipant_long_jv.csv: The proportion of correct (i.e., literal) responses per construction per participant. There are two rows for each participant: one contains the proportion of correct responses to the DO construction; the other to the PO construction. Gibson2017_dopo_perParticipant_wide_jv.csv: The proportion of correct (i.e., literal) responses per construction per participant. There is just one row for each participant; the proportion of correct responses is shown in different columns depending on the construction. References "],["further-resources.html", "Further resources", " Further resources If you want to learn more about drawing graphs, check out Healy (2019) and Wilke (2019). Both books are freely available online: https://socviz.co/ https://serialmentor.com/dataviz/ References "],["common-error-sources-in-r.html", "Common error sources in R 11.1 object 'x' not found 11.2 could not find function 'x' 11.3 there is no package called 'x' 11.4 unexpected symbol 11.5 It doesn’t work and there isn’t even an error message 11.6 object of type 'closure' is not subsettable", " Common error sources in R 11.1 object 'x' not found You’re trying to call an object that hasn’t been loaded yet. This error is commonly caused by typos. Example: x &lt;- c(1, 4, 5) mean(X) ## Error in eval(expr, envir, enclos): object &#39;X&#39; not found You’ve created an object named x, but on the second line, you’re trying to call an object named X (capitalisation!). When in doubt, you can inspect the names of all objects currently loaded by running this command: ls() 11.2 could not find function 'x' You’re trying to run a function that doesn’t exist or that requires you to load an extension package first. Check whether you’ve typed in its name correctly. If it’s a function from an extension package, check if that package has been loaded. Example: ggplot(dat, aes(x = predictor, y = outcome)) + geom_point() ## Error in ggplot(dat, aes(x = predictor, y = outcome)): could not find function &quot;ggplot&quot; You need to load tidyverse (or ggplot2) before you can use the ggplot() function. 11.3 there is no package called 'x' You’re trying to load an extension package that hasn’t been installed yet. Example: library(ggjoy) ## Error in library(ggjoy): there is no package called &#39;ggjoy&#39; Install the package first: install.package(&quot;ggjoy&quot;) 11.4 unexpected symbol Check if you’ve forgotton a comma or bracket somewhere, or if you’ve used a comma or bracket that shouldn’t be there. Example: library(ggplot2) ggplot(data = iris aes(x = Sepal.Width, y = Sepal.Length)) + geom_point() ## Error: &lt;text&gt;:3:8: unexpected symbol ## 2: ggplot(data = iris ## 3: aes ## ^ This error is difficult to spot because the error message isn’t too helpful: There is a missing comma at the end of line 2, after iris. Example: ggplot(data = iris) aes(x = Sepal.Width, y = Sepal.Length)) + geom_point() ## Error: &lt;text&gt;:3:29: unexpected &#39;)&#39; ## 2: aes(x = Sepal.Width, ## 3: y = Sepal.Length)) ## ^ The bracket after iris should be a comma. ggplot(data = iris, aes(x = Sepal.Width, y = Sepal.Length))) + geom_point() ## Error: &lt;text&gt;:3:30: unexpected &#39;)&#39; ## 2: aes(x = Sepal.Width, ## 3: y = Sepal.Length))) ## ^ Superfluous bracket at the end of line 3. 11.5 It doesn’t work and there isn’t even an error message You’ve probably missed a bracket. Example: The following command won’t produce an error message, but no graphic either: > ggplot(data = iris, + aes(x = Sepal.Width, + y = Sepal.Length) + + geom_point() + In the console, you’ll see that there’s a new line starting with +. This means that the previous command hasn’t been completed yet: completed commands are followed by new lines starting with &gt;. In this particular case, the malfunction is caused by a missing bracket on the third line. The last bracket on this line closes the command aes(, but you need a second bracket to close the command ggplot(. Here is another example of code that doesn’t produce an error but that doesn’t produce the desired graphic either: ggplot(data = iris, aes(x = Sepal.Width, y = Sepal.Length)) geom_point() ## geom_point: na.rm = FALSE ## stat_identity: na.rm = FALSE ## position_identity Reason: the + on line 3 is missing. 11.6 object of type 'closure' is not subsettable Ah, the quintessential R error message. It can be generated in a number of ways, but you’re probably accidentally treating a function as a variable. Here’s an example: Let’s say you want to compute the mean of the numbers 200 and 800. One way to do so is like so: mean(c(200, 800)) ## [1] 500 However, if you’ve accidentally used square brackets, the error pops up: mean[c(200, 800)] ## Error in mean[c(200, 800)]: object of type &#39;closure&#39; is not subsettable What you’re actually doing with the square brackets is reading out two values of mean, namely the 200th and 800th value it’s holding. However, mean doesn’t hold any values; it’s a function, not a variable. To fix the problem, go through your code and check if you haven’t mixed up square and round brackets. "],["software-versions.html", "Software versions", " Software versions ## ─ Session info ───────────────────────────────────────────────────────────────── ## setting value ## version R version 4.3.1 (2023-06-16) ## os Ubuntu 22.04.3 LTS ## system x86_64, linux-gnu ## ui X11 ## language en_US ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Europe/Zurich ## date 2023-10-27 ## pandoc 3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown) ## ## ─ Packages ───────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## bit 4.0.5 2022-11-15 [1] CRAN (R 4.3.0) ## bit64 4.0.5 2020-08-30 [1] CRAN (R 4.3.0) ## bookdown 0.34 2023-05-09 [1] CRAN (R 4.3.1) ## bslib 0.4.2 2022-12-16 [1] CRAN (R 4.3.0) ## cachem 1.0.6 2021-08-19 [2] CRAN (R 4.2.0) ## callr 3.7.3 2022-11-02 [1] CRAN (R 4.3.1) ## cli 3.6.1 2023-03-23 [1] CRAN (R 4.3.0) ## colorspace 2.1-0 2023-01-23 [1] CRAN (R 4.3.0) ## crayon 1.5.2 2022-09-29 [1] CRAN (R 4.3.1) ## devtools 2.4.5 2022-10-11 [1] CRAN (R 4.3.1) ## digest 0.6.29 2021-12-01 [2] CRAN (R 4.2.0) ## dplyr * 1.1.2 2023-04-20 [1] CRAN (R 4.3.0) ## ellipsis 0.3.2 2021-04-29 [2] CRAN (R 4.2.0) ## evaluate 0.15 2022-02-18 [2] CRAN (R 4.2.0) ## fansi 1.0.4 2023-01-22 [1] CRAN (R 4.3.1) ## farver 2.1.1 2022-07-06 [1] CRAN (R 4.3.0) ## fastmap 1.1.0 2021-01-25 [2] CRAN (R 4.2.0) ## forcats * 1.0.0 2023-01-29 [1] CRAN (R 4.3.0) ## fs 1.5.2 2021-12-08 [2] CRAN (R 4.2.0) ## generics 0.1.3 2022-07-05 [1] CRAN (R 4.3.0) ## ggplot2 * 3.4.2 2023-04-03 [1] CRAN (R 4.3.0) ## glue 1.6.2 2022-02-24 [2] CRAN (R 4.2.0) ## gridExtra 2.3 2017-09-09 [1] CRAN (R 4.3.0) ## gtable 0.3.3 2023-03-21 [1] CRAN (R 4.3.0) ## here * 1.0.1 2020-12-13 [1] CRAN (R 4.3.1) ## highr 0.9 2021-04-16 [2] CRAN (R 4.2.0) ## hms 1.1.3 2023-03-21 [1] CRAN (R 4.3.0) ## htmltools 0.5.5 2023-03-23 [1] CRAN (R 4.3.0) ## htmlwidgets 1.6.2 2023-03-17 [1] CRAN (R 4.3.1) ## httpuv 1.6.11 2023-05-11 [1] CRAN (R 4.3.1) ## jquerylib 0.1.4 2021-04-26 [1] CRAN (R 4.3.0) ## jsonlite 1.8.7 2023-06-29 [1] CRAN (R 4.3.1) ## knitr 1.39 2022-04-26 [2] CRAN (R 4.2.0) ## labeling 0.4.2 2020-10-20 [1] CRAN (R 4.3.0) ## later 1.3.1 2023-05-02 [1] CRAN (R 4.3.1) ## lattice 0.21-8 2023-04-05 [4] CRAN (R 4.3.0) ## lifecycle 1.0.3 2022-10-07 [1] CRAN (R 4.3.0) ## lubridate * 1.9.2 2023-02-10 [1] CRAN (R 4.3.0) ## magrittr 2.0.3 2022-03-30 [1] CRAN (R 4.3.0) ## Matrix 1.6-0 2023-07-08 [4] CRAN (R 4.3.1) ## memoise 2.0.1 2021-11-26 [2] CRAN (R 4.2.0) ## mgcv 1.9-0 2023-07-11 [4] CRAN (R 4.3.1) ## mime 0.10 2021-02-13 [2] CRAN (R 4.0.2) ## miniUI 0.1.1.1 2018-05-18 [1] CRAN (R 4.3.1) ## munsell 0.5.0 2018-06-12 [1] CRAN (R 4.3.0) ## nlme 3.1-162 2023-01-31 [4] CRAN (R 4.2.2) ## pillar 1.9.0 2023-03-22 [1] CRAN (R 4.3.0) ## pkgbuild 1.4.2 2023-06-26 [1] CRAN (R 4.3.1) ## pkgconfig 2.0.3 2019-09-22 [2] CRAN (R 4.2.0) ## pkgload 1.3.2.1 2023-07-08 [1] CRAN (R 4.3.1) ## png 0.1-8 2022-11-29 [1] CRAN (R 4.3.0) ## prettyunits 1.1.1 2020-01-24 [2] CRAN (R 4.2.0) ## processx 3.8.2 2023-06-30 [1] CRAN (R 4.3.1) ## profvis 0.3.8 2023-05-02 [1] CRAN (R 4.3.1) ## promises 1.2.0.1 2021-02-11 [1] CRAN (R 4.3.1) ## ps 1.7.5 2023-04-18 [1] CRAN (R 4.3.1) ## purrr * 1.0.1 2023-01-10 [1] CRAN (R 4.3.0) ## R6 2.5.1 2021-08-19 [2] CRAN (R 4.2.0) ## Rcpp 1.0.11 2023-07-06 [1] CRAN (R 4.3.1) ## readr * 2.1.4 2023-02-10 [1] CRAN (R 4.3.0) ## remotes 2.4.2 2021-11-30 [2] CRAN (R 4.2.0) ## rlang 1.1.1 2023-04-28 [1] CRAN (R 4.3.0) ## rmarkdown 2.21 2023-03-26 [1] CRAN (R 4.3.0) ## rprojroot 2.0.3 2022-04-02 [2] CRAN (R 4.2.0) ## rstudioapi 0.14 2022-08-22 [1] CRAN (R 4.3.0) ## sass 0.4.6 2023-05-03 [1] CRAN (R 4.3.0) ## scales 1.2.1 2022-08-20 [1] CRAN (R 4.3.0) ## sessioninfo 1.2.2 2021-12-06 [2] CRAN (R 4.2.0) ## shiny 1.7.4.1 2023-07-06 [1] CRAN (R 4.3.1) ## stringi 1.7.12 2023-01-11 [1] CRAN (R 4.3.1) ## stringr * 1.5.0 2022-12-02 [1] CRAN (R 4.3.0) ## tibble * 3.2.1 2023-03-20 [1] CRAN (R 4.3.0) ## tidyr * 1.3.0 2023-01-24 [1] CRAN (R 4.3.0) ## tidyselect 1.2.0 2022-10-10 [1] CRAN (R 4.3.0) ## timechange 0.2.0 2023-01-11 [1] CRAN (R 4.3.0) ## tzdb 0.4.0 2023-05-12 [1] CRAN (R 4.3.0) ## urlchecker 1.0.1 2021-11-30 [1] CRAN (R 4.3.1) ## usethis 2.2.2 2023-07-06 [1] CRAN (R 4.3.1) ## utf8 1.2.3 2023-01-31 [1] CRAN (R 4.3.1) ## vctrs 0.6.3 2023-06-14 [1] CRAN (R 4.3.0) ## vroom 1.6.3 2023-04-28 [1] CRAN (R 4.3.0) ## withr 2.5.0 2022-03-03 [2] CRAN (R 4.2.0) ## xfun 0.39 2023-04-20 [1] CRAN (R 4.3.0) ## xtable 1.8-4 2019-04-21 [1] CRAN (R 4.3.1) ## yaml 2.3.5 2022-02-21 [2] CRAN (R 4.2.0) ## ## [1] /home/jan/R/x86_64-pc-linux-gnu-library/4.3 ## [2] /usr/local/lib/R/site-library ## [3] /usr/lib/R/site-library ## [4] /usr/lib/R/library ## ## ──────────────────────────────────────────────────────────────────────────────── "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
