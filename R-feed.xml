<?xml version="1.0" encoding="utf-8"?>
    <feed xmlns="http://www.w3.org/2005/Atom">
        <link href="http://janhove.github.io/tag/R/feed.xml" rel="self" type="application/atom+xml" />
        <link href="http://janhove.github.io/" rel="alternate" type="text/html" />
        <updated>2016-11-16T16:17:48+01:00</updated>
        <id>http://janhove.github.io/</id>
        <title>janhove.github.io: R-related posts</title>
        <subtitle>A blog on statistics and research design in applied linguistics and bilingualism/multilingualism research.</subtitle>
        <author>
            <name>Jan Vanhove</name>
        </author>
              
        <entry>
            <title>Common-language effect sizes</title>
            <link href="http://janhove.github.io/reporting/2016/11/16/common-language-effect-sizes/" />
            <published>2016-11-16T00:00:00+01:00</published>
            <updated>2016-11-16T00:00:00+01:00</updated>
            <id>http://janhove.github.io/reporting/2016/11/16/common-language-effect-sizes/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2016/11/16/common-language-effect-sizes/">&lt;p&gt;The goal of this blog post is to share with you a simple &lt;code&gt;R&lt;/code&gt; function
that may help you to better communicate the extent to which two groups differ and overlap
by computing &lt;em&gt;common-language effect sizes&lt;/em&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;what-is-the-common-language-effect-size&quot;&gt;What is the ‘common-language effect size’?&lt;/h3&gt;
&lt;p&gt;In 1992, &lt;a href=&quot;http://psycnet.apa.org/doi/10.1037/0033-2909.111.2.361&quot;&gt;McGraw and Wong&lt;/a&gt; introduced the common-language effect size,
which they defined as&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;the probability that a score sampled at random from
one distribution will be greater than a score sampled from
some other distribution.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For instance, if you have scores on an English reading comprehension task for
both French- and German-speaking learners, you can compute
the probability that a randomly chosen French-speaking learner
will have a higher score than a randomly chosen German-speaking learner.
This gives you an idea of how much the groups’ scores overlap,
and the number can more easily be communicated to an audience that
has no firm notion of what quantiles are 
or of what standardised effect sizes such as &lt;em&gt;d = 0.3&lt;/em&gt; mean.&lt;/p&gt;

&lt;h3 id=&quot;computing-common-language-effect-sizes-in-r&quot;&gt;Computing common-language effect sizes in R&lt;/h3&gt;
&lt;p&gt;Below I first generate some data:
40 data points in a group creatively called &lt;code&gt;A&lt;/code&gt; vs. 30 data points in group &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Generate data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;16-11-2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Outcome&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rbeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# 40 observations in A
&lt;/span&gt;                             &lt;span class=&quot;n&quot;&gt;rbeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# 30 in B
&lt;/span&gt;                 &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A couple of boxplots to show the spread and central tendencies:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-11-16-common-language-effect-sizes/unnamed-chunk-194-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And the key summary statistics:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   Group Mean Standard_Deviation
## 1     A 0.24              0.084
## 2     B 0.30              0.172&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On the basis of the group means and standard deviations, McGraw and Wong’s common-language
effect size can be computed as follows:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;pnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.24&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.084&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.172&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower.tail&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.38&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I.e., there’s a 38% chance that if you put an observation from Group A and one from Group B together at random, the one from Group A will be greater.&lt;/p&gt;

&lt;p&gt;Strictly speaking, McGraw and Wong’s method assumes normally distributed, continuous data.
While they point out that their measure is quite robust with respect to this assumption,
you can use a brute-force method that doesn’t make this assumption to see 
if that yields different results.&lt;/p&gt;

&lt;p&gt;On http://janhove.github.io/RCode/CommonLanguageEffectSizes.R, I provide a function, &lt;code&gt;cles.fnc()&lt;/code&gt;,
that randomly pairs observations from the two groups a large number of times
and checks how often the observation sampled randomly from the first group is greater
than the one sampled randomly from the second group.
Ties are also taken into account.&lt;/p&gt;

&lt;p&gt;Here’s how the &lt;code&gt;cls.fnc()&lt;/code&gt; function works:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Read in the function
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/RCode/CommonLanguageEffectSizes.R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Set the number of random samples (runs);
# the variable you want to compare between the groups,
# the group name,
# the baseline level,
# and the dataset:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cles.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1e4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Outcome&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;baseline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Common-language effect size:
## 
## The probability that a random Outcome observation from group A
## is higher/larger than a random Outcome observation from the other group(s):
## 
##     Algebraic method:   0.38
##     Brute-force method: 0.41
## 
## (brute-force method based on 10000 runs)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The results for both methods aren’t identical (38% vs. 41%), but they’re in the same ballpark.
This is more often the case than not.&lt;/p&gt;

&lt;p&gt;You can turn off the output by setting the parameter &lt;code&gt;print&lt;/code&gt; to &lt;code&gt;FALSE&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;## (not run)
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cles.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1e4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Outcome&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;baseline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can also extract three pieces of information from the &lt;code&gt;cles&lt;/code&gt; object if you want to pass them on to other functions:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;cles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;algebraic&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;McGraw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Wong&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.38&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;cles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;brute&lt;/span&gt;     &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;brute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;force&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.41&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;cles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;      &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randomly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constructed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AB&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 10000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;an-example-with-non-overlapping-distributions&quot;&gt;An example with non-overlapping distributions&lt;/h3&gt;
&lt;p&gt;The code below generates a dataset with two non-overlapping groups.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Generate data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;16-11-2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Outcome&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Boxplots:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-11-16-common-language-effect-sizes/unnamed-chunk-201-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;McGraw &amp;amp; Wong’s (1992) method suggests that there’s a 6% chance
that a random observation in A will be higher than one in B.
This may well be true at the population level, but it’s clearly not true at the sample level.
The brute-force method pegs this probability at 0%, which may be wrong at the population level,
but it’s clearly correct at the sample level.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;cles.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1e4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Outcome&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;baseline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Common-language effect size:
## 
## The probability that a random Outcome observation from group A
## is higher/larger than a random Outcome observation from the other group(s):
## 
##     Algebraic method:   0.06
##     Brute-force method: 0
## 
## (brute-force method based on 10000 runs)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## $algebraic
## [1] 0.061
## 
## $brute
## [1] 0
## 
## $runs
## [1] 10000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;for-use-with-more-complex-datasets&quot;&gt;For use with more complex datasets&lt;/h3&gt;
&lt;p&gt;Let’s say you have data from a longitudinal study 
in which you collected data for Groups A and B at Times 1, 2 and 3,
and you want to compare the groups at each time:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Generate data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;16-11-2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;Outcome&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The boxplots:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-11-16-common-language-effect-sizes/unnamed-chunk-204-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using the &lt;code&gt;by()&lt;/code&gt; function, you can run &lt;code&gt;cles.fnc()&lt;/code&gt; separately for each &lt;code&gt;Time&lt;/code&gt;.
For more complex datasets, you can include more variables in the &lt;code&gt;INDICES&lt;/code&gt; list.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;cles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# select dataframe df
&lt;/span&gt;             &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# group dataframe df
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;INDICES&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# by Time
&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# and run cles.fnc() within each group
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;FUN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cles.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1e4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Outcome&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cles&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Time: 1
## $algebraic
## [1] 0.45
## 
## $brute
## [1] 0.55
## 
## $runs
## [1] 10000
## 
## -------------------------------------------------------- 
## Time: 2
## $algebraic
## [1] 0.46
## 
## $brute
## [1] 0.51
## 
## $runs
## [1] 10000
## 
## -------------------------------------------------------- 
## Time: 3
## $algebraic
## [1] 0.75
## 
## $brute
## [1] 0.77
## 
## $runs
## [1] 10000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
                          
        <entry>
            <title>Tutorial: Drawing a dot plot</title>
            <link href="http://janhove.github.io/reporting/2016/08/30/drawing-a-dotplot/" />
            <published>2016-08-30T00:00:00+02:00</published>
            <updated>2016-08-30T00:00:00+02:00</updated>
            <id>http://janhove.github.io/reporting/2016/08/30/drawing-a-dotplot/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2016/08/30/drawing-a-dotplot/">&lt;p&gt;In the fourth tutorial on drawing useful plots with &lt;code&gt;ggplot2&lt;/code&gt;, we’re taking a closer look at &lt;strong&gt;dot plots&lt;/strong&gt; – a useful and more flexible alternative to bar and pie charts.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;whats-a-dot-plot&quot;&gt;What’s a dot plot?&lt;/h3&gt;
&lt;p&gt;The three panels below show a same data in a pie chart, a bar chart and a dot plot.
For data like these, the bar chart and the dot plot
allow us to compare the sales of different kinds of pie about equally well.
The dot plot has a higher &lt;a href=&quot;http://www.infovis-wiki.net/index.php/Data-Ink_Ratio&quot;&gt;data-ink ratio&lt;/a&gt;, but I don’t think that’s too decisive a factor.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-30-drawing-a-dotplot/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where dot plots excel is when you want to display 
data with more than two dimensions.
In the plots above, the data had two dimensions: the kind of pie and the proportion of sales.
In the dot plot below, you find an additional dimension: year (2015 vs. 2016).
You couldn’t display this additional dimension in a single pie chart,
and you’d need side-by-side bars to do it in a bar chart, which usually looks cluttered.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-30-drawing-a-dotplot/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tutorial-drawing-a-dotchart-in-ggplot2&quot;&gt;Tutorial: Drawing a dotchart in ggplot2&lt;/h3&gt;

&lt;h4 id=&quot;what-youll-need&quot;&gt;What you’ll need&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;The free program R, the graphical user interface RStudio, and the add-on package &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A dataset. The data we’ll use were collected in a project on language transfer (&lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/GermanArticleChoices.csv&quot;&gt;download&lt;/a&gt;).
About 200 native speakers of Dutch from The Netherlands and Belgium (&lt;code&gt;Country&lt;/code&gt;)
were asked to pick a German gender-marked definite article (&lt;em&gt;der&lt;/em&gt;, &lt;em&gt;die&lt;/em&gt; or &lt;em&gt;das&lt;/em&gt;) for 44 German nouns (&lt;code&gt;Stimulus&lt;/code&gt;).
These nouns all had cognates in Dutch (&lt;code&gt;DutchCognate&lt;/code&gt;), which had either common or neuter gender (&lt;code&gt;DutchGender&lt;/code&gt;).
The expectation is that Dutch speakers from either country will tend to assign the neuter German article (&lt;em&gt;das&lt;/em&gt;)
to German words with neuter Dutch cognates compared to words with common-gender Dutch cognates.
The dataset also lists the German words’ actual gender (&lt;code&gt;GermanGender&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;preliminaries&quot;&gt;Preliminaries&lt;/h4&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Read in data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/GermanArticleChoices.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Load the ggplot2 package
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I don’t like &lt;code&gt;ggplot2&lt;/code&gt;’s default grey background, so let’s change the default theme to black and white:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Set black and white theme, font size 16
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;a-first-attempt&quot;&gt;A first attempt&lt;/h4&gt;
&lt;p&gt;Let’s plot the proportion of neuter article (&lt;em&gt;das&lt;/em&gt;) choices by both the Belgian and the Dutch participants for each German noun.
Dot plots show the numeric information along the &lt;em&gt;x&lt;/em&gt;-axis
and the categorical information (labels) along the &lt;em&gt;y&lt;/em&gt;-axis,
so we specify those mappings in second and third lines.
In the fourth line, we specify that the data points need to be plotted as points or dots,
and lastly we customise the axis labels.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                 &lt;span class=&quot;c1&quot;&gt;# name of the dataset
&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NeuterResponses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# x-variable
&lt;/span&gt;           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stimulus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# y-variable 
&lt;/span&gt;           &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# different symbols by Country
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# plot as dots/points
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Proportion of neuter (das) choices&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;German noun&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-30-drawing-a-dotplot/unnamed-chunk-6-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;facetting&quot;&gt;Facetting&lt;/h4&gt;
&lt;p&gt;The main comparison is between German words that have neuter Dutch cognates and those that have common-gender Dutch cognates.
To highlight this comparison, we can plot the data for both word categories in different panels.
Using the &lt;code&gt;facet_grid&lt;/code&gt; layer, we can specify that the words with common and with neuter Dutch gender are to be plotted on different rows of a grid (&lt;code&gt;x ~ .&lt;/code&gt;). 
(&lt;code&gt;. ~ x&lt;/code&gt; would’ve plotted them in different columns, but having them in different rows but the same column makes for an easier comparison.)&lt;/p&gt;

&lt;p&gt;Setting the &lt;code&gt;scales&lt;/code&gt; and &lt;code&gt;space&lt;/code&gt; arguments to &lt;code&gt;&quot;free_y&quot;&lt;/code&gt; ensures that items for which data is available in only one panel aren’t shown in the other panels as well (&lt;code&gt;scales&lt;/code&gt;) and that the size of the panels is proportionate to the number of items in them (&lt;code&gt;space&lt;/code&gt;).
If you set these arguments to &lt;code&gt;&quot;fixed&quot;&lt;/code&gt;, you’ll see what I mean.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NeuterResponses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stimulus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Proportion of neuter (das) choices&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;German noun&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DutchGender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# different vertical panels
&lt;/span&gt;             &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# flexible y-axis
&lt;/span&gt;             &lt;span class=&quot;n&quot;&gt;space&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-30-drawing-a-dotplot/unnamed-chunk-7-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This plot strongly suggests that the gender of the German words’ Dutch cognates has a major effect
on how often Dutch speakers pick &lt;em&gt;das&lt;/em&gt; as their article: with the exception of one word, &lt;em&gt;Boot&lt;/em&gt;,
the ranges in the two panels don’t even overlap.&lt;/p&gt;

&lt;p&gt;However, the German words are ordered alphabetically.
While we’re at it, we might as well sort them more meaningfully – 
for instance, according to the average proportion of &lt;em&gt;das&lt;/em&gt; responses per word.
Additionally, I don’t find the default filled circle and triangle symbols that represent the Belgian and Dutch responses very distinctive, so we’ll change these, too.&lt;/p&gt;

&lt;h4 id=&quot;sorting-the-items-by-their-average-value&quot;&gt;Sorting the items by their average value&lt;/h4&gt;
&lt;p&gt;In my &lt;a href=&quot;/analysis/2016/08/18/ordering-factor-levels&quot;&gt;previous post&lt;/a&gt;, I introduced a custom function
for sorting the levels of a factor according to
the average value of another variable per level.
Here we use this function to sort the levels of &lt;code&gt;Stimulus&lt;/code&gt;
according to their average value of &lt;code&gt;NeuterResponses&lt;/code&gt;.
We also use another custom function to put the words with neuter cognates in the top instead of in the bottom panel.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Download sorting function
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://raw.githubusercontent.com/janhove/janhove.github.io/master/RCode/sortLvls.R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Sort Stimulus by NeuterResponses
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Stimulus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvlsByVar.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Stimulus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NeuterResponses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Put DutchGender == neuter above DutchGender == common
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DutchGender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvls.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DutchGender&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To change the default symbols, we use &lt;code&gt;scale_shape_manual()&lt;/code&gt;.
For black and white plots, I prefer empty circles and crosses,
which are known internally as symbols 1 and 3, respectively:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NeuterResponses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stimulus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Proportion of neuter (das) choices&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;German noun&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_shape_manual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# custom symbols
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;facet_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DutchGender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;space&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-30-drawing-a-dotplot/unnamed-chunk-9-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The difference between responses to words with neuter cognates and to those with common-gender cognates is now particularly clear.
Nevertheless, there is a substantial degree of variation between the items, particularly in to words with neuter cognates.
Aficionados of the German language may’ve noticed, however, that the top words within each panel all have neuter gender in German, i.e., the article &lt;em&gt;das&lt;/em&gt; is the correct choice for these words.
The bottom words, by contrast, all have masculine or feminine gender in German.
As this factor – whether the word actually is neuter in German or not – can straightforwardly account for some variation within each panel due to people having learnt the correct gender, 
it makes sense to include this information in the plot, too.&lt;/p&gt;

&lt;h4 id=&quot;adding-another-facetting-variable&quot;&gt;Adding another facetting variable&lt;/h4&gt;
&lt;p&gt;First we create a new variable that specifies whether the German word actually has neuter gender or not.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GermanNeuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GermanGender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;neuter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;TRUE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;FALSE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then we add this new variable to the &lt;code&gt;facet_grid&lt;/code&gt; layer.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NeuterResponses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stimulus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Proportion of neuter (das) choices&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;German noun&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_shape_manual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DutchGender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GermanNeuter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# another facetting variable
&lt;/span&gt;             &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;space&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-30-drawing-a-dotplot/unnamed-chunk-11-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Adding this additional facetting variable may be useful for making it immediately clear
to the casual reader that the study featured a mixture of both congruent (neuter–neuter and non-neuter–common) and incongruent (neuter–common and non-neuter–neuter) cognates&lt;/p&gt;

&lt;p&gt;Additionally, it shows that while the Dutch participants consistently and correctly choose more neuter responses
than the Belgians for neuter–neuter cognates,
they don’t pick the correct neuter article more often for neuter–common cognates,
nor do they choose the neuter article less often than the Belgians for non-neuter words. 
To me, this suggests that the actual knowledge of German gender didn’t
greatly differ between the Belgian and the Dutch participants.&lt;/p&gt;

&lt;p&gt;Lastly, the word standing out in all of this is &lt;em&gt;Boot&lt;/em&gt;,
for which most participants correctly picked neuter &lt;em&gt;das&lt;/em&gt; even though
its highly transparent cognate in Dutch, &lt;em&gt;boot&lt;/em&gt;, is common-gender.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/en/a/a3/Das_boot_ver1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;finishing-touches-facet-labels&quot;&gt;Finishing touches: facet labels&lt;/h4&gt;
&lt;p&gt;Finally, as a courtesy to the reader, we’ll give the facet labels more transparent titles.
For this, we need to map the current default labels to more descriptive labels using &lt;a href=&quot;http://docs.ggplot2.org/current/as_labeller.html&quot;&gt;&lt;code&gt;as_labeller()&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_labeller&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`common`&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Du.: common&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;sb&quot;&gt;`neuter`&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Du.: neuter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;sb&quot;&gt;`TRUE`&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Gm.: neuter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;sb&quot;&gt;`FALSE`&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Gm.: non-neuter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then, we add these labels to the &lt;code&gt;facet_grid()&lt;/code&gt; call.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;germart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NeuterResponses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Stimulus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Country&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Proportion of neuter (das) choices&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;German noun&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_shape_manual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DutchGender&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GermanNeuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;space&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;free_y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;labeller&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-30-drawing-a-dotplot/unnamed-chunk-13-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;
</content>
        </entry>
                
        <entry>
            <title>R tip: Ordering factor levels more easily</title>
            <link href="http://janhove.github.io/analysis/2016/08/18/ordering-factor-levels/" />
            <published>2016-08-18T00:00:00+02:00</published>
            <updated>2016-08-18T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2016/08/18/ordering-factor-levels/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2016/08/18/ordering-factor-levels/">&lt;p&gt;By default, &lt;code&gt;R&lt;/code&gt; sorts the levels of a factor alphabetically.
When drawing graphs, this results in &lt;a href=&quot;http://dx.doi.org/10.1080/09332480.2001.10542269&quot;&gt;‘Alabama First’&lt;/a&gt; graphs,
and it’s usually better to sort the elements of a graph by more meaningful principles than alphabetical order.
This post illustrates three convenience functions you can use to sort factor levels in &lt;code&gt;R&lt;/code&gt;
according to another covariate, their frequency of occurrence, or manually.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;First you’ll need the &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;magrittr&lt;/code&gt; packages:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dplyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;magrittr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can download the convenience functions from my &lt;a href=&quot;https://github.com/janhove/janhove.github.io/blob/master/RCode/sortLvls.R&quot;&gt;Github page&lt;/a&gt; or read them in directly into &lt;code&gt;R&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://raw.githubusercontent.com/janhove/janhove.github.io/master/RCode/sortLvls.R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;sorting-factor-levels-by-another-variable&quot;&gt;Sorting factor levels by another variable&lt;/h3&gt;
&lt;p&gt;The code below creates an example dataset with a factor and a covariate:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Load packages
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;magrittr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate same data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;18-08-2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create data frame
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Current order of factor levels (alphabetically)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Covariate mean per factor level
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## # A tibble: 5 x 2
##   factorBefore mean(covariate)
##         &amp;lt;fctr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1            a        8.039675
## 2            b       36.881525
## 3            c       45.005219
## 4            d       71.575448
## 5            e       41.889307&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;What we want is to sort the levels of the factor by the covariate mean per factor level (i.e., a-b-e-c-d).
The function &lt;code&gt;sortLvlsByVar.fnc&lt;/code&gt; accomplishes this:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Reorder
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvlsByVar.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# New order of factor levels
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] &quot;a&quot; &quot;b&quot; &quot;e&quot; &quot;c&quot; &quot;d&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;By setting the &lt;code&gt;ascending&lt;/code&gt; parameter to &lt;code&gt;FALSE&lt;/code&gt;, the factor levels are sorting descendingly according to the covariate mean:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Reorder descendingly
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvlsByVar.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] &quot;d&quot; &quot;c&quot; &quot;e&quot; &quot;b&quot; &quot;a&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;How this looks like when graphed:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# &#39;install.packages(&quot;cowplot&quot;)&#39; if you haven&#39;t already
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cowplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Alphabetical order
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Sorted ascendingly
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Sorted descendingly
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-18-ordering-factor-levels/unnamed-chunk-6-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can change the &lt;code&gt;R&lt;/code&gt; code from the Github page so that the levels are sorted by another summary statistics, e.g., the covariate median per factor level.&lt;/p&gt;

&lt;h3 id=&quot;sorting-factor-levels-by-their-frequency-of-occurrence&quot;&gt;Sorting factor levels by their frequency of occurrence&lt;/h3&gt;
&lt;p&gt;Again we’ll first create some data:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;107&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;107&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
##   a   b   c   d   e 
##   7   3  80  15 107&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We want to order these factor levels by their frequency of occurrence in the dataset (i.e., b-a-d-c-e).
&lt;code&gt;sortLvlsByN.fnc()&lt;/code&gt; accomplishes this:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvlsByN.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
##   b   a   d   c   e 
##   3   7  15  80 107&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Or descendingly:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvlsByN.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
##   e   c   d   a   b 
## 107  80  15   7   3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;When plotted:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;varwidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;varwidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;varwidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-08-18-ordering-factor-levels/unnamed-chunk-10-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;customising-the-order-of-factor-levels&quot;&gt;Customising the order of factor levels&lt;/h3&gt;
&lt;p&gt;If you want to put the factor levels in a custom order, you can use the &lt;code&gt;sortLvls.fnc()&lt;/code&gt; function.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Create data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;letters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let’s say we, for some reason, want to put the current 5th level (e) first, the current 3rd level (c) second, the 4th 3rd, the 4th 2nd and the 1st last:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvls.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] &quot;e&quot; &quot;c&quot; &quot;d&quot; &quot;b&quot; &quot;a&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You can also just specify which factor levels need to go up front; the order of the other ones stays the same:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Put the current 3rd and 2nd in front; leave the rest as they were:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sortLvls.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorBefore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;factorAfter2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] &quot;c&quot; &quot;b&quot; &quot;a&quot; &quot;d&quot; &quot;e&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
                
        <entry>
            <title>Classifying second-language learners as native- or non-nativelike: Don&#39;t neglect classification error rates</title>
            <link href="http://janhove.github.io/analysis/2016/07/05/classification-algorithms/" />
            <published>2016-07-05T00:00:00+02:00</published>
            <updated>2016-07-05T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2016/07/05/classification-algorithms/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2016/07/05/classification-algorithms/">&lt;p&gt;I’d promised to write another installment on drawing &lt;a href=&quot;/reporting/2016/06/21/drawing-a-boxplot&quot;&gt;graphs&lt;/a&gt;,
but instead I’m going to write about something that 
I had to exclude, for reasons of space, 
from a recently published &lt;a href=&quot;http://janhove.github.io/publications.html#section&quot;&gt;book chapter&lt;/a&gt; 
on age effects in second language (L2) acquisition:
&lt;strong&gt;classifying&lt;/strong&gt; observations (e.g., L2 learners) and &lt;strong&gt;estimating error rates&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I’m going to illustrate the usefulness of classification algorithms
for addressing some problems in L2 acquisition research,
but my broader aim is to show that there’s more to statistics than running significance tests
and to encourage you to explore—even if superficially—what else is out there.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;background-classifying-l2-learners-as-native--or-non-nativelike&quot;&gt;Background: classifying L2 learners as native- or non-nativelike&lt;/h3&gt;
&lt;p&gt;In the field of second language acquisition, there are a couple of theories that predict
that L2 learners who begin learning the L2 after a certain age will never be
‘native-like’ in the L2. The ‘certain age’ differs between studies, and
what the prediction boils down to in some versions is that &lt;em&gt;no&lt;/em&gt; L2 learner will ever be fully ‘native-like’ in the L2.&lt;/p&gt;

&lt;p&gt;I, for one, don’t think that ‘nativelikeness’ is a useful scientific construct, 
but that doesn’t matter for this post: Some researchers obviously do consider it useful,
and for them the question is how they can test their prediction.&lt;/p&gt;

&lt;p&gt;Researchers interested in nativelikeness 
usually administer a battery of linguistic tasks to a sample of L2 learners
as well as to a ‘control’ sample of L1 speakers.
On the basis of the L1 speakers’ results, they then define a &lt;strong&gt;nativelikeness criterion&lt;/strong&gt;—an interval
that is considered typical of L1 speakers’ performance.
Common intervals are (a) the L1 speakers’ mean ± two standard deviations or (b) the range of the L1 speakers’ results.
L2 speakers whose results fall outside this interval are considered non-nativelike,
and the goal of the study is often to establish from which age of L2 acquisition onwards 
no nativelike L2 speakers can be found.&lt;/p&gt;

&lt;h3 id=&quot;the-problem-misclassifications&quot;&gt;The problem: Misclassifications&lt;/h3&gt;
&lt;p&gt;The procedure I’ve just sketched is pretty common but it’s fundamentally &lt;strong&gt;flawed&lt;/strong&gt;.
One problem with it is that it may misclassify non-nativelike speakers as nativelike.
I think most researchers are aware of this problem, 
as they sometimes seem to imply that fewer L2 learners would’ve qualified as nativelike 
if only more and more reliable data were available.
This may well be true.
But the other side of the coin is rarely considered: 
&lt;em&gt;not all L1 speakers may pass the nativelikeness criterion either!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To my knowledge, no paper in L2 acquisition provides an &lt;strong&gt;error-rate estimate&lt;/strong&gt;,
i.e., a quantitative appraisal of how well the nativelikeness criterion would
distinguish between L2 and L1 speakers &lt;em&gt;other than those used for defining the criterion&lt;/em&gt;.
Nonetheless, I think this is precisely what is needed if we are to sensibly interpret such studies.
Let me illustrate.&lt;/p&gt;

&lt;h3 id=&quot;illustration&quot;&gt;Illustration&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://dx.doi.org/10.1111/j.1467-9922.2009.00507.x&quot;&gt;Abrahamsson and Hyltenstam&lt;/a&gt; 
subjected 41 advanced Spanish-speaking learners of L2 Swedish 
as well as 15 native speakers of Swedish to a battery of linguistic tasks.
From these tasks, 14 variables were extracted; the details don’t matter much here, 
but you can look them up in the paper (see Table 6 on page 280).
Abrahamsson and Hyltenstam defined the minimum criterion of nativelikeness as the lowest native-speaker result on each measure,
but I’m going to define it as the range of native-speaker results (i.e., between lowest and highest; it doesn’t really matter much).&lt;/p&gt;

&lt;p&gt;The original raw data aren’t available, but I’ve simulated some placeholder data to illustrate my point.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;(For the 15 native speakers, I simulated 14 variables from normal distributions with the same mean as in Abrahamsson &amp;amp; Hyltenstam’s Table 6; the standard deviation was estimated by taking the range and dividing it by 4. For the 41 non-native speakers, I simulated the same 14 variables but with generally lower means and larger standard deviations.
None of the variables were systematically correlated.
This simulation obviously represent a huge simplification; life would be easier if people &lt;a href=&quot;/reporting/2015/12/14/perks-data-sharing&quot;&gt;put their data online&lt;/a&gt;.)&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Using these simulated data, we can compute the range of the native-speaker results.
Don’t be intimidated by the R code, the comments say what it accomplishes, which is really all you need to know.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;## Read in data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/nativelikeness.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## &#39;data.frame&#39;:	56 obs. of  15 variables:
##  $ Pred1 : int  18 15 17 13 22 21 15 20 18 20 ...
##  $ Pred2 : int  12 17 14 16 16 12 19 13 22 14 ...
##  $ Pred3 : int  18 11 16 15 20 14 20 18 18 14 ...
##  $ Pred4 : int  -5 11 0 -3 2 -9 2 7 16 6 ...
##  $ Pred5 : int  19 11 21 8 20 24 13 9 14 19 ...
##  $ Pred6 : int  29 22 21 24 19 24 28 27 19 21 ...
##  $ Pred7 : int  -10 -8 -5 -9 -8 -6 -8 -7 -4 -2 ...
##  $ Pred8 : int  16 15 16 17 16 17 17 16 16 15 ...
##  $ Pred9 : int  73 74 70 64 70 72 64 76 63 63 ...
##  $ Pred10: int  71 70 74 67 73 65 73 66 72 66 ...
##  $ Pred11: int  7852 6977 7246 7768 8106 8457 7680 8156 7672 8417 ...
##  $ Pred12: int  38 34 35 33 36 35 36 37 33 36 ...
##  $ Pred13: int  45 41 45 42 46 40 36 38 39 48 ...
##  $ Pred14: int  41 40 36 36 40 41 41 44 38 36 ...
##  $ Class : Factor w/ 2 levels &quot;L1 speaker&quot;,&quot;L2 speaker&quot;: 1 1 1 1 1 1 1 1 1 1 ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;## Load packages
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;magrittr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# for piping (%&amp;gt;% below)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# for working with dataframes
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Retain L1 speakers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;L1 speaker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## Compute minimum and maximum for numeric data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;summarise_if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;summarise_if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can then take a look at the L2 speakers’ results and filter out the L2 speakers
whose results aren’t all within the native speakers’ range:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;## Retain L2 speakers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat.L2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;L2 speaker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## Retain only L2 speakers whose results lie within L1 speakers&#39; range
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat.nativelikeL2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat.L2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat.nativelikeL2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Sure enough, none of the L2 learners classify as nativelike. 
With more realistic data, a handful probably would have, cf. Abrahamsson &amp;amp; Hyltenstam’s results.&lt;/p&gt;

&lt;p&gt;By contrast, and quite obviously, all fifteen native speakers are classified as nativelike:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 15&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This comes as no surprise: the nativelikeness criterion was based on these speakers’ scores,
so of course they should pass it with flying colours.&lt;/p&gt;

&lt;p&gt;But what happens when we test a new sample of native speakers &lt;em&gt;using the old nativelikeness criterion&lt;/em&gt;?
I simulated data for another 10,000 native speakers using the same procedure I used to create the first 15 native speakers’ data.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;## Read in data for *new* L1 speakers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/new_nativelikeness.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## &#39;data.frame&#39;:	10000 obs. of  14 variables:
##  $ Pred1 : int  14 15 21 17 17 18 18 17 23 18 ...
##  $ Pred2 : int  14 18 16 12 16 15 15 10 15 15 ...
##  $ Pred3 : int  17 18 14 16 23 13 20 21 22 21 ...
##  $ Pred4 : int  1 21 -17 3 -2 1 7 0 -1 16 ...
##  $ Pred5 : int  23 15 14 12 11 15 6 14 17 20 ...
##  $ Pred6 : int  24 24 26 26 26 29 17 29 24 25 ...
##  $ Pred7 : int  -10 -6 -8 -6 -10 -3 -6 -8 -6 -9 ...
##  $ Pred8 : int  16 13 15 14 17 17 15 14 18 16 ...
##  $ Pred9 : int  64 77 69 64 66 73 67 70 71 66 ...
##  $ Pred10: int  67 73 70 63 74 74 75 62 66 75 ...
##  $ Pred11: int  7159 8098 8344 7113 7142 7808 7388 8062 8124 7864 ...
##  $ Pred12: int  38 32 28 32 38 32 39 38 35 31 ...
##  $ Pred13: int  41 42 44 49 40 37 44 47 43 52 ...
##  $ Pred14: int  36 38 38 40 36 45 41 40 43 39 ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;## Retain only participants whose results lie within *original* L1 speakers&#39; range
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new.L1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pred14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pred14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 1048&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Only 1048 of the 10,000 new native speakers pass the nativelikeness criterion!
And these 10,000 new native speakers were sampled from the &lt;em&gt;exact same&lt;/em&gt; population as the 
fifteen speakers used to establish the nativelikeness criterion—factors that would matter in
real life such as social status, age, region, linguistic background, and what not don’t matter here;
these would only make matters worse (see this &lt;a href=&quot;http://dare.uva.nl/document/2/148989&quot;&gt;paper&lt;/a&gt; on the selection of native-speaker controls by Sible Andringa).&lt;/p&gt;

&lt;p&gt;Clearly, &lt;strong&gt;the finding that none of the L2 speakers are classified as nativelike carries considerably less weight now that we know that most L1 speakers wouldn’t have, either&lt;/strong&gt;.
Such information about the error rate associated with the nativelikeness criterion is therefore
crucial to properly interpret studies relying on such a criterion.
In practice, the bias against being classified as nativelike may not be huge as in this simulated example, but without an error-rate estimate (or access to the raw data), we’ve no way of knowing.&lt;/p&gt;

&lt;h3 id=&quot;estimating-error-rates-using-classification-algorithms&quot;&gt;Estimating error rates using classification algorithms&lt;/h3&gt;
&lt;p&gt;If researchers want to classify L2 learners as nativelike or non-nativelike
and sensibly interpret their results,
I suggest they stop defining nativelikeness criteria as intervals based on native speakers’ scores.
Instead, they can turn to tools developed in a field specialised in such matters: &lt;strong&gt;machine learning&lt;/strong&gt;, or &lt;strong&gt;predictive modelling&lt;/strong&gt;.
There’s an astounding number of algorithms out there
that were developed for taking a set of predictor variables (e.g., task scores) 
on the one hand and a
set of class labels (e.g., &lt;em&gt;L1 speaker&lt;/em&gt; vs. &lt;em&gt;L2 speaker&lt;/em&gt;) on the other hand,
deriving a classification model from these data,
and estimating the error rate of the classifications.&lt;/p&gt;

&lt;p&gt;I won’t provide a detailed introduction—Kuhn &amp;amp; Johnson’s &lt;a href=&quot;http://appliedpredictivemodeling.com/&quot;&gt;&lt;em&gt;Applied Predictive Modeling&lt;/em&gt;&lt;/a&gt; seems excellent—but I’ll just illustrate one such classification algorithm, &lt;strong&gt;random forests&lt;/strong&gt;.
In fact, the precise workings of this algorithm, which was developed in 2001 by Leo Breiman, needn’t really concern us here—you can read about them &lt;a href=&quot;http://projecteuclid.org/euclid.ss/1009213726&quot;&gt;from the horse’s mouth&lt;/a&gt;, so to speak, 
in my &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Diss/VanhoveJ.pdf#subsection.9.3.2&quot;&gt;thesis&lt;/a&gt;,
or in tutorials by &lt;a href=&quot;http://dx.doi.org/10.1017/S0954394512000129&quot;&gt;Tagliamonte &amp;amp; Baayen&lt;/a&gt; or 
&lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2927982/&quot;&gt;Strobl and colleagues&lt;/a&gt;.
What’s important is that it often produces &lt;strong&gt;excellent classification models&lt;/strong&gt;
and that it computes an &lt;strong&gt;error-rate estimate&lt;/strong&gt; as a matter of course.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;randomForest&lt;/code&gt; function in the &lt;code&gt;randomForest&lt;/code&gt; package implements the algorithm.
There are a couple of settings that the user can tweak; again these needn’t concern us here—you
can read about these in the articles referred to above.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;## Load the randomForest package;
## you may need to run &#39;install.packages(&quot;randomForest&quot;)&#39; first.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randomForest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## Random forest have built-in random variability;
## by setting the random seed, you&#39;ll get the same result as me.
## You can try setting a different seed or not setting one
## and see what happens
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5-7-2016&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## Use a random forest to predict Class (L1 vs. L2 speaker)
## by means of all other variables in the dataset.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nativelike.rf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randomForest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## Output, including confusion matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nativelike.rf&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
## Call:
##  randomForest(formula = Class ~ ., data = dat) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 12.5%
## Confusion matrix:
##            L1 speaker L2 speaker class.error
## L1 speaker         10          5  0.33333333
## L2 speaker          2         39  0.04878049&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The output shows the estimated classification error 
that was computed on the basis of the original (simulated) data with
15 L1 and 41 L2 speakers (&lt;code&gt;OBB estimate of error rate&lt;/code&gt;):
an estimated 12.5% of observations will be misclassified by this algorithm.
With more data (more observations, more predictors, more reliable predictors),
this estimated error rate may become more accurate.&lt;/p&gt;

&lt;p&gt;More interesting for our present purposes is the confusion matrix:
The algorithm wrongly classifies two out of 41 L2 speakers as L1 speakers—these could perhaps be considered to have passed an updated ‘nativelikeness criterion’ inasmuch as they ‘fooled’ the algorithm.
&lt;strong&gt;But it also misclassifies 5 of the 15 L1 speakers as L2 speakers.&lt;/strong&gt;
In this case, then, the 5% ‘nativelikeness incidence’ among L2 speakers may be an underestimate, as the algorithm seems to be biased against classifying participants as L1 speakers.
This is likely due to the &lt;strong&gt;imbalance&lt;/strong&gt; in the data: there are about 3 times more L2 than L1 speakers, so the algorithm naturally defaults to L2 speakers.
(Take-home message if you want to conduct a study on nativelikeness: include more native speakers.)&lt;/p&gt;

&lt;p&gt;The same random forest can also be applied to the 10,000 new L1 speakers,
which gives a better estimate of how much the odds are stacked against classifying
a participant as an L1 speaker:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;new.predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nativelike.rf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newdata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new.L1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new.predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## L1 speaker L2 speaker 
##       7787       2213&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;While the random forest doesn’t classify all L1 speakers in the original control sample as L1 speakers (as the naïve nativelikeness procedure did),
it performs much better on new L1 data, classifying 78% of new L1 speakers as L1 speakers.
Evidently, in a real study, we wouldn’t have a sample of 10,000 participants on the side to check the estimated classification error rate.&lt;/p&gt;

&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;By using common definitions of nativelikeness criteria, L2 acquisition studies are likely to stack the odds against findings of nativelikeness and yield generally uninterpretable results.  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Random forests and other classification algorithms will yield
considerably &lt;strong&gt;better classifications&lt;/strong&gt; than ad-hoc criteria, but they may be far from perfect.
Their &lt;strong&gt;imperfection&lt;/strong&gt;, unlike that of ad-hoc criteria, can be quantified, however, which is crucial for interpreting the results.  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You’re unlikely to learn about such algorithms in an introductory course to statistics,
but it’s useful to &lt;strong&gt;simply know that they exist&lt;/strong&gt;. 
This is how you build up your statistical toolbox:
when you know that these tools exist and have a vague sense of what they’re for, 
you can brush up on them when you need them. 
There’s a world beyond &lt;em&gt;t&lt;/em&gt;-tests, ANOVA and Pearson’s &lt;em&gt;r&lt;/em&gt;.  &lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;package-versions-etc&quot;&gt;Package versions etc.&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;devtools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session_info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;magrittr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;dplyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;randomForest&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Session info --------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##  setting  value                       
##  version  R version 3.3.1 (2016-06-21)
##  system   x86_64, linux-gnu           
##  ui       RStudio (0.99.491)          
##  language en_US                       
##  collate  en_US.UTF-8                 
##  tz       Europe/Zurich               
##  date     2016-07-05&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Packages ------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##  package      * version  date       source        
##  assertthat     0.1      2013-12-06 CRAN (R 3.3.0)
##  BH             1.60.0-2 2016-05-07 CRAN (R 3.3.0)
##  DBI            0.4-1    2016-05-08 CRAN (R 3.3.0)
##  dplyr        * 0.5.0    2016-06-24 CRAN (R 3.3.1)
##  lazyeval       0.1.10   2015-01-02 CRAN (R 3.3.0)
##  magrittr     * 1.5      2014-11-22 CRAN (R 3.3.0)
##  R6             2.1.2    2016-01-26 CRAN (R 3.3.0)
##  randomForest * 4.6-12   2015-10-07 CRAN (R 3.3.0)
##  Rcpp           0.12.5   2016-05-14 CRAN (R 3.3.0)
##  tibble         1.1      2016-07-04 CRAN (R 3.3.1)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
                
        <entry>
            <title>Tutorial: Drawing a boxplot</title>
            <link href="http://janhove.github.io/reporting/2016/06/21/drawing-a-boxplot/" />
            <published>2016-06-21T00:00:00+02:00</published>
            <updated>2016-06-21T00:00:00+02:00</updated>
            <id>http://janhove.github.io/reporting/2016/06/21/drawing-a-boxplot/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2016/06/21/drawing-a-boxplot/">&lt;p&gt;In the two previous blog posts,
you learnt to draw simple but informative &lt;a href=&quot;/reporting/2016/06/02/drawing-a-scatterplot&quot;&gt;&lt;strong&gt;scatterplots&lt;/strong&gt;&lt;/a&gt;
and &lt;a href=&quot;/reporting/2016/06/13/drawing-a-linechart&quot;&gt;&lt;strong&gt;line charts&lt;/strong&gt;&lt;/a&gt;.
This time, you’ll learn how to draw &lt;strong&gt;boxplots&lt;/strong&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;whats-a-boxplot&quot;&gt;What’s a boxplot?&lt;/h3&gt;
&lt;p&gt;A boxplot is a graphical display of a sample’s &lt;strong&gt;five-number summary&lt;/strong&gt;:
the minimum, the maximum, the &lt;strong&gt;median&lt;/strong&gt; (i.e., the middle value if you sort the data from high to low),
and the 25th and 75th &lt;strong&gt;percentiles&lt;/strong&gt;.
The 25th percentile is the value below which 25% of the data lie;
the 75th percentile is the value below which 75% of the data lie.
The range between the 25th and 75th percentiles contains 50% of the sample and
is known as the &lt;strong&gt;inter-quartile range&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A boxplot might look like the one below–the median is highlighted by a thick line, the 25th and 75th are displayed by a box, and the minimum and maximum are plotted as ‘whiskers’:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Often, though, you’ll also see some points that lie beyond the whiskers.
These are values that lie too far from the bulk of data,
and they’re commonly referred to as &lt;strong&gt;outliers&lt;/strong&gt;.
Here’s an example:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It’s important to note, however, that these outliers may be perfectly valid observations,
so you shouldn’t remove them from the data set just because they show up in a boxplot.&lt;/p&gt;

&lt;h3 id=&quot;when-to-use-boxplots-and-when-there-are-better-choices&quot;&gt;When to use boxplots, and when there are better choices&lt;/h3&gt;
&lt;p&gt;Boxplots are often a good choice when you want to compare two or more groups.
In particular, I’ll take a boxplot over the ubiquitous ‘average-only’ barplot &lt;a href=&quot;/reporting/2015/01/07/some-alternatives-to-barplots&quot;&gt;any day&lt;/a&gt;.
The plot belows illustrates the problem with barplots:
the ‘average-only’ barplots on the left make a crisp impression,
but we have no way of knowing how large the 0.6-point difference between the means is in practical terms. (Error bars only slightly alleviate this for me.)
Additionally, we don’t know how the data are really distributed—knowing
this is usually important when interpreting the results.
The boxplots on the right, by contrast, show that—relative to the spread of the data—a 0.6-point difference is tiny.
Moreover, they show that both samples have a skewed distribution: the lower 50% of the data is restricted to a small range, whereas the upper 50% is spread out much more.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-3-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That said, there are situations where boxplots aren’t optimal.
One such situation is when the median is actually fairly atypical of the data.
From the left panel below, we would correctly gather 
that the sample median is slightly higher than 0.4
and that 50% of the data lies between 0.1 and 0.9.
A moment’s thought shows that this means that
a quarter of the data lies squished between 0 and 0.1
and another quarter between 0.9 and 1, but this may not be something
you consciously think of when leafing through a paper—what you focus on is the big white box and the thick line.
In this case, the histogram on the right does a much better job of highlighting the interesting patterns in the data—viz., that the distribution is strongly bimodal.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-4-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My point is this: Boxplots are much better than your run-of-the-mill barplots showing the group means,
but be willing to look for alternatives when
you need to—or ought to—highlight particular aspects of the data.&lt;/p&gt;

&lt;h3 id=&quot;tutorial-drawing-boxplots-in-ggplot2&quot;&gt;Tutorial: Drawing boxplots in ggplot2&lt;/h3&gt;

&lt;h4 id=&quot;what-youll-need&quot;&gt;What you’ll need&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;a href=&quot;http://r-project.org&quot;&gt;free program R&lt;/a&gt;,
the graphical user interface &lt;a href=&quot;http://rstudio.com&quot;&gt;RStudio&lt;/a&gt;, and the add-on package &lt;code&gt;ggplot2&lt;/code&gt;. See my &lt;a href=&quot;/reporting/2016/06/13/drawing-a-linechart&quot;&gt;previous post&lt;/a&gt; when you need help with this.  &lt;/li&gt;
  &lt;li&gt;A dataset. For this tutorial we’re going to work with another dataset on &lt;a href=&quot;http://ijb.sagepub.com/content/early/2015/03/05/1367006915573338&quot;&gt;receptive multilingualism&lt;/a&gt; that you can &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/VowelChoices_ij.csv&quot;&gt;download&lt;/a&gt; to your hard disk. The dataset contains three variables; what interests us is whether the proportion of responses to Dutch words with the digraph &lt;em&gt;ij&lt;/em&gt; (&lt;code&gt;PropCorrect&lt;/code&gt;) differs according the &lt;code&gt;LearningCondition&lt;/code&gt; to which the participants were assigned.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;preliminaries&quot;&gt;Preliminaries&lt;/h4&gt;
&lt;p&gt;In RStudio, read in the data.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file.choose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If the summary looks like this, you’re good to go.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##     Subject           LearningCondition  PropCorrect    
##  S10    : 1   &amp;lt;ij&amp;gt; participants:43      Min.   :0.0000  
##  S100   : 1   &amp;lt;oe&amp;gt; participants:37      1st Qu.:0.2262  
##  S11    : 1                             Median :0.3333  
##  S12    : 1                             Mean   :0.3685  
##  S14    : 1                             3rd Qu.:0.4762  
##  S15    : 1                             Max.   :0.9048  
##  (Other):74&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now load the &lt;code&gt;ggplot2&lt;/code&gt; package we’ll be using.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;a-first-attempt&quot;&gt;A first attempt&lt;/h4&gt;
&lt;p&gt;The first three lines of code specify
the data frame that the data are to be read from
and the variables that go on the x- and y-axis.
By setting &lt;code&gt;LearningCondition&lt;/code&gt; as the x-variable,
we make it clear that we want to compare the
accuracy data between these groups of participants.
The fourth line specifies that these data
should be rendered as boxplots.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LearningCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PropCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-9-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This first attempt already produces a very presentable result.
We would eventually like to label the axes more appropriately and get rid of the grey background,
but all in all, this is pretty decent.&lt;/p&gt;

&lt;h4 id=&quot;adding-the-individual-data-points&quot;&gt;Adding the individual data points&lt;/h4&gt;
&lt;p&gt;One more substantial thing we can add to the graph is the &lt;a href=&quot;http://dx.doi.org/10.1371/journal.pbio.1002128&quot;&gt;individual data points&lt;/a&gt; that the boxplots are based on.
You don’t &lt;em&gt;have&lt;/em&gt; to do this, but particularly when the number of observations is fairly small and the data aren’t too coarse, it may be interesting to see
how the data are distributed &lt;em&gt;within&lt;/em&gt; the boxes and whiskers.&lt;/p&gt;

&lt;p&gt;To add the individual data points to the boxplots, simply add a &lt;code&gt;geom_point()&lt;/code&gt; layer to the previous code.
I’ve specified that the points should be grey circles, but you can simply use &lt;code&gt;geom_point()&lt;/code&gt; instead of the fifth line.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LearningCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PropCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-10-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, some participants had the same number of correct responses, but from the graph you can’t tell which ones: the points are just plotted on top of each other.
To remedy this, we can ‘jitter’ the position of the data points using the &lt;code&gt;position_jitter&lt;/code&gt; command.
Note that I set the &lt;code&gt;height&lt;/code&gt; parameter to 0 as I don’t want to render proportions of, say, 0.24 as 0.28; I just want to spread apart the data points horizontally:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LearningCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PropCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position_jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-11-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;the-final-product&quot;&gt;The final product&lt;/h4&gt;
&lt;p&gt;You’ll notice that in the plot above, it appears as though three ‘oe’ participants have scores of around 62%, whereas in actual fact only two do:
we plotted a symbol to represent the outliers when drawing the boxplots &lt;em&gt;and&lt;/em&gt; we drew the data points individually.
When you’re plotting the individual data points anyway,
there’s no need to also draw the outliers for the boxplots;
you can turn this off by specifying &lt;code&gt;outlier.shape = NA&lt;/code&gt; in the &lt;code&gt;geom_boxplot()&lt;/code&gt; call.&lt;/p&gt;

&lt;p&gt;Second, the y-axis should be properly labelled,
whereas the label for the x-axis seems to be superfluous 
(the information is already supplied in the tick labels). Change this using the &lt;code&gt;ylab()&lt;/code&gt; and &lt;code&gt;xlab()&lt;/code&gt; calls.&lt;/p&gt;

&lt;p&gt;Third, personally I prefer white backgrounds. Simply adding &lt;code&gt;theme_bw()&lt;/code&gt; to the call overrides the grey default. &lt;code&gt;theme_bw(8)&lt;/code&gt; means that the font size will be slightly smaller, which is okay.&lt;/p&gt;

&lt;p&gt;Lastly, we can flip the x- and y-axes using &lt;code&gt;coord_flip()&lt;/code&gt;. The main advantage here is that doing so saves some vertical space on the page, which means there’s more room for other graphs!&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LearningCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PropCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outlier.shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position_jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Proportion of correct vowel choices&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;coord_flip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-21-drawing-a-boxplot/unnamed-chunk-12-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;the-cowplot-package&quot;&gt;The cowplot package&lt;/h4&gt;
&lt;p&gt;Lastly, I want to draw your attention to the &lt;a href=&quot;https://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html&quot;&gt;&lt;code&gt;cowplot&lt;/code&gt;&lt;/a&gt; package, which among other things is useful when you want to draw a plot containing several panels.&lt;/p&gt;
</content>
        </entry>
                
        <entry>
            <title>Tutorial: Drawing a line chart</title>
            <link href="http://janhove.github.io/reporting/2016/06/13/drawing-a-linechart/" />
            <published>2016-06-13T00:00:00+02:00</published>
            <updated>2016-06-13T00:00:00+02:00</updated>
            <id>http://janhove.github.io/reporting/2016/06/13/drawing-a-linechart/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2016/06/13/drawing-a-linechart/">&lt;p&gt;Graphs are incredibly useful
both for understanding your own data
and for communicating your insights to your audience.
This is why the next few blog posts
will consist of  tutorials on how to draw 
four kinds of graphs that I find most useful:
&lt;a href=&quot;/reporting/2016/06/02/drawing-a-scatterplot&quot;&gt;&lt;strong&gt;scatterplots&lt;/strong&gt;&lt;/a&gt;, &lt;strong&gt;line charts&lt;/strong&gt;,
&lt;strong&gt;boxplots&lt;/strong&gt; and some variations, and &lt;strong&gt;Cleveland dotplots&lt;/strong&gt;.
These tutorials are aimed primarily at the students in our MA programme.
Today’s graph: the line chart.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;whats-a-linechart&quot;&gt;What’s a linechart?&lt;/h3&gt;
&lt;p&gt;A line chart is quite simply a graph in which
data points that belong together are connected with a line.
If you want to compare different groups, as we do below,
you can use lines of different colours or different types to highlight differences between the groups.&lt;/p&gt;

&lt;p&gt;As an aside, 
line charts are often used to plot the development of a variable over time—the tutorial below is an example of this—and 
I used to think that linecharts should &lt;em&gt;only&lt;/em&gt; be used when time was involved, that connecting data points using lines was somehow not kosher otherwise.
But now I’m fine with using line charts even when time isn’t involved:
the lines often highlight the patterns in the data much better than a handful of unconnected symbols do.&lt;/p&gt;

&lt;h3 id=&quot;tutorial-drawing-a-linechart-in-ggplot2&quot;&gt;Tutorial: Drawing a linechart in ggplot2&lt;/h3&gt;
&lt;p&gt;In this tutorial, you’ll learn how to draw a basic linechart and how you can tweak it.
You’ll also learn how to quickly partition a dataset according to several variables and compute summary statistics within each part.
For this, we’ll make use of the free statistical program R and the add-on packages &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;magrittr&lt;/code&gt; and &lt;code&gt;dplyr&lt;/code&gt;.
Working with these programs and packages may be irksome at first if you’re used to pull-down menus,
but the trouble is well worth it.&lt;/p&gt;

&lt;h4 id=&quot;what-youll-need&quot;&gt;What you’ll need&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;a href=&quot;http://r-project.org&quot;&gt;free program R&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The graphical user interface &lt;a href=&quot;http://rstudio.com&quot;&gt;RStudio&lt;/a&gt; – also free. Download and install R first and only then RStudio.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I’m going to assume some familiarity with these programs.
Specifically, 
I’ll assume that you know how to enter commands in RStudio
and import datasets stored in the CSV file format.
If you need help with this, 
see &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Statistikkurs/StatistischeGrundlagen.pdf#page=11&quot;&gt;Chapter 1&lt;/a&gt; of my introduction to statistics (in German)
or Google &lt;em&gt;importing data R&lt;/em&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;magrittr&lt;/code&gt; and &lt;code&gt;dplyr&lt;/code&gt; add-on packages for R. 
To install them, simply enter the following command at the prompt in RStudio.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ggplot2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;magrittr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;dplyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;A dataset. For this tutorial, we’ll use a dataset
on the acquisition of morphological cues to agency
that my students compiled.
It consists of the responses of 70 learners (&lt;code&gt;SubjectID&lt;/code&gt;) 
who were assigned to one of three learning conditions (&lt;code&gt;BiasCondition&lt;/code&gt;) – the details don’t matter much for our purposes.
All learners completed three kinds of tasks (&lt;code&gt;Task&lt;/code&gt;):
understanding sentences in an unknown languages,
judging the grammaticality of sentences in the same languages,
and producing sentences in this language.
These tasks occurred in &lt;code&gt;Block&lt;/code&gt;s.
The learners’ responses were tracked throughout the experiment (&lt;code&gt;ResponseCorrect&lt;/code&gt;).
&lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/Seminarprojekt2016.csv&quot;&gt;Download&lt;/a&gt; this dataset to your hard disk.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;preliminaries&quot;&gt;Preliminaries&lt;/h4&gt;
&lt;p&gt;In RStudio, read in the data.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;semproj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file.choose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If the summary looks like this, you’re good to go.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;semproj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##                             SubjectID           BiasCondition 
##  0krwma8qskny4r4d1za1gqsp3hp78y4s:  96   RuleBasedInput:2496  
##  0pmm7rhegvxjttmjla7zyv0qrfwlv0a0:  96   StrongBias    :2112  
##  0qyn6np5fgyrmqjfbqjq68fcvs61y2gu:  96   WeakBias      :2112  
##  0uet846f755xvnm9ow9phkusz2zbhgac:  96                        
##  0vm3nrrqdd5mnbncnmon7sjp5f7fz4z8:  96                        
##  12athefgbh4zetjy4y2tn2148p713c6x:  96                        
##  (Other)                         :6144                        
##      Block      ResponseCorrect            Task     
##  Min.   :1.00   no :1670        Comprehension:4480  
##  1st Qu.:1.75   yes:5050        GJT          :1120  
##  Median :2.50                   Production   :1120  
##  Mean   :2.50                                       
##  3rd Qu.:3.25                                       
##  Max.   :4.00                                       
##&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now load the packages we’ll be using.
You may get a message that some ‘objects are masked’, but that’s nothing to worry about.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;magrittr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;summarising-a-data-frame&quot;&gt;Summarising a data frame&lt;/h4&gt;
&lt;p&gt;We want to compare how response accuracy develops block by block
in the different experimental conditions.
To that end, we need to calculate the proportion of correct
responses by each learner in each block and for each task.
The &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;magrittr&lt;/code&gt; packages make doing so easy.&lt;/p&gt;

&lt;p&gt;The following lines of code create a new data frame called &lt;code&gt;semproj_perParticipant&lt;/code&gt;
that was constructed by taking the dataset &lt;code&gt;semproj&lt;/code&gt; (first line),
grouping it by the variables &lt;code&gt;SubjectID&lt;/code&gt;, &lt;code&gt;BiasCondition&lt;/code&gt;, &lt;code&gt;Block&lt;/code&gt; and &lt;code&gt;Task&lt;/code&gt; (second line),
and within each ‘cell’ calculating the proportion of entries in &lt;code&gt;ResponseCorrect&lt;/code&gt; that read &lt;code&gt;&quot;yes&quot;&lt;/code&gt; (third line).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;semproj_perParticipant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semproj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SubjectID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ResponseCorrect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Type the name of the new data frame at the prompt. If you see something like this,
everything’s fine.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;semproj_perParticipant&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##                          SubjectID BiasCondition Block          Task
## 1 0krwma8qskny4r4d1za1gqsp3hp78y4s    StrongBias     1 Comprehension
## 2 0krwma8qskny4r4d1za1gqsp3hp78y4s    StrongBias     1           GJT
## 3 0krwma8qskny4r4d1za1gqsp3hp78y4s    StrongBias     1    Production
## 4 0krwma8qskny4r4d1za1gqsp3hp78y4s    StrongBias     2 Comprehension
## 5 0krwma8qskny4r4d1za1gqsp3hp78y4s    StrongBias     2           GJT
## 6 0krwma8qskny4r4d1za1gqsp3hp78y4s    StrongBias     2    Production
##   ProportionCorrect
## 1            0.6875
## 2            0.5000
## 3            0.0000
## 4            0.3750
## 5            0.5000
## 6            0.0000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now that we’ve computed the proportion of correct responses
by each participant for each block and task,
we can compute the average proportion of correct responses
per block and task according to the experimental condition the participants
were assigned to.
The code works similarly to before:
a new data frame called &lt;code&gt;semproj_perCondition&lt;/code&gt; is created
by taking the &lt;code&gt;semproj_perParticipant&lt;/code&gt; data frame we constructed above (line 1),
grouping it by &lt;code&gt;BiasCondition&lt;/code&gt;, &lt;code&gt;Block&lt;/code&gt; and &lt;code&gt;Task&lt;/code&gt; (line 2), and
computing the mean proportion of correct responses (line 3).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;semproj_perCondition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semproj_perParticipant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MeanProportionCorrect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The result should look like this—you can see that those in the ‘rule-based input’ learning condition score an average of 69% on the first comprehension block,
59% on the first grammaticality judgement task (GJT) block,
and 13% on the first production block.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;semproj_perCondition&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Source: local data frame [36 x 4]
## Groups: BiasCondition, Block [?]
## 
##     BiasCondition Block          Task MeanProportionCorrect
##            (fctr) (int)        (fctr)                 (dbl)
## 1  RuleBasedInput     1 Comprehension             0.6923077
## 2  RuleBasedInput     1           GJT             0.5865385
## 3  RuleBasedInput     1    Production             0.1346154
## 4  RuleBasedInput     2 Comprehension             0.8461538
## 5  RuleBasedInput     2           GJT             0.7307692
## 6  RuleBasedInput     2    Production             0.5096154
## 7  RuleBasedInput     3 Comprehension             0.8798077
## 8  RuleBasedInput     3           GJT             0.8076923
## 9  RuleBasedInput     3    Production             0.5480769
## 10 RuleBasedInput     4 Comprehension             0.8966346
## ..            ...   ...           ...                   ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;a-first-attempt-development-in-comprehension&quot;&gt;A first attempt: Development in comprehension&lt;/h4&gt;
&lt;p&gt;To start off with a simple example,
let’s plot the mean proportion of correct responses
in the four comprehension blocks for the three experimental conditions
and connect them with a line.&lt;/p&gt;

&lt;p&gt;First, we create another new data frame that contains the averages
for the comprehension task only.
The new data frame &lt;code&gt;semproj_perCondition_Comprehension&lt;/code&gt; is constructed
by taking the data frame &lt;code&gt;semproj_perCondition&lt;/code&gt; we constructed above
and retaining (filtering) the rows for which the &lt;code&gt;Task&lt;/code&gt; variable reads &lt;code&gt;Comprehension&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;semproj_perCondition_Comprehension&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semproj_perCondition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Comprehension&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;semproj_perCondition_Comprehension&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Source: local data frame [12 x 4]
## Groups: BiasCondition, Block [12]
## 
##     BiasCondition Block          Task MeanProportionCorrect
##            (fctr) (int)        (fctr)                 (dbl)
## 1  RuleBasedInput     1 Comprehension             0.6923077
## 2  RuleBasedInput     2 Comprehension             0.8461538
## 3  RuleBasedInput     3 Comprehension             0.8798077
## 4  RuleBasedInput     4 Comprehension             0.8966346
## 5      StrongBias     1 Comprehension             0.7329545
## 6      StrongBias     2 Comprehension             0.8011364
## 7      StrongBias     3 Comprehension             0.8125000
## 8      StrongBias     4 Comprehension             0.8920455
## 9        WeakBias     1 Comprehension             0.7897727
## 10       WeakBias     2 Comprehension             0.8295455
## 11       WeakBias     3 Comprehension             0.8977273
## 12       WeakBias     4 Comprehension             0.9261364&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To plot these averages, use the following code.
The first line specifies the data frame the graph should be based on,
the second line specifies that &lt;code&gt;Block&lt;/code&gt; (1-2-3-4) should go on the x-axis,
the third that &lt;code&gt;MeanProportionCorrect&lt;/code&gt; should go on the y-axis,
and the fourth that the different experimental conditions
should be rendered using different colours.
The fifth line, finally, specifies that the data should be plotted as lines.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semproj_perCondition_Comprehension&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MeanProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-13-drawing-a-linechart/unnamed-chunk-12-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is decent enough for a start: 
it’s clear from this graph that,
contrary to what we’d expected,
those in the weak bias condition actually
seem to perform better than the other participants, for instance.
We could go on and draw similar graphs
for the other two tasks—comprehension and production—but there’s a better option:
draw them all at once so that
the results can more easily be compared.&lt;/p&gt;

&lt;h4 id=&quot;several-linecharts-in-one-plot&quot;&gt;Several linecharts in one plot&lt;/h4&gt;
&lt;p&gt;For this plot, we use the &lt;code&gt;semproj_perCondition&lt;/code&gt; data frame
that contains the averages for all three tasks, split up by block and experimental condition.
The code is otherwise the same as before,
but I’ve added one additional line:
&lt;code&gt;facet_wrap&lt;/code&gt; splits up the
data according to a variable (here &lt;code&gt;Task&lt;/code&gt;)
and plots a separate plot for each part.
By default, the axes of the different subplots
span the same range so that 
differences in overall performance 
can easily be compared between the three tasks.
So not only is this quicker than drawing three separate graphs,
it also saves (vertical) space &lt;em&gt;and&lt;/em&gt; the side-by-side plots are easier to compare with one another than
three separate plots would be.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semproj_perCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MeanProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-13-drawing-a-linechart/unnamed-chunk-13-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;a-printer-friendly-version&quot;&gt;A printer-friendly version&lt;/h4&gt;
&lt;p&gt;If you prefer a printer-friendly version,
you can add the &lt;code&gt;theme_bw()&lt;/code&gt; command to the ggplot call (10th line)
and specify that the different experimental conditions
should be distinguished using different linetypes (solid, dashed, dotted) rather than different colours (4th line).
Since the difference between dashed and dotted lines may not be immediately obvious,
it can be a good idea to also plot the averages using different symbols (lines 5 and 6).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semproj_perCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MeanProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;linetype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-13-drawing-a-linechart/unnamed-chunk-14-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;with-customised-legends-and-labels&quot;&gt;With customised legends and labels&lt;/h4&gt;
&lt;p&gt;The plot above is okay, but you can go the extra mile
by customising the axis and legend labels rather than using the defaults—even if they are comprehensible, it just makes a better impression to do so:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The &lt;code&gt;xlab&lt;/code&gt; and &lt;code&gt;ylab&lt;/code&gt; commands change the names of the x- and y-axes. Note that &lt;code&gt;\n&lt;/code&gt; starts a new line. &lt;/li&gt;
  &lt;li&gt;With &lt;code&gt;scale_shape_manual&lt;/code&gt;, I changed the &lt;code&gt;labels&lt;/code&gt; of the legend for the different symbols. I also changed the symbols themselves (&lt;code&gt;values&lt;/code&gt;) as I thought the default symbols were difficult to tell apart. 
The values 1, 2 and 3 work fine for this graph, I think, but you can try out different values (&lt;a href=&quot;http://sape.inf.usi.ch/quick-reference/ggplot2/shape&quot;&gt;handy list with symbol numbers&lt;/a&gt;). &lt;/li&gt;
  &lt;li&gt;If you customise the labels and symbols for the &lt;code&gt;shape&lt;/code&gt; parameter, you need to do the same for the &lt;code&gt;linetype&lt;/code&gt; parameters—otherwise, R gets confused. This is what I did in &lt;code&gt;scale_linetype_manual&lt;/code&gt;. Note that the &lt;code&gt;labels&lt;/code&gt; must occur in the same order as the labels in &lt;code&gt;scale_shape_manual&lt;/code&gt;. (&lt;a href=&quot;http://sape.inf.usi.ch/quick-reference/ggplot2/linetype&quot;&gt;handy list with linetypes&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;In both &lt;code&gt;scale_shape_manual&lt;/code&gt; and &lt;code&gt;scale_linetype_manual&lt;/code&gt;, I set &lt;code&gt;name&lt;/code&gt; to &lt;code&gt;&quot;Learning condition&quot;&lt;/code&gt;.
This changes the title of the legend, and by using the same title twice, you tell R to combine the two
legends into one.&lt;/li&gt;
  &lt;li&gt;In &lt;code&gt;theme&lt;/code&gt;, &lt;code&gt;legend_position&lt;/code&gt; specifies where the legend should go (on top rather than on the right),
and &lt;code&gt;legend_direction&lt;/code&gt; whether the keys should be plotted next to (horizontal) or under (vertical) each other.&lt;/li&gt;
  &lt;li&gt;The lines with &lt;code&gt;panel.grid&lt;/code&gt; draw horizontal grid lines to facilitate the comparison between tasks and suppress any vertical grid lines ggplot may draw.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semproj_perCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MeanProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;linetype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BiasCondition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Experimental block&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Mean proportion\nof correct responses&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_shape_manual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rule-based&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;s2&quot;&gt;&quot;strongly biased&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;s2&quot;&gt;&quot;weakly biased&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Learning condition&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_linetype_manual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;solid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;dotted&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;dotdash&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rule-based&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                   &lt;span class=&quot;s2&quot;&gt;&quot;strongly biased&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                   &lt;span class=&quot;s2&quot;&gt;&quot;weakly biased&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Learning condition&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend.position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;top&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;legend.direction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;horizontal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;panel.grid.major.y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;grey65&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;panel.grid.minor.y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;grey85&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;panel.grid.major.x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element_blank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;panel.grid.minor.x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;element_blank&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-13-drawing-a-linechart/unnamed-chunk-15-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;
</content>
        </entry>
                
        <entry>
            <title>Tutorial: Drawing a scatterplot</title>
            <link href="http://janhove.github.io/reporting/2016/06/02/drawing-a-scatterplot/" />
            <published>2016-06-02T00:00:00+02:00</published>
            <updated>2016-06-02T00:00:00+02:00</updated>
            <id>http://janhove.github.io/reporting/2016/06/02/drawing-a-scatterplot/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2016/06/02/drawing-a-scatterplot/">&lt;p&gt;Graphs are incredibly useful
both for understanding your own data
and for communicating your insights to your audience.
This is why the next few blog posts
will consist of  tutorials on how to draw 
four kinds of graphs that I find most useful:
&lt;strong&gt;scatterplots&lt;/strong&gt;, &lt;strong&gt;linecharts&lt;/strong&gt;,
&lt;strong&gt;boxplots&lt;/strong&gt; and some variations, and &lt;strong&gt;Cleveland dotplots&lt;/strong&gt;.
These tutorials are aimed primarily at the students in our MA programme.
Today’s graph: the scatterplot.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;whats-a-scatterplot&quot;&gt;What’s a scatterplot?&lt;/h3&gt;
&lt;p&gt;A scatterplot is one of the most useful kind of graphs in your toolbox.
Any time your data consists of pairs of fairly fine-grained measurements
such as people’s heights and weights,
a scatterplot is one of the top alternatives.
To draw one, you plot each pair of measurements in an &lt;em&gt;x&lt;/em&gt;/&lt;em&gt;y&lt;/em&gt; plane, like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Plotting the data in this way often gives
the reader – and yourself – a good idea of how the two measurements are related.
We can immediately see what range both variables span
and how differences in one variable are related to differences in
the other one.
In this case, the relationship between the two variable is distinctly non-linear,
the direction of the relationship changing when the first variable is 0.
Additionally, it’s immediately obvious that one pair of measurements stands
out from the rest of the data and may need triple-checking.&lt;/p&gt;

&lt;p&gt;When researchers are interested in how two variables are correlated,
they often overeagerly jump straight to computing correlation coefficients.
But correlation coefficients can deceive:
low correlation coefficients (&lt;em&gt;r&lt;/em&gt;) can hide strong but non-linear relationships (left panel),
whereas high correlation coefficients can be caused by a single outlying data point (middle)
or may gloss over distinct groups in the datasets
within each of which the direction of relationship
is actually the reverse of the one indicated by the correlation coefficient (right).
It’s only in a scatterplot that the meaning of a correlation coefficient – or lack thereof – becomes clear.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bottom line: Show your data – Any time you want to compute a correlation coefficient,
draw a scatterplot first and show it to your audience.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;tutorial-drawing-a-scatterplot-in-ggplot2&quot;&gt;Tutorial: Drawing a scatterplot in ggplot2&lt;/h3&gt;
&lt;p&gt;In this tutorial, you’ll learn how to draw a basic scatterplot
and how you can tweak it.
For this, 
we’ll make use of the free statistical program R
and the add-on package ggplot2.
ggplot2 is an extremely powerful tool for plotting data,
and gaining familiarity with it through fairly simple examples
will pay dividends if you’re ever going to work with more complex data.&lt;/p&gt;

&lt;h4 id=&quot;what-youll-need&quot;&gt;What you’ll need&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;a href=&quot;http://r-project.org&quot;&gt;free program R&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The graphical user interface &lt;a href=&quot;http://rstudio.com&quot;&gt;RStudio&lt;/a&gt; – also free. Download and install R first and only then RStudio.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I’m going to assume some familiarity with these programs.
Specifically, 
I’ll assume that you know how to enter commands in RStudio
and import datasets stored in the CSV file format.
If you need help with this, 
see &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Statistikkurs/StatistischeGrundlagen.pdf#page=11&quot;&gt;Chapter 1&lt;/a&gt; of my introduction to statistics (in German)
or Google &lt;em&gt;importing data R&lt;/em&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The ggplot2 add-on package for R. To install it, simply enter the following command at the prompt in RStudio.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ggplot2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;A dataset with pairs of fairly fine-grained measurements.
For this tutorial, we’ll use a dataset on &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Cog4Talen/FactorenCognaatherkenning.pdf&quot;&gt;receptive multilingualism&lt;/a&gt; which was compiled by showing about 100 German speakers lists of Danish, Dutch, Frisian and Swedish words and asking them to translate these words into German.
The dataset consists of four variables: 
the word shown;
the language of the word;
the degree of orthographic distance between this word and its translation equivalent 
in German, English or French (possible values between 0 and 1);
and the proportion of participants that correctly translated the word (between 0 and 1).
&lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/CognateTranslations.csv&quot;&gt;Download&lt;/a&gt; this dataset
to a local drive.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;preliminaries&quot;&gt;Preliminaries&lt;/h4&gt;
&lt;p&gt;In RStudio, read in the data. Setting &lt;code&gt;encoding&lt;/code&gt; to &lt;code&gt;&quot;UTF-8&quot;&lt;/code&gt; 
ensures that letters with diacritics (ä, ö, å etc.) are read in correctly.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file.choose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If the summary looks like this, you’re ready to go.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##          Item        Language  OrthographicDistance ProportionCorrect
##  aai       :  1   Danish :45   Min.   :0.0000       Min.   :0.0000   
##  aarde     :  1   Dutch  :46   1st Qu.:0.2222       1st Qu.:0.2243   
##  anslutning:  1   Frisian:45   Median :0.3333       Median :0.4860   
##  antal     :  1   Swedish:45   Mean   :0.3563       Mean   :0.4906   
##  applåd    :  1                3rd Qu.:0.4545       3rd Qu.:0.7757   
##  armoede   :  1                Max.   :0.8571       Max.   :0.9907   
##  (Other)   :175&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;a-first-attempt&quot;&gt;A first attempt&lt;/h4&gt;
&lt;p&gt;Load the ggplot2 package you installed earlier.
You don’t need to reinstall the ggplot2 package every time you use it,
but you do need to load it each time you fire up R/RStudio.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Above, we read in the dataset as &lt;code&gt;translations&lt;/code&gt;.
The variables in this dataset that we want to plot are 
&lt;code&gt;OrthographicDistance&lt;/code&gt; and &lt;code&gt;ProportionCorrect&lt;/code&gt;.
Since it stands to reason that the orthographic distance between a word
and its translation equivalents affects how easily it can be understood,
but not vice versa, we’ll put &lt;code&gt;OrthographicDistance&lt;/code&gt; along the &lt;em&gt;x&lt;/em&gt;-axis and
&lt;code&gt;ProportionCorrect&lt;/code&gt; along the &lt;em&gt;y&lt;/em&gt;-axis.&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;ggplot&lt;/code&gt; function, we first specify which dataset contains the variables
we want to display and then define the ‘aesthetics’ of the graph we want to draw,
i.e., which variable we want to put on the x-axis and which one on the y-axis:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-7-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The plot above shows an empty coordinate system.
The reason is that we haven’t told &lt;code&gt;ggplot&lt;/code&gt;
&lt;em&gt;how&lt;/em&gt; we want to display the pairs of measurements.
Usually, we plot them as dots or circles.
To achieve this, we add another &lt;em&gt;layer&lt;/em&gt; consisting of points
to the coordinate system:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-8-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can change the appearance of these dots,
for instance by setting the &lt;code&gt;shape&lt;/code&gt; parameter.
For further examples, see the &lt;a href=&quot;http://docs.ggplot2.org/current/geom_point.html&quot;&gt;ggplot2 documentation&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-9-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;make-it-reader-friendly&quot;&gt;Make it reader-friendly&lt;/h4&gt;
&lt;p&gt;The main trend is clear from the graph above:
words with a larger orthographic distance to their translation equivalents
are translated correctly less often.
(Nothing out of the ordinary, I’ll admit.)
Graphs like these are great for learning about your own data,
but they need some tweaking before you can use them in a presentation or term paper.
Specifically, 
the default axis names aren’t usually very meaningful to other people,
and even if they are, they look a bit slapdash.
By specifying the &lt;code&gt;xlab&lt;/code&gt; and &lt;code&gt;ylab&lt;/code&gt; layers, 
you can give the axes more interpretable titles.
The &lt;code&gt;theme_bw&lt;/code&gt; layer get rid of the default grey background.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-10-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;labels-instead-of-points&quot;&gt;Labels instead of points&lt;/h4&gt;
&lt;p&gt;Instead of plotting points, 
we can plot the words that the points stand for.
This makes it easier to
identify data points that go against the grain
– words with high orthographic distances that are easy to understand and vice versa.
The words are stored in the &lt;code&gt;Item&lt;/code&gt; column;
to plot them, we need to add the &lt;code&gt;label&lt;/code&gt; aesthetic to the ggplot call and specify that we want to plot text labels instead of points.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# specify label aesthetic
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;             &lt;span class=&quot;c1&quot;&gt;# plot text labels instead of points
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-11-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Words that are easy to understand despite their high orthographic distance (e.g., &lt;em&gt;eftermiddag&lt;/em&gt;)
or that are difficult to understand despite their low orthographic distance (e.g., &lt;em&gt;ræsonnement&lt;/em&gt;)
can now be identified.
That said, with all the overlapping labels, the scatterplot looks crowded.
We can make the font size a bit smaller,
but with 181 labels, 
this plot is always going to look crowded.
That said, this kind of plot would work well for smaller datasets.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# change font size
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-12-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Instead of plotting labels for all words,
we could just plot the labels of a handful of words and use dots for the rest:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# change font size
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;annotate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.72&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.86&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;eftermiddag&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-13-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;adding-a-trend-line&quot;&gt;Adding a trend line&lt;/h4&gt;
&lt;p&gt;To highlight the trend in the data even more,
you can add a trend line to the scatterplot.
In ggplot2, this is a matter of adding another layer to the call (&lt;code&gt;geom_smooth&lt;/code&gt;).
If you put the &lt;code&gt;geom_smooth&lt;/code&gt; after the &lt;code&gt;geom_text&lt;/code&gt; layer, the trend line is plotted on top of the text labels; if you put it before &lt;code&gt;geom_text&lt;/code&gt;, it’s plotted below the labels.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-14-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By default, the trend line is a non-linear one,
is plotted in blue and is accompanied by a
grey confidence band.
This can all be &lt;a href=&quot;http://docs.ggplot2.org/current/geom_smooth.html&quot;&gt;modified&lt;/a&gt;, however.
Below, I turn off the confidence band (&lt;code&gt;se = FALSE&lt;/code&gt;)
because it extents to proportions below 0 – which doesn’t make sense here.
I also change the colour to red, just because.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-15-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;using-panels&quot;&gt;Using panels&lt;/h4&gt;
&lt;p&gt;If the data consist of different groups,
it can be a good idea to draw separate scatterplots
for each group.
In this example, 45 of the 181 words were Danish, 46 were Dutch, 45 Frisian and 45 Swedish.
To draw separate scatterplots for each of these four languages,
we add &lt;code&gt;facet_wrap&lt;/code&gt; to the ggplot call:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Language&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# split up by Language and plot in four columns
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-16-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Or with labels instead of points,
so that we can see which items cause
the trend line for Danish to look so different from 
the other ones:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;translations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OrthographicDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProportionCorrect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orthographic Levenshtein distance&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;proportion of correct translations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Language&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 2 columns
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-06-02-drawing-a-scatterplot/unnamed-chunk-17-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;learning-more&quot;&gt;Learning more&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;http://docs.ggplot2.org/current/&quot;&gt;ggplot2 online documentation&lt;/a&gt; is great,
and you’ll find a wealth of information by googling keywords such as &lt;em&gt;ggplot2 label points scatterplot&lt;/em&gt;.&lt;/p&gt;
</content>
        </entry>
                        
        <entry>
            <title>Why reported R² values are often too high</title>
            <link href="http://janhove.github.io/analysis/2016/04/22/r-squared/" />
            <published>2016-04-22T00:00:00+02:00</published>
            <updated>2016-04-22T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2016/04/22/r-squared/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2016/04/22/r-squared/">&lt;p&gt;After reading a couple of papers whose conclusions were heavily based on &lt;em&gt;R²&lt;/em&gt; (“variance explained”) values, 
I thought I’d summarise why I’m often skeptical of such conclusions.
The reason, in a nutshell, is that reported &lt;em&gt;R²&lt;/em&gt; values tend to overestimate how much of the variance in the outcome variable the model can actually “explain”.
To dyed-in-the-wool quantitative researchers, 
none of this blog post will be new, 
but I hope that it will make some readers think twice before focusing heavily on &lt;em&gt;R²&lt;/em&gt; values.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;whats-r&quot;&gt;What’s &lt;em&gt;R²&lt;/em&gt;?&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;R²&lt;/em&gt;, or the &lt;em&gt;coefficient of determination&lt;/em&gt;, takes values between 0 and 1 and represents the proportion of the variance in the outcome variable
that the predictors in a regression model jointly “explain”.
There are a couple of ways to calculate &lt;em&gt;R²&lt;/em&gt;,
and for ordinary regression models, all of them produce the same result.
However, for other regression models, such as logistic regression or mixed-effects models,
the different definitions of &lt;em&gt;R²&lt;/em&gt; can produce different results,
so that it’s not clear which definition, if indeed any, is the right one in every case.
Here, I’ll stick to discussing &lt;em&gt;R²&lt;/em&gt; for ordinary regression models.&lt;/p&gt;

&lt;p&gt;Incidentally, I put “variance explained” between scare quotes,
as I think “variance described” would be a better way of putting it.
“Variance explained” could suggest that the regression model has the status of an explanatory theoretical model
that truly attempts to explain why the data look the way they do.
The regression model does no such thing.&lt;/p&gt;

&lt;h3 id=&quot;problems-with-r&quot;&gt;Problems with &lt;em&gt;R²&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;I’ve written about my skepticism about standardised effect sizes before
(&lt;a href=&quot;/reporting/2015/02/05/standardised-vs-unstandardised-es&quot;&gt;here&lt;/a&gt; 
and &lt;a href=&quot;/design/2015/03/16/standardised-es-revisited&quot;&gt;here&lt;/a&gt;).
&lt;em&gt;R²&lt;/em&gt; inherits all of the problems I discussed there
and adds some additional ones.
To be clear, I don’t doubt that &lt;em&gt;R²&lt;/em&gt; can be used sensibly;
it’s just that it often isn’t.&lt;/p&gt;

&lt;p&gt;The first problem with taking &lt;em&gt;R²&lt;/em&gt; values at face value is 
that they tend to be too high:
even if the predictor variables and the outcome are actually unrelated,
you’ll find that the predictors “explain” some proportion of the variance in the outcome.
This is easiest to see when you have one predictor variable and one outcome variable.
Even if the predictor and the outcome are unrelated,
sampling error will cause the correlation coefficient (&lt;em&gt;r&lt;/em&gt;) to deviate from 0 in any one sample.
These deviations from 0 can be both positive or negative (left panels in the figure below),
and averaged over many samples, the correlation coefficient will be 0 (dashed lines).
When you have one predictor and one outcome variable,
&lt;em&gt;R²&lt;/em&gt; can simply be calculated by squaring the correlation coefficient.
But when you square negative values, you get positive numbers,
so that sampling error will cause &lt;em&gt;R²&lt;/em&gt; to be positive (right panels) – 
there will always be some “variance explained”!
What’s more, since sampling error plays a bigger role in small samples,
this overestimation of “variance explained” is larger in smaller samples (top vs. bottom panels).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-04-22-r-squared/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Second, &lt;em&gt;R²&lt;/em&gt; always increases when you add more predictors to the regression model.
But by adding more and more predictors, you’re bound to model random fluctuations (‘noise’) in the data.
As a result, if you were to apply the same model to a new dataset,
you could find that the more complex model actually has a worse fit than a simpler model.&lt;/p&gt;

&lt;h4 id=&quot;r-hacking&quot;&gt;‘&lt;em&gt;R²&lt;/em&gt; hacking’&lt;/h4&gt;
&lt;p&gt;You may object that while the above may be true,
it’s also irrelevant:
your statistics package also outputs an ‘adjusted &lt;em&gt;R²&lt;/em&gt;’ value
that corrects the &lt;em&gt;R²&lt;/em&gt; value based on the sample size and the number of predictors.
Adjusted &lt;em&gt;R²&lt;/em&gt; values can be negative so that they aren’t biased away from 0 (figure below).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-04-22-r-squared/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is true in principle.
In practice, though, reported adjusted &lt;em&gt;R²&lt;/em&gt; values are often too high, too.
The reason is what I’ll call ‘&lt;em&gt;R²&lt;/em&gt; hacking’:
analytical decisions in variable selection, data transformation and outlier treatment
with which the analyst deliberately or indeliberately enhances the model’s fit to the present data,
but which cause the model to generalise poorly to new data.
&lt;em&gt;R²&lt;/em&gt; hacking is like &lt;a href=&quot;http://blogs.discovermagazine.com/neuroskeptic/2015/05/18/p-hacking-a-talk-and-further-thoughts/#.VxngW0I5vCI&quot;&gt;&lt;em&gt;p&lt;/em&gt; hacking&lt;/a&gt;,
but rather than selecting for statistical significance,
the analyst (deliberately or indeliberately) selects for larger (adjusted or unadjusted) &lt;em&gt;R²&lt;/em&gt; values.&lt;/p&gt;

&lt;p&gt;The effects of &lt;em&gt;R²&lt;/em&gt; hacking are most easily illustrated
in the simple scenario where the analyst has several predictor variable at their disposal,
for the sake of parsimony selects the predictor with the highest absolute sample correlation
to the outcome as the sole predictor in a simple regression model,
and then reports the model’s adjusted &lt;em&gt;R²&lt;/em&gt;.
The code below simulates such a scenario
and assumes that none of the predictors are actually related to the outcome.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Run 10,000 simulations
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adjrs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1e4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Generate dataset with 25 observations for 1 outcome and 10 predictors.
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# None of the predictors is actually related to the outcome here:
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;x4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;x7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;x10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Select predictor with highest absolute sample correlation to outcome
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# as sole predictor in simple regression model
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;formula.lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as.formula&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;y ~ &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                 &lt;span class=&quot;n&quot;&gt;noquote&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;which.max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))))))&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Run simple regression model and calculate adjusted R²
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;adjr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;formula.lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adj.r.squared&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Return adjusted R²
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adjr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot histogram with results
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;par&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mfrow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;las&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cex.main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adjrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;#4DAF4A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
     &lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;adjusted R²\n(n = 25)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;adjusted R²&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adjrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-04-22-r-squared/unnamed-chunk-3-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As the histogram above shows,
prior variable screening causes the average adjusted &lt;em&gt;R²&lt;/em&gt; value to be higher than zero.
This positive bias also occurs when the predictors actually &lt;em&gt;are&lt;/em&gt; related to the outcome.
For the figure below, I also simulated 10,000 datasets with one outcome variable and ten possible predictors.
This time, all of the predictors were weakly related to the outcome.
The left panel shows the distribution of the adjusted &lt;em&gt;R²&lt;/em&gt; value 
when we always choose the same predictor for the simple regression model (i.e., no data-dependent variable selection).
The average adjusted &lt;em&gt;R²&lt;/em&gt; in this case is about 4%.
The panel on the right shows what happens when we select the predictor with the
highest sample correlation (data-dependent variable selection): the average adjusted &lt;em&gt;R²&lt;/em&gt; is now about 21%.
So, predictor selection inflates the “variance explained” by a factor of 5 in this case.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-04-22-r-squared/unnamed-chunk-4-1.png&quot; alt=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The reason for this positive bias is that the adjusted &lt;em&gt;R²&lt;/em&gt; value
was corrected for the number of predictors that occur in the model (1) –
not for the number of predictors that were actually consider when building the model (10).
But at least in this case, we know what the number of predictors considered was.
Similar situations arise, however, when the predictors were selected by more informal procedures
such as visually inspecting the data before deciding which predictors are worth a place in the model
or trying out different data transformations and picking the one that yield the prettiest scatterplots.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;The reason I’m often skeptical about conclusions based on adjusted or unadjusted &lt;em&gt;R²&lt;/em&gt; values is that
these values are bound to be overestimates: 
the same model applied to a new dataset will in all likelihood produce appreciably poorer fits
and may sometimes be worse than having no regression model at all.
There are methods to minimise this danger,
but those are for another time.&lt;/p&gt;
</content>
        </entry>
                                  
        <entry>
            <title>Experiments with intact groups: spurious significance with improperly weighted t-tests</title>
            <link href="http://janhove.github.io/design/2016/02/16/cluster-randomisation-correction/" />
            <published>2016-02-16T00:00:00+01:00</published>
            <updated>2016-02-16T00:00:00+01:00</updated>
            <id>http://janhove.github.io/design/2016/02/16/cluster-randomisation-correction/</id>
            <content type="html" xml:base="http://janhove.github.io/design/2016/02/16/cluster-randomisation-correction/">&lt;p&gt;When analysing experiments in which intact groups (clusters) were assigned to the experimental conditions,
&lt;em&gt;t&lt;/em&gt;-tests on cluster means that weight these means for cluster size are occasionally used.
In fact, I too endorsed this approach as a straightforward and easily implemented way to account for clustering.
It seems, however, that these weighted &lt;em&gt;t&lt;/em&gt;-test are still anti-conservative, i.e. they find too many significant differences when there is in fact no effect.
In this post, I present simulation results to illustrate this and I also correct another published error of mine.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;what-are-cluster-randomised-experiments-again&quot;&gt;What are cluster-randomised experiments again?&lt;/h3&gt;
&lt;p&gt;Cluster-randomised experiments are experiments in which whole groups, rather than individual participants, are assigned to the experimental conditions.
In education, for instance, it is often impractical or undesirable to randomly assign individual students to a new pedagogical programme or a control programme. Instead, entire classes or even entire schools or school districts are assigned to one of the programmes, and all students within the class, school or school district (‘cluster’) participate in the same programme.&lt;/p&gt;

&lt;p&gt;This seemingly minor difference between cluster-randomised experiments and typical randomised experiments has enormous consequences for the way in which the data should be analysed. 
See the blog post on &lt;a href=&quot;/design/2015/09/17/cluster-randomised-experiments&quot;&gt;&lt;em&gt;Analysing experiments with intact groups&lt;/em&gt;&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h3 id=&quot;weighting-clusters-for-their-size&quot;&gt;Weighting clusters for their size&lt;/h3&gt;
&lt;p&gt;In a paper on &lt;a href=&quot;http://www.ssllt.amu.edu.pl/images/vol.5.no.1/SSLLT%205%281%29%20135-152%20Vanhove.pdf&quot;&gt;&lt;em&gt;Analyzing randomized controlled interventions&lt;/em&gt;&lt;/a&gt;, I wrote the following on analysing cluster-randomised experiments:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A conceptually straightforward approach [for taking clustering into account] is to calculate the mean (or another summary measure) of each cluster and run a &lt;em&gt;t&lt;/em&gt; test on them rather than on the original observations. When the number of observations differs from cluster to cluster, a &lt;em&gt;t&lt;/em&gt; test in which the cluster means are weighted for cluster size is recommended (see, e.g., &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/17136746&quot;&gt;Campbell, Donner, &amp;amp; Klar, 2007&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I regret that the recommendation to weight cluster means for cluster size does not stem from M. &lt;em&gt;J.&lt;/em&gt; Campbell et al. (2007) but from &lt;a href=&quot;http://dx.doi.org/10.1093/fampra/17.2.192&quot;&gt;M. &lt;em&gt;K.&lt;/em&gt; Campbell et al. (2000)&lt;/a&gt;: “When the size of the clusters varies widely, it is preferable to carry out a weighted t-test, using cluster sizes as weights” (pp. 193-194).
From there, the recommendation can be traced back to &lt;a href=&quot;http://dx.doi.org/10.1136/bmj.316.7124.54&quot;&gt;Kerry &amp;amp; Bland (1998)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;More imporantly, using cluster sizes as weights does &lt;em&gt;not&lt;/em&gt; perfectly account for violations of the independence assumption, i.e. it does not guarantee that the Type-I error rate will be at its nominal level.
I noticed this problem when running some simulations for a previous blog post.
You can read about the details below or skip straight to the discussion.&lt;/p&gt;

&lt;h3 id=&quot;the-simulation&quot;&gt;The simulation&lt;/h3&gt;
&lt;p&gt;The full simulation code is available from &lt;a href=&quot;https://github.com/janhove/janhove.github.io/blob/master/RCode/SimulateWeightedTTestClusters.R&quot;&gt;GitHub&lt;/a&gt;.
Here, I’ll just give you the main points.&lt;/p&gt;

&lt;p&gt;The code first creates a dataset in individual data points form a number of clusters. The size of the cluster varies between clusters, and half of the clusters is assigned to the control condition and half to the intervention condition. There is both within- and between-cluster variance in the outcome measure (i.e., there is statistical clustering), but the intervention did not have any effect whatsoever (i.e., the null hypothesis is true).&lt;/p&gt;

&lt;p&gt;Then, three analyses are carried out on the data. The first analysis ignores clustering altogether: a &lt;em&gt;t&lt;/em&gt;-test on the participants’ outcomes. The second analysis is the weighted &lt;em&gt;t&lt;/em&gt;-test introduced above: the data analysed are the cluster means, weighted for cluster size. The third analysis is an unweighted &lt;em&gt;t&lt;/em&gt;-test on the cluster means. The p-values of each analysis are saved and the process is repeated a number of times.&lt;/p&gt;

&lt;p&gt;For this simulation, I set the number of clusters to 10 (5 in the control, 5 in the intervention condition) with cluster sizes 8, 10, 13, 14, 41, 45, 50, 62, 80 and 86. (You’re welcome to change these numbers.) The intra-class correlation coefficient, which expresses the degree of clustering, was set to 0.1. The simulation was run 10,000 times.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;
&lt;p&gt;Seeing as the null hypothesis in this simulation was true, we should expect to find a significant difference between the control and intervention conditions in only 5% of cases.
The &lt;strong&gt;naive analysis&lt;/strong&gt; – the one that ignored clustering – had a hugely inflated &lt;strong&gt;Type-I error rate of 44%&lt;/strong&gt;, which doesn’t come as a surprise.
However, the &lt;strong&gt;weighted &lt;em&gt;t&lt;/em&gt;-test&lt;/strong&gt; also had an inflated Type-I error rate: it returned spurious significance in &lt;strong&gt;9%&lt;/strong&gt; of cases.
The &lt;strong&gt;unweighted &lt;em&gt;t&lt;/em&gt;-test&lt;/strong&gt;, by contrast, was on par with a &lt;strong&gt;5%&lt;/strong&gt; Type-I error rate.&lt;/p&gt;

&lt;p&gt;The numbers for the naive analysis and the weighted t-test vary depending on the ICC and the cluster sizes, 
but what’s important is that &lt;em&gt;t&lt;/em&gt;-tests on cluster means weighted for cluster size find too many false positives.&lt;/p&gt;

&lt;h3 id=&quot;discussion-and-conclusion&quot;&gt;Discussion and conclusion&lt;/h3&gt;
&lt;p&gt;I’m not sure where the recommendation to use &lt;em&gt;t&lt;/em&gt;-tests with cluster means weighted for cluster size for analysing cluster-randomised experiments ultimately originates.
In their book-length treatment of clusted-randomised experiments, &lt;a href=&quot;http://www.clusterrandomisedtrials.com/&quot;&gt;Hayes &amp;amp; Moulton (2009)&lt;/a&gt;&lt;br /&gt;
list the weighted &lt;em&gt;t&lt;/em&gt;-test as a &lt;em&gt;theoretical&lt;/em&gt; alternative to the unweighted &lt;em&gt;t&lt;/em&gt;-test on cluster means. (Actually, cluster proportions, but they claim that “[t]he extension to means and rates is obvious” (p. 178)). 
But the weights they propose aren’t merely the cluster sizes, but &lt;em&gt;m / (1 + ICC * (m - 1))&lt;/em&gt; (where &lt;em&gt;m&lt;/em&gt; is the cluster size and ICC the intra-class correlation coefficient).
Using these weights in the simulation does result in a 5% Type-I error rate.
As Hayes &amp;amp; Moulton note, however, this weighting requires that the ICC be known with great precision, which isn’t usually the case. 
Hence, they do not “generally recommend use of the weighted &lt;em&gt;t&lt;/em&gt;-test unless there are good prior estimates of [the ICC]” (p. 179).&lt;/p&gt;

&lt;p&gt;In conclusion, weighting cluster means for cluster size is not generally recommended.
Unweighted &lt;em&gt;t&lt;/em&gt;-tests on cluster means are still available as a straightforward alternative with an on-par Type-I error rate, whereas multilevel models present the analyst with more flexibility as regards the inclusion of covariates, modelling further hierarchical dependencies etc.&lt;/p&gt;

&lt;h3 id=&quot;another-correction&quot;&gt;Another correction&lt;/h3&gt;
&lt;p&gt;In the &lt;a href=&quot;http://www.ssllt.amu.edu.pl/images/vol.5.no.1/SSLLT%205%281%29%20135-152%20Vanhove.pdf&quot;&gt;&lt;em&gt;Analyzing randomized controlled interventions&lt;/em&gt;&lt;/a&gt; paper, I included a graph to illustrate how Type-I error rates soar when clustering is ignored (Figure 1 on page 143). When running simulations, I noted that this graph slightly exaggerated the Type-I error inflation. The reason is that my analytical derivation of the Type-I error rate contained some errors.&lt;/p&gt;

&lt;p&gt;Luckily, &lt;a href=&quot;http://dx.doi.org/10.3102/1076998606298040&quot;&gt;Hedges (2007)&lt;/a&gt; provides an analytical derivation whose results do agree with the simulated Type-I error rates. For the record, here it is in R form, along with the corrected plot:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;typeI.fnc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Computation from Hedges 2007,
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# where ICC is the intra-class correlation coefficient, 
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# k the number of clusters and 
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# m the number of observations per cluster
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ICC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;critical.value.t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.975&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;critical.value.t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2016-02-16-cluster-randomisation-correction/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 1 – corrected:&lt;/strong&gt; Type-I error rates for cluster-randomized experiments when analyzed by means of a t-test on the participants’ scores as a function of the intraclass correlation coefficient (ICC) and the number of participants per cluster (m). For this graph, the number of clusters was fixed at 10, but the Type-I error rate differs only slightly for different numbers of clusters.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The take-home message from both graphs is the same (&lt;em&gt;ignoring clustering drastically increases Type-I error rates, more so for larger clusters and larger ICC values&lt;/em&gt;), but the precise Type-I error rates are somewhat lower. &lt;/p&gt;
</content>
        </entry>
                    
        <entry>
            <title>Drawing a scatterplot with a non-linear trend line</title>
            <link href="http://janhove.github.io/reporting/2015/11/17/scatterplot-trendline/" />
            <published>2015-11-17T00:00:00+01:00</published>
            <updated>2015-11-17T00:00:00+01:00</updated>
            <id>http://janhove.github.io/reporting/2015/11/17/scatterplot-trendline/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2015/11/17/scatterplot-trendline/">&lt;p&gt;This blog post is a step-by-step guide to drawing scatterplots with non-linear trend lines in &lt;a href=&quot;http://r-project.org&quot;&gt;R&lt;/a&gt;.
It is geared towards readers who don’t have much experience with drawing statistical graphics and who aren’t entirely happy with their attempts in Excel.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;When flicking through an issue of a journal on language research or when attending a conference, 
chances are you’ll harvest a fair number of unclear, uninformative, for-the-record-only graphs.
This is unfortunate, as a good graph serves two important purposes:&lt;/p&gt;

&lt;p&gt;First, it can alert the researcher to aspects of the data that aren’t obvious from a purely numerical description, such as outliers, coding errors, non-linearities, and skewed distributions.&lt;/p&gt;

&lt;p&gt;Second, while a good graph can be difficult to construct, it should – by virtue of being a &lt;em&gt;good&lt;/em&gt; graph – be straightforward to comprehend with little guidance on the part of the author or presenter. 
In my view, a good graph provides a reasonably accurate picture of the main patterns in the data and of how the raw data relate to these patterns – i.e. is there a lot of variation or do the individual data points map closely onto the patterns?
This makes graphs – rather than numerical descriptions or significance tests – essential for presenting research results to an audience, especially one that may not be familiar with advanced statistical techniques or even
one that may not be entirely comfortable with concepts such as, say, standard deviations or confidence intervals (any casual definition of either of which is almost certainly wrong).&lt;/p&gt;

&lt;p&gt;Since knowing how to draw a good graph is bound to be a useful skill for our students – whether they’ll become 
researchers themselves or will have to communicate research data to policy makers and teachers – 
I’ve decided I’m going to stress it more in my teaching.
This blog post is a step-by-step solution to an exercise I gave my students.
While they were free to use whatever program they wanted, I’m going to use R in this solution.
The main reason is that I’m most familiar with it myself. 
In addition, the plots it produces look pretty clean and professional (I often find Excel graphs to be pig ugly, but that’s me), and it’s easier to tell you which commands you have to type at the R prompt than what you have to select and click in Excel.&lt;/p&gt;

&lt;h3 id=&quot;installing-r-and-ggplot2&quot;&gt;Installing R and ggplot2&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Go to &lt;a href=&quot;http://r-project.org&quot;&gt;http://r-project.org&lt;/a&gt;. Download and install R. R is a free but powerful environment for conducting statistical analyses and drawing graphs.&lt;/li&gt;
  &lt;li&gt;Go to &lt;a href=&quot;http://www.rstudio.com&quot;&gt;http://www.rstudio.com&lt;/a&gt;. Download and install RStudio. R itself is run on a command line; RStudio provides a more organised user interface for R.&lt;/li&gt;
  &lt;li&gt;Open RStudio. At the prompt (bottom left, the line starting with ‘&amp;gt;’), type the following command:&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;install.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;ggplot2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This installs a (free) add-on package, &lt;code&gt;ggplot2&lt;/code&gt;, that provides powerful plotting capabilities.
Make sure you type (or copy-paste) the command verbatim – if you type &lt;code&gt;install.package(&quot;ggplot2&quot;)&lt;/code&gt; (without the s), R will return an error. Likewise if you type &lt;code&gt;INSTALL.PACKAGES(&quot;ggplot2&quot;)&lt;/code&gt; (in caps).&lt;/p&gt;

&lt;h3 id=&quot;reading-in-data&quot;&gt;Reading in data&lt;/h3&gt;

&lt;p&gt;The data for this exercise are available from &lt;a href=&quot;http://janhove.github.io/datasets/sinergia.csv&quot;&gt;http://janhove.github.io/datasets/sinergia.csv&lt;/a&gt;.
Download this file and save it locally. 
To import it into R, enter the following command at the prompt (again verbatim):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file.choose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A window will now open where you can navigate to the directory where you’ve saved the dataset. 
Select and open the dataset.&lt;/p&gt;

&lt;p&gt;The dataset is now known in R as &lt;code&gt;dat&lt;/code&gt;. To get an outline of the dataset, you can run the &lt;code&gt;str()&lt;/code&gt; command with &lt;code&gt;dat&lt;/code&gt; as its argument (the lines beginning with ‘##’ show the output of the command; you don’t have to type this yourself):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## &#39;data.frame&#39;:	163 obs. of  10 variables:
##  $ Subject: int  64 78 134 230 288 326 447 527 545 550 ...
##  $ Spoken : int  23 19 24 12 12 20 22 9 19 22 ...
##  $ Written: int  25 20 12 26 9 24 25 15 14 24 ...
##  $ Sex    : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 1 1 2 2 2 1 1 2 1 1 ...
##  $ Age    : int  27 47 33 84 28 32 53 71 16 52 ...
##  $ NrLang : int  4 3 3 4 4 3 3 2 3 3 ...
##  $ BWDS   : int  7 8 6 7 9 6 8 8 4 5 ...
##  $ WST    : num  34 33 32 37 35 35 34 34 29 35 ...
##  $ Raven  : int  28 26 24 20 24 19 16 15 21 15 ...
##  $ English: num  2.394 -0.0314 -0.4751 0.4915 1.7437 ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;drawing-a-scatterplot&quot;&gt;Drawing a scatterplot&lt;/h3&gt;

&lt;p&gt;The goal is to visualise the relationship between the self-explanatory &lt;code&gt;Age&lt;/code&gt; variable and &lt;code&gt;Raven&lt;/code&gt;, which contains the participants’ results on a cognitive task.
The workhorse plot for showing the relationship between two continuous variables such as these is the &lt;strong&gt;scatterplot&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The basic idea behind a scatterplot is simple: 
each pair of (Age, Raven) observations is shown in an XY plane.
There’s no need to group together participants by decade;
you don’t have to compute the average Raven score per age group etc. – &lt;strong&gt;you just show the data you have&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;There are a couple of ways to draw a scatterplot in R. 
For this tutorial we’ll use the functions in the &lt;code&gt;ggplot2&lt;/code&gt; package.
To activate these functions, run the following command:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;By default, &lt;code&gt;ggplot2&lt;/code&gt; draws plots on a grey background.
Personally, I prefer a white background, so I tell &lt;code&gt;ggplot2&lt;/code&gt; to switch its default theme to black and white:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;theme_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_bw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To draw any plot, we need to tell the program where it can find the &lt;code&gt;data&lt;/code&gt; and which information should go where.
In this case, the data can be found in the dataset called &lt;code&gt;dat&lt;/code&gt;,
and it makes sense to plot the &lt;code&gt;Age&lt;/code&gt; information along the &lt;code&gt;x&lt;/code&gt; axis and the &lt;code&gt;Raven&lt;/code&gt; scores along the &lt;code&gt;y&lt;/code&gt; axis.
(As a rule of thumb, if it’s more likely that one variable affects another variable than vice versa, put the first variable along the x axis.)
All of this is defined in the &lt;code&gt;ggplot&lt;/code&gt; function (first two lines).
The third line then specifies what we want to do with these data.
Here, we want to plot a point for each pair of (Age, Raven) observations.
The lay-out of this graph is stored as &lt;code&gt;p&lt;/code&gt; (this is what the &lt;code&gt;&amp;lt;-&lt;/code&gt; in the first line does).
To display the graph, simply type &lt;code&gt;p&lt;/code&gt; at the prompt.
The hashes introduce comments that are ignored by the program but that are useful for documenting what you’re doing.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# specify dataset
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Raven&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Age on x-, Raven on y-axis
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# plot points (pch = 1: circles, type &#39;?pch&#39; for other options)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-11-17-scatterplot-trendline/unnamed-chunk-7-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;This scatterplot strongly suggests the presence of a non-linear age effect: Raven performance increases up through about age 20-25 and then decreases with age. 
Additionally, there don’t seem to be any wildly outlying points that may be indicative of coding errors and the like.
Both of these points are useful to know:
the first because it indicates that common tools such as linear regression or correlations would mischaracterise the relationship between age and Raven score;
the second because such outliers would’ve require us to go back to the raw data and check whether they make sense.&lt;/p&gt;

&lt;p&gt;When this scatterplot is to be used in a publication or for a presentation, it may need a bit of polishing, though.
First, while the axis labels are pretty straightforward here, that’s not always the case.
To change them, we can take the plot object, &lt;code&gt;p&lt;/code&gt;, and explicitly add an &lt;code&gt;xlab()&lt;/code&gt; and a &lt;code&gt;ylab()&lt;/code&gt; argument to it:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Age (years)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# add label for x axis
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Raven&#39;s Matrices (score)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# add label for y axix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-11-17-scatterplot-trendline/unnamed-chunk-8-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Second, it may be useful to highlight the non-linear pattern in the data.
To this end, we can add a scatterplot smoother to the plot.
The algorithm behind such a smoother essentially fits a number of best-fitting curves to subsets of the data and then glues them together:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;q1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# add scatterplot smoother
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## geom_smooth: method=&quot;auto&quot; and size of largest group is &amp;lt;1000, so using loess. Use &#39;method = x&#39; to change the smoothing method.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-11-17-scatterplot-trendline/unnamed-chunk-9-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;The warning message informs us that we didn’t specify any one algorithm for drawing the smoother, so it defaulted to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Local_regression&quot;&gt;loess&lt;/a&gt; algorithm. 
The blue curve is the scatterplot smoother; the grey band about it is a 95% confidence band.
For this exercise, I prefer to turn this confidence band off (&lt;code&gt;se = FALSE&lt;/code&gt;) as it moves us into the realm of inferential statistics – for now, I’d rather stick to plotting and descriptive statistics.
The appearence of the curve itself can be changed, too, e.g. by making it a bit thicker (&lt;code&gt;width&lt;/code&gt;) and colouring it black.&lt;/p&gt;

&lt;p&gt;Additionally, we can change the default smoothing algorithm.
One alternative for drawing non-linear curves is to use a generalised additive model (see &lt;a href=&quot;http://janhove.github.io/analysis/2015/10/16/nonlinear-relationships/&quot;&gt;this blog post&lt;/a&gt;).
The logic behind it is pretty similar to the one behind loess curves, though:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;q2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;black&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# black line
&lt;/span&gt;              &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# slightly thicker
&lt;/span&gt;              &lt;span class=&quot;n&quot;&gt;se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# turn off confidence band
&lt;/span&gt;              &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;gam&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# use &#39;gam&#39; instead of default (loess)
&lt;/span&gt;              &lt;span class=&quot;n&quot;&gt;formula&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# specify gam formula
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-11-17-scatterplot-trendline/unnamed-chunk-10-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;By default, the &lt;code&gt;gam&lt;/code&gt; function estimates the form of the curve by fitting so-called thin-plate regression splines.
The details don’t matter here, but a disadvantage of this default is that it assumes that the curve has the same degree of ‘wiggliness’ everywhere.
What this means is that the increased rate of deterioration around age 50 and the decreased rate of deterioration around age 60 needn’t be ‘there’: they may just be the result of the function trying to accommodate the fact that a constant degree of wiggliness was implicitly assumed.
In other words, it may add wiggles to the end of the curve (where there may not be any) in order to be able to add wiggles to the start of the curve (where they’re clearly needed).
If you have enough data, you can use so-called ‘adaptive’ smooths instead:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;q3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;black&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;gam&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;formula&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ad&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# use &#39;adaptive&#39; spline
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q3&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-11-17-scatterplot-trendline/unnamed-chunk-11-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;This graph succeeds in highlighting both the average age trend in the data and showing the scatter about that trend and doesn’t sweep any unbecoming data under the rug. 
I’m also pretty confident that this graph can be interpreted by experts and laypeople alike: while they may not know the algorithm behind the curve, it’s the meaning of the curve that’s of interest. And its meaning is obvious.&lt;/p&gt;
</content>
        </entry>
                  
        <entry>
            <title>Causes and consequences of unequal sample sizes</title>
            <link href="http://janhove.github.io/design/2015/11/02/unequal-sample-sized/" />
            <published>2015-11-02T00:00:00+01:00</published>
            <updated>2015-11-02T00:00:00+01:00</updated>
            <id>http://janhove.github.io/design/2015/11/02/unequal-sample-sized/</id>
            <content type="html" xml:base="http://janhove.github.io/design/2015/11/02/unequal-sample-sized/">&lt;p&gt;In this blog post, I want to dispel a myth that’s reasonably common among students: the notion that there’s something wrong about a study that compares groups of different sizes.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;goal&quot;&gt;Goal&lt;/h3&gt;
&lt;p&gt;There is something aesthetically pleasing about studies that compare two equal-sized groups. An experiment with two conditions with 30 participants each looks ‘cleaner’ than one with 27 participants in one condition and 34 in the other. Whatever the reasons for this aesthetic appeal may be, I’m going to argue that there’s nothing un-kosher about unequal sample sizes per se. This post is geared first and foremost to our MA students, primarily to help them get rid of the idea that they should throw away data in order to perfectly balance their datasets.&lt;/p&gt;

&lt;p&gt;There are three main causes of unequal sample sizes: simple random assignment of participants to conditions; planned imbalances; and drop-outs and missing data. I will discuss these in order.&lt;/p&gt;

&lt;h3 id=&quot;simple-randomisation-as-the-cause-of-sample-size-imbalance&quot;&gt;Simple randomisation as the cause of sample size imbalance&lt;/h3&gt;
&lt;p&gt;The random assignment of participants to the different conditions is the hallmark of a ‘true experiment’ and distinguishes it from ‘quasi-experiments’. Random assignment can be accomplished in essentially two different ways. The first technique is &lt;strong&gt;complete randomisation&lt;/strong&gt;: 
first, sixty participants are recruited; then, half of them are randomly assigned to the control and half to the experimental condition. 
This technique guarantees that an equal number of participants is assigned to both conditions. 
The second technique is &lt;strong&gt;simple randomisation&lt;/strong&gt;: for each participant that volunteers for the experiment, there’s a 50/50 chance that she ends up in the control or in the experimental condition – regardless of how large either sample already is. 
Simple randomisation causes unequal sample sizes: you’re not guaranteed to get &lt;em&gt;exactly&lt;/em&gt; 30 heads in 60 coin flips, and similarly you’re not guaranteed to get exactly 30 participants in either condition.&lt;/p&gt;

&lt;p&gt;(Note: Some refer to ‘simple randomisation’ as ‘complete randomisation’, so check how the procedures are described when reading about randomisation techniques.) &lt;/p&gt;

&lt;p&gt;Unequal sample sizes, then, may be the consequence of using simple rather than complete randomisation. And there can be good reasons for choosing simple rather than complete randomisation as your allocation technique, notably a reduced potential for selection bias (see &lt;a href=&quot;http://www.trialsjournal.com/content/16/1/405/abstract&quot;&gt;Kahan et al. 2015&lt;/a&gt;) and ease of planning (it’s easier to let the experimental software take care of the randomisation than to keep track of the number of participants in each condition as participants find their way to the lab).&lt;/p&gt;

&lt;p&gt;Compared to complete randomisation, simple randomisation seems to have a distinct disadvantage, however: an experiment with 60 participants in total has more power, i.e. a better chance to find systematic differences between the conditions, if the participants are distributed evenly across the conditions (i.e. 30/30, complete randomisation) than if they’re distributed unevenly (e.g. 20/40). (This is assuming that the variability in both conditions is comparable.) For this reason, it’s usually much better to have 50 participants in both conditions rather than 20 in one condition and 200 in the other – even though the total number of participants is much greater in the second set-up. Simple randomisation, however, can cause such imbalances. In fact, it’s possible to end up with &lt;em&gt;no&lt;/em&gt; participants in one of the groups.&lt;/p&gt;

&lt;p&gt;But. While stark imbalances are &lt;em&gt;possible&lt;/em&gt; when using simple randomisation, they’re also pretty improbable. Figure 1 shows the probability of ending up with any number of participants in one condition when 60 participants are randomly assigned to one of two conditions with equal probability. As this graph illustrates, it’s highly improbable to end up with 10 participants in the first condition (and 50 in the other). In fact, in 999 out of 1,000 cases, you’ll end up with between 17 and 43 participants in each group.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-11-02-unequal-sample-sized/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Figure 1: Probability that simple randomisation will give rise to a specific numbers of participants in one condition if the total number of participants is 60 and they are assigned to one of two conditions with equal probability and independently of one another.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Additionally, while equal-sized groups maximise statistical power, the advantage is easily overstated. An experiment with 30+30 participants has a 76% chance to detect a systematic difference of 0.7 standard deviations between the two group means; for an experiment with 20+40 participants, this probability is 71%. On average, an experiment in which 60 participants are assigned to the conditions according to a simple randomisation procedure has 75% power to detect a difference of 0.7 standard deviations. The difference in power between complete randomisation (guaranteeing equal sample sizes) and simple randomisation, then, is minimal. Table 1 compares a couple of additional set-ups, and all point to the same conclusion: &lt;strong&gt;the loss of power associated with simple vs. complete randomisation is negligible.&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Table 1: Comparison of the power of an experiment using complete randomisation (equal sample sizes) and the average power of an experiment using simple randomisation (possibly unequal sample sizes). The R code for the comparison is at the bottom of this post.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Total number of participants&lt;/th&gt;
      &lt;th&gt;Difference (sd)&lt;/th&gt;
      &lt;th&gt;Power complete randomisation (t-test)&lt;/th&gt;
      &lt;th&gt;Power simple randomisation (t-test)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;0.32&lt;/td&gt;
      &lt;td&gt;0.30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;0.76&lt;/td&gt;
      &lt;td&gt;0.75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;0.97&lt;/td&gt;
      &lt;td&gt;0.97&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;0.3&lt;/td&gt;
      &lt;td&gt;0.10&lt;/td&gt;
      &lt;td&gt;0.10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;0.3&lt;/td&gt;
      &lt;td&gt;0.21&lt;/td&gt;
      &lt;td&gt;0.21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;0.3&lt;/td&gt;
      &lt;td&gt;0.37&lt;/td&gt;
      &lt;td&gt;0.37&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Simple randomisation and the unequal sample sizes it gives rise to, then, aren’t much of a problem when comparing the means of two groups. For more complex (factorial) designs, however, they do present some complications. Specifically, cell size imbalances in factorial designs force the analyst to decide whether the effects should be estimated by means of Type I, Type II or Type III &lt;strong&gt;sums of squares&lt;/strong&gt; (see &lt;a href=&quot;http://goanna.cs.rmit.edu.au/~fscholer/anova.php&quot;&gt;the explanation by Falk Scholer&lt;/a&gt;). I don’t feel qualified to give any definite advice in this matter other than to point out the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;What’s usually (though not invariably) of interest in a factorial design is the interaction between the predictors rather than their main effects.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The conclusions about the highest-order interaction aren’t affected by the choice between Type I, Type II or Type III sums of squares. In the most common case, if you have two independent variables, the test for the interaction between them gives the same result irrespective of your sums of squares choice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;So, if you’re interested in this interaction and not so much in the independent effects of the predictors, it doesn’t really matter.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In conclusion, sample size imbalances can be the result of assigning participants to conditions by means of simple randomisation. When comparing two groups, this doesn’t really present any problems. When the study has a factorial design, though, you may want to brush up on Type I/II/III sums of squares. But whatever you do, &lt;strong&gt;don’t throw away precious data just to make the group sizes equal.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;planned-imbalances&quot;&gt;Planned imbalances&lt;/h3&gt;
&lt;p&gt;Researchers sometimes intentionally recruit a greater number of participants in one condition than in the other. This seems to be particularly the case in quasi-experiments, i.e. studies in which the allocation of participants to condition is predetermined rather than manipulated by the researcher (e.g. comparisons of native speakers to foreign language learners). From what I can tell, the (usually tacit) reasons for such imbalances include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;accessibility problems and financial cost: It may be more difficult or more costly to recruit participants in secluded villages than university students;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;a relative lack of interest: Comparisons within, say, the Learner group may be considered more interesting than comparisons between the Learner and the Native Speaker group;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;less variability in one group: One group may be considerably more homogeneous with respect to some linguistic behaviour than the other one, so you gain less by recruiting participants for one group than for the other.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, even when the unequal sample sizes were planned and not due to simple randomisation,
they may be a matter of sound reasoning and practicality rather than of poor design.&lt;/p&gt;

&lt;h3 id=&quot;drop-outs-and-missing-data&quot;&gt;Drop-outs and missing data&lt;/h3&gt;
&lt;p&gt;Imbalances can arise when participants drop out of the study or when data is lost due to technical glitches. These cases are different from the previous two (simple randomisation and planned imbalances) as they needn’t be due to different numbers of participants being &lt;em&gt;assigned&lt;/em&gt; to the experiment’s conditions. Rather, at the end of the study, different numbers of participants &lt;em&gt;remain&lt;/em&gt; there to be analysed.&lt;/p&gt;

&lt;p&gt;When data are lost due to, say, computer malfunctions, the loss of data can reasonably be expected not to skew the study’s results by occurring more often in one condition than in the other or by primarily affecting high or low performers etc. In this case, the lost data are said to be &lt;strong&gt;missing completely at random&lt;/strong&gt;. While such losses of data are unfortunate as they lead to a loss of statistical power, they’re benign in that you can just discount the missing data and run your analyses on the remaining data without introducing bias. (Alternatively, the analyst could try to impute the missing data, but that’s for another time.)&lt;/p&gt;

&lt;p&gt;Not all missing data are missing completely at random, however. 
Say that an experimental study finds that children in L2 immersion classes outperform children in the control group (traditional classes) in subjects such as geography and biology. Such a finding could well be interpreted as evidence for bilingual advantages extending into scholastic performance. Now imagine that out of the 230 children starting the school year in an L2 class, 80 switched to traditional classes and dropped out of the study (35%), whereas out of the 200 children starting out in the control group, 20 went off the radar (10%). All of a sudden, the picture for L2 immersion looks bleaker: it’s plausible that it’s especially the pupils that would’ve performed poorly dropped out of the L2 immersion classes, and that the positive effect is the result of L2 immersion being more &lt;em&gt;selective&lt;/em&gt; rather than being more &lt;em&gt;effective&lt;/em&gt;. In such cases, the lost data are said to be &lt;strong&gt;not missing at random&lt;/strong&gt;. Indeed, the very fact that more data are missing in the L2 immersion group than in the control condition is &lt;strong&gt;informative in its own right&lt;/strong&gt; and should be taken into account when evaluating the efficacy of L2 immersion.&lt;/p&gt;

&lt;p&gt;(There’s a third kind of ‘missingness’, viz. &lt;em&gt;missing at random&lt;/em&gt;, which describes the situation in which the missingness can be accounted for by control variables.)&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;p&gt;The main points to take away from this blog post are the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A sample size imbalance isn’t a tell-tale sign of a poor study.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You don’t need equal-sized groups to compute accurate statistics.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the sample size imbalance is due to drop-outs rather than due to design, simple randomisation or technical glitches, this is something to take into account when interpreting the results.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Whatever you do, don’t throw away data.&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;r-code-average-power-of-experiments-with-simple-randomisation&quot;&gt;R code: Average power of experiments with simple randomisation&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Load pwr package
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pwr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# To compute power for complete randomisation, use:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pwr.t.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;power&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.76&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Note&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;n is number in each group&#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For experiments where the allocation was done using simple randomisation,
we need to compute the power of each possible combination of sample sizes
and weight it by its probability of occurrence.
The &lt;code&gt;pwr.t2n.test()&lt;/code&gt; function will return an error when the sample size in one condition is 0 or 1, so we’ll manually set the power for these cases to 0.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;weighted.power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total.n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Compute power for n1 = 2, 3 etc. n-2
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# And add 0 for n1 = 0, 1, n-1 and n
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;power.unbalanced&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pwr.t2n.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total.n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
                                           &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total.n&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                           &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;power&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Compute probability of each n1/n2 combination occurring
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbinom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total.n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total.n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Compute weighted average and return
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weighted.mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;power.unbalanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;weighted.power&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total.n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.75&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
                  
        <entry>
            <title>The problem with cutting up continuous variables and what to do when things aren&#39;t linear</title>
            <link href="http://janhove.github.io/analysis/2015/10/16/nonlinear-relationships/" />
            <published>2015-10-16T00:00:00+02:00</published>
            <updated>2015-10-16T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2015/10/16/nonlinear-relationships/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2015/10/16/nonlinear-relationships/">&lt;p&gt;A common analytical technique is to cut up continuous variables (e.g. age, word frequency, L2 proficiency) into discrete categories and then use them as predictors in a group comparison (e.g. ANOVA). 
For instance, stimuli used in a lexical decision task are split up into a high-frequency and a low-frequency group, whereas the participants are split up into a young, middle, and old group. 
Although discretising continuous variables appears to make the analysis easier, this practice has been criticised for years. 
Below I outline the problems with this approach and present some alternatives.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;problem-1-loss-of-information-and-its-consequences&quot;&gt;Problem 1: Loss of information and its consequences&lt;/h3&gt;
&lt;p&gt;The problem with discretising continuous variables is that it throws away meaningful information. 
This loss of information is most pronounced in the case of dichotomisation (carving up a continuous variable into two levels).
When splitting up words into a high- and a low-frequency group, 
within-group information about relative frequency differences is lost – extremely frequent words and somewhat frequent words are treated as though they had the same frequency.
Doing so leads to an appreciable &lt;strong&gt;loss of power&lt;/strong&gt;, i.e. a decrease in the probability of finding a pattern if there really is one 
(&lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1458573/&quot;&gt;Altman &amp;amp; Royston 2006&lt;/a&gt;; 
&lt;a href=&quot;http://www.unc.edu/~rcm/psy282/cohen.1983.pdf&quot;&gt;Cohen 1983&lt;/a&gt;; 
&lt;a href=&quot;http://www.psychology.sunysb.edu/attachment/measures/content/maccallum_on_dichotomizing.pdf&quot;&gt;MacCullum et al. 2002&lt;/a&gt;; 
&lt;a href=&quot;http://www-psychology.concordia.ca/fac/kline/734/royston.pdf&quot;&gt;Royston, Altman &amp;amp; Sauerbrei 2006&lt;/a&gt;): 
&lt;a href=&quot;http://www.unc.edu/~rcm/psy282/cohen.1983.pdf&quot;&gt;Cohen 1983&lt;/a&gt; shows that carving up a continuous variable into two groups is akin to throwing away a third of the data. 
Paradoxically, dichotomisation can sometimes lead to a simultaneous &lt;strong&gt;increase of false positives&lt;/strong&gt;, 
i.e. finding a pattern where there is in fact none 
(&lt;a href=&quot;http://www.researchgate.net/profile/Harold_Delaney/publication/232580560_Bivariate_median_splits_and_spurious_statistical_significance/links/550065790cf2d61f820d6f93.pdf&quot;&gt;Maxwell &amp;amp; Delaney 1993&lt;/a&gt;) – a statistical double whammy.&lt;/p&gt;

&lt;h3 id=&quot;problem-2-spurious-threshold-effects&quot;&gt;Problem 2: Spurious threshold effects&lt;/h3&gt;
&lt;p&gt;Furthermore, discretisation draws categorical boundaries where none exist and may thereby &lt;strong&gt;spuriously suggest the presence of cut-offs or threshold effects&lt;/strong&gt;
(e.g. &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1458573/&quot;&gt;Altman &amp;amp; Royston 2006&lt;/a&gt;; 
&lt;a href=&quot;http://dx.doi.org/10.1371/journal.pone.0069172&quot;&gt;Vanhove 2013&lt;/a&gt;). 
For instance, by grouping 20- to 29-year-olds in one category and 30- to 39-year-olds in another, 
we create the impression that 20- and 29-year-olds tend to be more alike than 29- and 30-year-olds. 
If the outcome variable differs between the groups, it might even be tempting to conclude that some important change occurred in the 30th year.
I suspect – I &lt;em&gt;hope&lt;/em&gt; – that the researchers themselves are aware that such a sudden change is entirely due to their arbitrary cut-off choices,
but these details tend to get lost in citation,
and I wonder to what extent threshold theories in language acquisition owe their existence to continuous predictors being squeezed into the ANOVA straitjacket.&lt;/p&gt;

&lt;h3 id=&quot;solutions&quot;&gt;Solutions&lt;/h3&gt;

&lt;h4 id=&quot;when-the-pattern-is-more-or-less-linear&quot;&gt;When the pattern is more or less linear&lt;/h4&gt;
&lt;p&gt;With the authors cited above, I agree that the best solution is usually to stop carving up continuous phenomena into discrete categories and to instead exploit the continuous data to the full in a &lt;strong&gt;linear regression&lt;/strong&gt; analysis 
(see &lt;a href=&quot;http://www.sfs.uni-tuebingen.de/~hbaayen/publications/baayenML2010matching.pdf&quot;&gt;Baayen 2010&lt;/a&gt;, 
and &lt;a href=&quot;http://dx.doi.org/10.1371/journal.pone.0069172&quot;&gt;Vanhove 2013&lt;/a&gt; for linguistic examples). 
Sometimes, however, the data suggest a non-linear trend that is less easily accommodated in a linear regression model. I turn to such cases next.&lt;/p&gt;

&lt;h4 id=&quot;when-the-pattern-is-non-linear&quot;&gt;When the pattern is non-linear&lt;/h4&gt;
&lt;p&gt;A more sophisticated rationale for carving up a continuous predictor is that the relationship between the predictor and the outcome is not approximately linear. 
By way of example, Figure 1 shows how the performance on some test varies according to the participants’ age (data from &lt;a href=&quot;http://dx.doi.org/10.1515/iral-2015-0001&quot;&gt;Vanhove &amp;amp; Berthele 2015&lt;/a&gt;,
available &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/participants_163.csv&quot;&gt;here&lt;/a&gt;). 
What the data mean is of less importance for our present purposes; 
what is important is that the scatterplot highlights a non-linear trend.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-10-16-nonlinear-relationships/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Scatterplot of the original data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;An ordinary correlation analysis or a simple linear regression model would find a small, positive, non-significant age trend. 
But these analyses test the linear trend in the data, which is clearly not relevant in this case.
Dichotomising the age variable by means of a median split does not bring us much closer to a resolution, however: As the boxplots in the left-hand panel of Figure 2 show, a median split completely hides the trend in the data 
(see also &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1458573/&quot;&gt;Altman &amp;amp; Royston 2006&lt;/a&gt;; 
&lt;a href=&quot;http://www.psychology.sunysb.edu/attachment/measures/content/maccallum_on_dichotomizing.pdf&quot;&gt;MacCullum et al. 2002&lt;/a&gt;). 
A more fine-grained discretisation, e.g., in slices of ten years, underscores the trend appreciably better as shown in the right-hand panel of Figure 2 (see also &lt;a href=&quot;http://www.stat.columbia.edu/~gelman/arm/&quot;&gt;Gelman &amp;amp; Hill 2007&lt;/a&gt;, pp. 66-68). 
But it also raises a number of questions: What is the optimal number of bins? Where should we draw the cut-offs between the bins? Should every bin be equally as wide? And how much can we fiddle about with these bins without jeopardising our inferential statistics?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-10-16-nonlinear-relationships/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 2.&lt;/strong&gt; &lt;em&gt;Left:&lt;/em&gt; Boxplots after a median split of the age variable; the age pattern is unrecognisable. 
&lt;em&gt;Right:&lt;/em&gt; Boxplots after a more fine-grained discretisation; the non-linear pattern is now recognisible, but the cut-offs between the groups were drawn arbitrarily.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Clearly, it is preferable to side-step such arbitrary decisions. 
Apart from transforming the predictor, the outcome or both,
we can deal with non-linearities by modelling them directly.
There are a couple of options available in this domain
(e.g. &lt;a href=&quot;https://en.wikipedia.org/wiki/Local_regression&quot;&gt;LO(W)ESS&lt;/a&gt;,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Polynomial_regression&quot;&gt;polynomial regression&lt;/a&gt;,
restricted cubic splines);
here I’ll briefly demonstrate one of them: &lt;strong&gt;generalised additive modelling&lt;/strong&gt;.
It’s not my goal to discuss the ins and outs of generalised additive modelling,
but rather to illustrate its use and to direct those interested to more thorough sources.
In doing so, I’ll be freely quoting from Section 4.3.2 from my &lt;a href=&quot;http://ethesis.unifr.ch/theses/downloads.php?file=VanhoveJ.pdf&quot;&gt;thesis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Generalised additive models (GAMs) are implemented in the &lt;code&gt;mgcv&lt;/code&gt; package for R.
GAMs estimate the form of the non-linear relationship from the data.
This is essentially accomplished by fitting a kind of regression on subsets of the data and then glueing the different pieces together.
The more subset regression are fitted and glued together, the more ‘wiggly’ the overall curve will be.
Fitting too many subset regressions results in overwiggly curves that fit disproportionally much noise in the data (‘oversmoothing’).
To prevent this, the &lt;code&gt;mgcv&lt;/code&gt; package implements a procedure that estimates the number of subset regression – and hence the complexity of the overall curve – that stands the best chance of predicting new data points.
For details, I refer to Chapter 3 in &lt;a href=&quot;http://www.highstat.com/book2.htm&quot;&gt;Zuur et al. (2009)&lt;/a&gt; and to a tutorial by &lt;a href=&quot;http://www3.nd.edu/~mclark19/learn/GAMS.pdf&quot;&gt;Clark (2013)&lt;/a&gt; for fairly accessible introductions.
An in-depth treatment is provided by &lt;a href=&quot;http://people.bath.ac.uk/sw283/igam/index.html&quot;&gt;Wood (2006)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The following R code reads in the dataset,
plots an unpolished version of the scatterplot in Figure 1 above,
and loads the &lt;code&gt;mgcv&lt;/code&gt; package.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Read in data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/participants_163.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Draw scatterplot of Age vs Spoken (not shown)
# plot(Spoken ~ Age, data = dat)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Load mgcv package;
# run &#39;install.packages(&quot;mgcv&quot;)&#39; if not installed:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mgcv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The GAM is then fitted using the &lt;code&gt;gam()&lt;/code&gt; function, whose interface is similar to that of the &lt;code&gt;lm()&lt;/code&gt; function for fitting linear models.
The embedded &lt;code&gt;s()&lt;/code&gt; function specified that the effect of &lt;code&gt;Age&lt;/code&gt; should be fitted non-linearly (&lt;em&gt;s&lt;/em&gt; for &lt;em&gt;smoother&lt;/em&gt;).
Plotting the model shows the non-linear age trend and its 95% confidence band:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;mod1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Spoken&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-10-16-nonlinear-relationships/unnamed-chunk-4-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;With the &lt;code&gt;summary()&lt;/code&gt; function, numerical details about the model, including approximate inferential statistics,
can be displayed. See &lt;a href=&quot;http://www3.nd.edu/~mclark19/learn/GAMS.pdf&quot;&gt;Clark (2013)&lt;/a&gt; for details.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## Spoken ~ s(Age)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)    16.52       0.32    51.7   &amp;lt;2e-16
## 
## Approximate significance of smooth terms:
##        edf Ref.df    F p-value
## s(Age) 7.4   8.36 15.1  &amp;lt;2e-16
## 
## R-sq.(adj) =  0.429   Deviance explained = 45.5%
## GCV = 17.555  Scale est. = 16.65     n = 163&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;All of this is just to give you a flavour of what you can do when you’re confronted with non-linear data than can’t easily be transformed or fitted with a higher-order polynomials.
GAMs are flexible in that they can incorporate several predictors, non-linear interactions between continuous variables, and random effects, and they can deal with non-Gaussian outcome variables (e.g. binary data), too.&lt;/p&gt;

&lt;p&gt;In conclusion, if you have continuous variables, don’t throw away useful information and treat them as such.
If a scatterplot reveals an approximately linear pattern, linear regression is the way to go.
If a non-linear pattern emerges, consider fitting a non-linear model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-10-16-nonlinear-relationships/unnamed-chunk-6-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; Scatterplot of the original data with a non-linear GAM-based scatterplot smoother and its 95% confidence band.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;r-session-info&quot;&gt;R session info&lt;/h3&gt;
&lt;p&gt;For those interested:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;sessionInfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## R version 3.2.2 (2015-08-14)
## Platform: i686-pc-linux-gnu (32-bit)
## Running under: Ubuntu 14.04.3 LTS
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=de_CH.UTF-8        LC_COLLATE=en_US.UTF-8    
##  [5] LC_MONETARY=de_CH.UTF-8    LC_MESSAGES=en_US.UTF-8   
##  [7] LC_PAPER=de_CH.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=de_CH.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] knitr_1.11   mgcv_1.8-7   nlme_3.1-122
## 
## loaded via a namespace (and not attached):
##  [1] magrittr_1.5    Matrix_1.2-2    formatR_1.2.1   htmltools_0.2.6
##  [5] tools_3.2.2     yaml_2.1.13     stringi_0.5-5   splines_3.2.2  
##  [9] rmarkdown_0.8   grid_3.2.2      stringr_1.0.0   digest_0.6.8   
## [13] evaluate_0.8    lattice_0.20-33&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
                    
        <entry>
            <title>Analysing experiments with intact groups: the problem and an easy solution</title>
            <link href="http://janhove.github.io/design/2015/09/17/cluster-randomised-experiments/" />
            <published>2015-09-17T00:00:00+02:00</published>
            <updated>2015-09-17T00:00:00+02:00</updated>
            <id>http://janhove.github.io/design/2015/09/17/cluster-randomised-experiments/</id>
            <content type="html" xml:base="http://janhove.github.io/design/2015/09/17/cluster-randomised-experiments/">&lt;p&gt;To evaluate a new teaching method, a researcher arranges for one class of 20 students to be taught with the old method and another class of 20 students with the new method.
According to a &lt;em&gt;t&lt;/em&gt;-test, the students taught with the new method significantly outperform the control group at an end-of-year evaluation.
The set-up of studies like these is pretty standard in applied linguistics – but it is fatally flawed.
In this post, I explain the problem with comparing intact groups using traditional statistical tools and 
present a solution that’s easy to both understand and implement.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;the-problem&quot;&gt;The problem&lt;/h3&gt;
&lt;p&gt;In a textbook experiment, the 40 students from the example above would have been assigned to one of the teaching methods randomly and on an individual basis.
In the example above, however, the assignment to one of the teaching methods wasn’t done individually but class-by-class, so that all students in the same class were taught using the same method.&lt;/p&gt;

&lt;p&gt;The difference may seem minute – after all, we end up with about 20 participants in either group, so who cares?
However, assigning participants to experimental conditions class-by-class – in what is called a &lt;strong&gt;cluster-randomised experiment&lt;/strong&gt; – leads to a problem known as &lt;strong&gt;clustering&lt;/strong&gt;: Due to selection processes, a common background, having the same teachers, etc., two students in the same class tend to be somewhat more alike than two students from different classes.
This, in turn, means that the information that each participant contributes to the study isn’t entirely new: if someone’s class-mates have above-average reading skills, chances are she too will have above-average reading skills, regardless of the teaching method.
Rather than having 40 participants,
the researcher in the example above could have the equivalent of, say, 8, 14 or 32 participants per group in terms of the information that the sample contains.&lt;/p&gt;

&lt;p&gt;The degree of clustering is expressed in the &lt;strong&gt;intra-class correlation&lt;/strong&gt; (ICC). This number takes a value between 0 and 1. An ICC of 1 means that all values within a cluster (e.g. a class) are identical to each other so that multiple observations per cluster don’t contribute any information to the study. An ICC of 0 means that values within a cluster are no more alike that values from different clusters. For reference, typical ICC values fall in the 0.15 to 0.20 bracket in educational contexts.&lt;/p&gt;

&lt;p&gt;Ordinary &lt;em&gt;t&lt;/em&gt;-tests and ANOVAs as well as correlation and regression analyses don’t take into account the clustered nature of such data. Instead, they assume that each datapoint is independent of any other.
This may seem like a technicality, but its effect is staggering.
Conventionally, a statistical test has a 5% chance of detecting a ‘significant effect’ even if nothing is going on. This is known as the Type-I error rate.
If clustered data are analysed without taking the clustering into account, the Type-I error rate could easily rise to 40% or more.
Crucially, even seemingly negligible degrees of clustering bloat the Type-I error rate.
Figure 1 shows how the actual Type-I error rate increases as the ICC becomes larger and as the number of participants per cluster increases if the clustered nature of the data is not taken into account.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-09-17-cluster-randomised-experiments/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Spurious significance in cluster-randomised experiments analysed using traditional &lt;em&gt;t&lt;/em&gt;-tests according to the intra-class correlation (&lt;em&gt;ICC&lt;/em&gt;) and the number of participants per cluster (&lt;em&gt;m&lt;/em&gt;).
The number of clusters was fixed at 10, but the Type-I error rate differs only slightly for different numbers of clusters.
&lt;em&gt;Reading guide:&lt;/em&gt; If you carry out a cluster-randomised experiment with 10 classes of 20 (&lt;em&gt;m&lt;/em&gt;, green line) students each and run an ordinary &lt;em&gt;t&lt;/em&gt;-test on the resultant 200 data points, you have a 17% chance of observing a significant difference even if no real difference exists (for an intra-class correlation of 0.05) rather than the nominal 5% chance. Common ICC values in educational contexts are in the 0.15 to 0.20 bracket.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The intuition behind these bloated Type-I error rates is this. If you compare two groups of 10 participants each but you pretend to compare two groups of 100 participants each (e.g. by entering each participant’s outcome ten times), you overestimate the degree of confidence you have in your results. 
Similarly, if you have 40 participants that are the informational equivalent of only 20 participants, you overestimate your confidence in the results.&lt;/p&gt;

&lt;p&gt;Clustered data are fairly common in applied linguistics and the language sciences at large, and often for good reason. For instance, it may not be feasible to randomly assign students to teaching methods on an individual basis, or doing so may jeopardise the ecological validity of the study.
But regardless of whether a cluster-randomised experiment is well-motivated,
the clustering it gives rise to needs to be taken into account in order to arrive at statistically valid results.
Before discussing how this can be done, here are some examples of common clustered designs so that you may more easily identify clustered data when you stumbled across them:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;94 students from 6 classes participate in an intervention study. To improve the study’s ecological validity, students in the same class are all assigned to the same experimental condition. If you see a &lt;em&gt;t&lt;/em&gt;-test with 92 (i.e. 94 - 2) degrees of freedom (e.g. ‘t(92) = 2.3, p = 0.02’), the analysis is overwhelming likely not to have taken into account clustering and probably underestimates the Type-I error rate. In a word, the analysis is invalid.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The length of the KIT vowel ([I]) is measured in 15 bilinguals and 13 monolinguals. A total of 840 tokens are collected. In the Results section, you find the following: “We found a significant length difference between [I] sounds produced by bilinguals (n = 450, M = 72 ms, SD = 29 ms) and those produced by the monolingual controls (n = 390, M = 87 ms, SD = 28 ms; t(838) = 7.38, p &amp;lt; 0.001).” This study doesn’t concern comparisons of intact groups of students. Nevertheless, vowel tokens produced by one speaker tend to be more alike than vowels produced by different speakers. In other words, vowel tokens cluster by speaker in the same way that students cluster by class. A traditional &lt;em&gt;t&lt;/em&gt;-test on the individual vowels (i.e. a &lt;em&gt;t&lt;/em&gt;-test with 840 - 2 = 838 degrees of freedom) ignores this clustering and is therefore invalid.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;40 participants are randomly assigned to one of two teaching methods on an individual basis. Teaching takes place in four groups of ten participants each (two groups per method). Even though the participants are assigned to the teaching methods individually, some clustering can be expected to arise during teaching (see &lt;a href=&quot;http://dx.doi.org/10.1136/bmj.330.7483.142&quot;&gt;Lee and Thompson 2005&lt;/a&gt; for a related discussion). A traditional &lt;em&gt;t&lt;/em&gt;-test (in this case one with 40 - 2 = 38 degrees of freedom) ignores this clustering, too, and is likely to yield too low a &lt;em&gt;p&lt;/em&gt;-value.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;80 primary-school students are divided into age groups and, within age group, are randomly combined into pairs. They are then given a &lt;a href=&quot;http://groups.inf.ed.ac.uk/maptask/maptask-description.html&quot;&gt;map task&lt;/a&gt;, and the lexical diversity of their utterances is measured. A regression or correlation analysis is used to gauge the relationship between the students’ age and their lexical diversity. Here, too, the data are clustered – presumably by class but also per dyad: Mutual likes and dislikes and phenomena such as lexical and syntactic priming may contribute to lexical diversity measurements within each dyad being more similar than between different dyads in the same age group.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A questionnaire-based experiment is administered to two groups of students taking parallel courses. Students in the first group all fill out version A of the questionnaire; those in the second group fill out version B. Again, even fairly innocuous-looking similarities within each group (friends going to the same course, students having the same timetable because they take the same courses and have similar interests, more convenient to attend one class and not the other due to better train connections etc.) can lead to an overstated degree of confidence in the study’s results.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the last three cases, researchers may &lt;em&gt;argue&lt;/em&gt; that no clustering is present in their data, 
but this argument would be extremely difficult to prove statistically. (It would involve showing that the between-cluster variance is zero.)
Such an argument would be entirely rhetorical and would probably be quite easy to pick apart.&lt;/p&gt;

&lt;h3 id=&quot;an-easy-solution&quot;&gt;An easy solution&lt;/h3&gt;
&lt;p&gt;The fancy solution for dealing with the clustering problem is to analyse the data in a multilevel (i.e. mixed-effects) model.
Multilevel models aren’t too easy to learn, though, and communicating their results to an audience that’s unfamiliar with them can be a challenge.
There’s a conceptually straightforward and easy-to-implement alternative, however:
average the measurements per cluster and &lt;strong&gt;run the &lt;em&gt;t&lt;/em&gt;-test on the cluster averages&lt;/strong&gt; instead.
Doing so removes the dependencies in the data and produces nominal Type-I error rates.&lt;/p&gt;

&lt;p&gt;To show how easy this is and how fundamentally it can affect the results,
I’ll go through the process 
using simulated data for a cluster-randomised experiment that you can either &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/clusteredData.csv&quot;&gt;download&lt;/a&gt; or read directly into R.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/clusteredData.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## &#39;data.frame&#39;:	160 obs. of  3 variables:
##  $ Class      : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ Condition  : Factor w/ 2 levels &quot;control&quot;,&quot;intervention&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Measurement: int  8 8 5 9 3 4 10 16 14 20 ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##      Class              Condition   Measurement   
##  Min.   :1.000   control     :80   Min.   : 0.00  
##  1st Qu.:3.000   intervention:80   1st Qu.: 9.00  
##  Median :4.500                     Median :13.00  
##  Mean   :4.569                     Mean   :12.69  
##  3rd Qu.:6.000                     3rd Qu.:16.00  
##  Max.   :8.000                     Max.   :26.00&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;As you can see, this is a simple experiment with 80 participants per condition.
Cross-tabulating the &lt;code&gt;Condition&lt;/code&gt; and &lt;code&gt;Class&lt;/code&gt; variables reveals that all students in a given class were assigned to the same experimental condition.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;xtabs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##      Condition
## Class control intervention
##     1      22            0
##     2      13            0
##     3      21            0
##     4      24            0
##     5       0           18
##     6       0           23
##     7       0           16
##     8       0           23&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;What if we were to ignore this clustering?
A visual inspection of the distribution of the scores in each condition wouldn’t reveal anything out of the ordinary…&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Some graphical settings
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;par&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;las&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Draw boxplot, but don&#39;t draw outliers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Measurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# red = control; blue = intervention
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;border&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#E41A1C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;#377EB8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Condition&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Measurement&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Add individual points
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Measurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;grey40&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-09-17-cluster-randomised-experiments/unnamed-chunk-4-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;… and a &lt;em&gt;t&lt;/em&gt;-test would reveal a highly significant difference between the two conditions (t(158) = 3.2, p = 0.002): the intervention worked!&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;t.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Measurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;var.equal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
## 	Two Sample t-test
## 
## data:  Measurement by Condition
## t = -3.1913, df = 158, p-value = 0.001709
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -4.0472258 -0.9527742
## sample estimates:
##      mean in group control mean in group intervention 
##                    11.4375                    13.9375&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It’s only by plotting the scores per class that we get an idea of how the data are clustered.
Class 3, a control class, consists of students who were pretty good at the task relative to the other control classes, for instance.
(Incidentally, I set the ICC value to 0.1 when simulating this dataset.)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;par&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;las&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Draw boxplots per class, no outliers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Measurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# colour boxes red (control) or blue (intervention)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;border&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#E41A1C&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#377EB8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;varwidth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# wider boxes for larger classes
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Measurement&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Add individual points
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Measurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as.numeric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;grey40&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-09-17-cluster-randomised-experiments/unnamed-chunk-6-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;To take by-class clustering into account, we can compute the mean score per class.
For this, I use the &lt;code&gt;plyr&lt;/code&gt; package (use &lt;code&gt;install.packages(&quot;plyr&quot;)&lt;/code&gt; to install):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# install.packages(&quot;plyr&quot;)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat.byclass&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summarise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;meanMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Measurement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;nrStudents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Measurement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dat.byclass&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   Class    Condition meanMeasurement nrStudents
## 1     1      control        9.136364         22
## 2     2      control       13.307692         13
## 3     3      control       15.714286         21
## 4     4      control        8.791667         24
## 5     5 intervention       15.055556         18
## 6     6 intervention       12.217391         23
## 7     7 intervention       12.250000         16
## 8     8 intervention       15.956522         23&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;These class means are then compared in a &lt;em&gt;t&lt;/em&gt;-test:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;t.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meanMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
       &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat.byclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var.equal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
## 	Two Sample t-test
## 
## data:  meanMeasurement by Condition
## t = -1.1031, df = 6, p-value = 0.3122
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -6.862295  2.597565
## sample estimates:
##      mean in group control mean in group intervention 
##                   11.73750                   13.86987&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This time, the test fails to show a significant difference (t(6) = 1.1, p = 0.31),
and we’d be forced to conclude that we have no evidence that the intervention worked. (Which &lt;a href=&quot;http://www.phil.vt.edu/dmayo/personal_website/Schmidt_StatSigTesting.pdf#page=12&quot;&gt;doesn’t&lt;/a&gt; mean that it didn’t, mind you.)&lt;/p&gt;

&lt;h3 id=&quot;further-reading-and-some-additional-points&quot;&gt;Further reading and some additional points&lt;/h3&gt;

&lt;p&gt;For further references and some additional points concerning cluster-randomised experiments, I refer to a recent &lt;a href=&quot;http://www.ssllt.amu.edu.pl/images/vol.5.no.1/SSLLT%205%281%29%20135-152%20Vanhove.pdf&quot;&gt;article&lt;/a&gt; of mine (Section 4).
Here’s the bullet-point version of what I think researchers should be aware of when planning or evaluating class-based experiments:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Properly analysed cluster-randomised experiments have lower statistical power (i.e., a lower probability of observing statistical differences if the intervention actually works) than individually randomised experiments with the same number of participants – no matter what. Having 200 participants in an individually randomised design or 200 participants in a cluster-randomised design are two entirely different things.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Increasing the number of participants per cluster increases power, but not as much as you’d think. For instance, if having 10 classes of 20 participants gives you 40% power, having 10 classes of 200 participants gives you about 53% power.
Increasing the number of clusters is much more efficient. With 14 classes of 20 participants each, you’d already have 57% power.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Having 10 clusters of 20 participants each is better than having 2 clusters of 80 participants each and 8 clusters of 5 participants each. If the former gives you 40% power, the latter gives you 27% power.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Think about what sort of covariates would account for uninteresting variance in the dependent variable. Pretest scores, for instance, can be averaged by class, too, and be entered into an &lt;a href=&quot;http://janhove.github.io/analysis/2014/08/14/pretest-posttest-ancova/&quot;&gt;analysis of covariance&lt;/a&gt; on the class means. Don’t go overboard with this, though: Each covariate costs a degree of freedom, and sacrificing a degree of freedom for a weakly predictive covariate could actually result in a loss of power.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Don’t run experiments with only one cluster per condition.&lt;/em&gt;&lt;/strong&gt;
A &lt;em&gt;t&lt;/em&gt;-test on two cluster means will have 2 - 2 = 0 degrees of freedom and will return an error. 
Conceptually, a study with one cluster per condition has no reliable way of telling whether any difference between the two classes are due to the experimental condition or to the classes tested.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lastly, in the article referenced above, I suggested that researchers may want to consider weighting the cluster means by the number of observations in each cluster when running analyses on the cluster means. &lt;em&gt;This was incorrect.&lt;/em&gt; When running some simulations in preparation of this blog post, I noticed that weighting cluster means in this way inflates the test’s Type-I error rate, sometimes dramatically. My error was due to having misinterpreted some articles on taking unequal cluster sizes into account when planning cluster-randomised designs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
        </entry>
                    
        <entry>
            <title>Covariate adjustment in logistic mixed models: Is it worth the effort?</title>
            <link href="http://janhove.github.io/design/2015/09/02/covariate-adjustment-mixed-logistic-regression/" />
            <published>2015-09-02T00:00:00+02:00</published>
            <updated>2015-09-02T00:00:00+02:00</updated>
            <id>http://janhove.github.io/design/2015/09/02/covariate-adjustment-mixed-logistic-regression/</id>
            <content type="html" xml:base="http://janhove.github.io/design/2015/09/02/covariate-adjustment-mixed-logistic-regression/">&lt;p&gt;The &lt;a href=&quot;/analysis/2015/07/17/covariate-adjustment-logistic-regression&quot;&gt;previous&lt;/a&gt; post
investigated whether adjusting for covariates is useful 
when analysing binary data collected in a randomised experiment with one observation per participant.
This turned out to be the case in terms of statistical power 
and obtaining a more accurate estimate of the treatment effect.
This posts investigates whether these benefits carry over to 
mixed-effect analyses of binary data collected in randomised experiments 
with several observations per participant.
The results suggest that, while covariate adjustment may be worth it if the covariate is a very strong determinant of individual differences in the task at hand,
the benefit doesn’t seem large enough to warrant collecting the covariate variable in an experiment I’m planning.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;I mostly deal with binary dependent variables – whether a word was translated correctly (yes or no), for instance.
When each participant contributes only a single datapoint,
binary data can be analysed using logistic regression models.
More often than not, however, participants are asked to translate several words,
i.e. several datapoints are available per participant.
This ‘clustering’ needs to be taken into account in the analysis, which is where logistic mixed-effects models come in 
(see &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2613284/&quot;&gt;Jaeger 2008&lt;/a&gt; for a rundown).&lt;/p&gt;

&lt;p&gt;For a new experiment I’m planning, 
it’d be useful to know whether I should collect &lt;strong&gt;between-subjects variables&lt;/strong&gt; 
(the participants’ language skills) 
that are likely to account for inter-individual differences in translation performance 
but that don’t interest me as such.
What interests me instead is the effect of the learning condition, to which the participants will be assigned randomly.
Nonetheless, as the &lt;a href=&quot;/analysis/2015/07/17/covariate-adjustment-logistic-regression&quot;&gt;previous&lt;/a&gt; post shows,
accounting for important if uninteresting covariates could be beneficial in terms of power and the accuracy of the estimated treatment effect.&lt;/p&gt;

&lt;p&gt;However, when analysing an earlier &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Vanhove_CorrespondenceRules.pdf&quot;&gt;experiment&lt;/a&gt;, 
I noticed that including covariates did not really affect the estimate of the treatment effect nor its standard error.
Since collecting these variables will lengthen the data collection sessions,
it’d be useful to know whether the additional time and effort are actually worth it from a statistical point of view.
I didn’t find much in the way of readable literature that addresses this questions,
so I ran some simulations to find out.&lt;/p&gt;

&lt;h3 id=&quot;set-up&quot;&gt;Set-up&lt;/h3&gt;
&lt;p&gt;The set-up for the simulations is as follows.
Sixty German-speaking participants are randomly and evenly assigned 
to either the experimental or the control condition.
During training, the participants in the experimental condition are exposed to a series of Dutch–German word pairs, 
some of which feature a systematic interlingual correspondence (e.g. Dutch &lt;em&gt;oe&lt;/em&gt; = German &lt;em&gt;u&lt;/em&gt; as in ‘groet’–‘Gruss’).
The participants in the control group are exposed to comparable word pairs without this interlingual correspondence.
During testing, all participants are asked to translate previously unseen Dutch words into German.
The target stimuli are those that contain Dutch &lt;em&gt;oe&lt;/em&gt;,
and the question is whether participants in the experimental condition are more likely 
to apply the interlingual correspondence when translating these words than the participants in the control group.
After the experiment, all participants take a German vocabulary test, 
which a previous &lt;a href=&quot;http://dx.doi.org/10.1515/iral-2015-0001&quot;&gt;study&lt;/a&gt; had suggested to be a strong predictor of
interindividual differences in this kind of task.&lt;/p&gt;

&lt;h3 id=&quot;settings&quot;&gt;Settings&lt;/h3&gt;

&lt;p&gt;The technical detals of the simulation are available &lt;a href=&quot;https://github.com/janhove/janhove.github.io/blob/master/RCode/GLMMPowerSimulation.md&quot;&gt;here&lt;/a&gt;.
While I’d be chuffed if someone would go through it with the fine-toothed comb,
the general idea is this.
I took data from a previous experiment similar to the one I’m planning and fitted a model to this dataset.
On the basis of the fitted model, I generated new datasets for which I varied the following parameters:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the number of target stimuli: 5 vs. 20 items per participant;&lt;/li&gt;
  &lt;li&gt;the size of the effect of the between-subjects covariate: realistic (a slope of 0.1) and hugely exaggerated (slope of 1.0). The slope of 0.1 is ‘realistic’ in that it is pretty close to the covariate effect found in the original study.
The simulations with the much larger covariate effect were run in order to gauge power in situations were large inter-individual differences exist that can, however, be captured using a covariate.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The distribution of the covariate scores in the simulated datasets was similar 
to the one in the original one.
The number of participants was fixed at 60, distributed evenly between the two conditions,
and the size of the experimental effect was assumed to be equal to that of the original study.
A study with more participants or investigating a larger effect size will obviously have more statistical power,
but the precise power level isn’t what interests me.
Rather, what I wanted to find out is, given a fixed effect size and a fixed number of participants,
would it be worth it to collect a between-subjects covariate and include it in the analysis?
To address this question, I compared the power of logistic mixed-effects models with and without covariates fitted to the simulated datasets.
Per parameter combination, 500 simulated datasets were generated and analysed.
This is not a huge number, but running logistic mixed model analyses takes a &lt;em&gt;lot&lt;/em&gt; of time.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;h4 id=&quot;treatment-estimate&quot;&gt;Treatment estimate&lt;/h4&gt;

&lt;p&gt;Figure 1 shows how well logistic mixed-effect models with and without the between-subjects covariate estimated the true treatment effect on average.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-09-02-covariate-adjustment-mixed-logistic-regression/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Average estimated experimental effect of 500 logistic mixed-effects models without (o) and with the covariate modelled as a fixed effect (+).
The vertical dashed line shows the true simulated experimental effect (0.95 log-odds).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For the realistic covariate slope of 0.1,
the covariate-adjusted and -unadjusted models produce essentially the same and highly accurate estimate of the treatment effect.
Even for the unrealistically large covariate slope of 1.0, i.e. for datasets with extreme but readily accountable inter-individual differences, the two models perform more or less on par.&lt;/p&gt;

&lt;p&gt;From this, I tentitatively conclude that, for this kind of study, accounting for known sources of inter-individual variation using covariates does not substantially affect the estimates of the experimental effect.&lt;/p&gt;

&lt;h4 id=&quot;power&quot;&gt;Power&lt;/h4&gt;

&lt;p&gt;Figure 2 shows the proportion of significant treatment effects out of 500 simulation runs for the covariate-adjusted and -unadjusted models.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-09-02-covariate-adjustment-mixed-logistic-regression/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Estimated power to detect an experimental effect of 0.95 log-odds of logistic mixed-effects models without (o) and with the covariate modelled as a fixed effect (+).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For a realistic covariate effect (slope of 0.1), adding the between-subjects covariate improves power only marginally (by 1 to 2 percentage points).
For larger covariate effects, however, the gain in power is dramatic,
especially if a fair number of datapoints are available per participant.&lt;/p&gt;

&lt;h3 id=&quot;conclusion-and-outlook&quot;&gt;Conclusion and outlook&lt;/h3&gt;
&lt;p&gt;Adjusting for a between-subjects covariate in a between-subjects randomised experiment may be well worth it 
in terms of statistical power if the covariate is very strongly related to the outcome.
For the kind of task I want to investigate, though, the relationship between the covariate and the outcome doesn’t seem to be large enough for covariate adjustment to have any noticeable effect on the results.
Presumably, the model’s by-subject random intercepts do a sufficiently good job in accounting for interindividual differences in this case.
In practical terms, these insights will be useful to me as not collecting the between-subjects variable should free up time elsewhere in the data collection sessions.&lt;/p&gt;

&lt;p&gt;Lastly, some new questions that arose during this exploration:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Does accounting for a strong within-subjects covariate affect power in a between-subjects randomised experiment?&lt;/li&gt;
  &lt;li&gt;Would by-item/by-participant variability in the covariate effects change these conclusions? Specifically, would accounting for the covariate effect using both a fixed and a random term improve power? In this dataset, the by-item variability in the between-subjects covariate was negligible, but this is probably different for other variables.&lt;/li&gt;
&lt;/ul&gt;
</content>
        </entry>
                      
        <entry>
            <title>Covariate adjustment in logistic regression — and some counterintuitive findings</title>
            <link href="http://janhove.github.io/analysis/2015/07/17/covariate-adjustment-logistic-regression/" />
            <published>2015-07-17T00:00:00+02:00</published>
            <updated>2015-07-17T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2015/07/17/covariate-adjustment-logistic-regression/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2015/07/17/covariate-adjustment-logistic-regression/">&lt;p&gt;Including sensible covariates is a good idea when analysing continuous experimental data,
but when I learnt that its benefits may not carry entirely carry over to the analysis of &lt;strong&gt;binary data&lt;/strong&gt;,
I wasn’t sure that I’d fully understood the implications.
This post summarises the results of some simulations that I ran to learn more about
the usefulness of covariates when analysing binary experimental data.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;My previous discussions of the usefulness of including covariates when analysing randomised experiments (&lt;a href=&quot;/analysis/2014/08/14/pretest-posttest-ancova&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/design/2014/11/18/neglected-covariates&quot;&gt;here&lt;/a&gt;) dealt with the case in which the dependent variable is continuous and could be analysed in a linear regression model.
In a nutshell, including sensible covariates in such an analysis increases precision and power and does not bias the estimates of the treatment effect.&lt;/p&gt;

&lt;p&gt;I mostly deal with binary dependent variables (e.g. presence v. absence or correct v. incorrect), however, which can be analysed in logistic regression models.
According to &lt;a href=&quot;http://www.jstor.org/stable/1403444&quot;&gt;Robinson and Jewell (1991)&lt;/a&gt;, the benefits of covariate adjustment in linear regression don’t fully apply to logistic regression models.
I wasn’t sure whether I had fully understood their take-home points 
(reading math-heavy papers means reading selectively for me), though.
As I am currently planning a number of randomised experiments with binary outcome variables, 
I’d like to know whether it’d be useful to extract a number of additional variables that are known to related to this outcome but that aren’t of primary interest to me.
To this end, I ran a couple of simulations that probe the effects of covariate adjustment in logistic regressions on the &lt;strong&gt;effect size estimate&lt;/strong&gt;, its &lt;strong&gt;standard error&lt;/strong&gt; and the &lt;strong&gt;statistical power&lt;/strong&gt; for finding a treatment effect.
I typically analyse my data using logistic mixed-effects models (see &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2613284/&quot;&gt;Jaeger 2008&lt;/a&gt;), but as a first step, I investigated the effects of covariate adjustment in ‘normal’ logistic regression models, i.e. models without random intercepts and random slopes.&lt;/p&gt;

&lt;h3 id=&quot;set-up-a-simple-experiment&quot;&gt;Set-up: A simple experiment&lt;/h3&gt;
&lt;p&gt;The set-up of the simulation is based on the one reported in my &lt;a href=&quot;/design/2014/11/18/neglected-covariates&quot;&gt;first blog post&lt;/a&gt;.
The narrative is as follows.
Eighty German-speaking participants (the number of participants can be adjusted using the &lt;code&gt;n&lt;/code&gt; parameter in the simulation) are randomly assigned to two equal-sized groups.
Half of the participants are told something about Dutch grapheme-to-phoneme correspondences (say that Dutch &lt;oe&gt; is pronounced /u/ and not /ø/, as a native German speaker might assume; experimental group). 
The other participants aren&#39;t told anything (control group).
The participants are then asked to translate a single Dutch (e.g. &lt;i&gt;schoen&lt;/i&gt;) word into German.
If they correctly translate the word as &lt;i&gt;Schuh&lt;/i&gt; &#39;shoe&#39;, their answer is scored as correct,
otherwise it is scored as incorrect, i.e. we have a binary dependent variable.
The question is to what extent translation accuracy differs between the two groups.&lt;/oe&gt;&lt;/p&gt;

&lt;p&gt;However, the participants differ in their knowledge of English, which may also affect their translation accuracy.
Would it be worth the effort to give the participants an English-language test in order to be able to take this covariate (English skills) into account during the analysis, even though we’re not really interested in this variable?&lt;/p&gt;

&lt;h3 id=&quot;skippable-settings&quot;&gt;Skippable: Settings&lt;/h3&gt;
&lt;p&gt;I assumed that the accuracy variable (correct vs. incorrect) was generated from a binomial distribution.
The probability of a correct translation was specified as:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p.correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plogis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In words, &lt;code&gt;condition&lt;/code&gt; (experimental v. control) has an effect (in log-odds) that is equal to &lt;code&gt;b.condition&lt;/code&gt; (i.e. the slope of &lt;code&gt;condition&lt;/code&gt; in log-odds),
the &lt;code&gt;covariate&lt;/code&gt; has an effect (in log-odds) equal to &lt;code&gt;b.covariate&lt;/code&gt; and 
participants could differ randomly in their underlying ‘translation skills’, which is captured by the &lt;code&gt;rnorm&lt;/code&gt; term – the &lt;code&gt;sd.lat&lt;/code&gt; parameter specifies the standard deviation of this normal distribution.&lt;/p&gt;

&lt;p&gt;For the simulation, the covariate (English test performance) is specified to be uniformly distributed between -1 and 1,
whereas the parameters &lt;code&gt;b.condition&lt;/code&gt;, &lt;code&gt;b.covariate&lt;/code&gt; and &lt;code&gt;sd.lat&lt;/code&gt; are systematically varied.
For each combination of parameters, 
10.000 datasets were generated that were analysed in two logistic models: one without and one with the covariate.
From each model, I culled the estimate of the treatment effect and its standard error.
Additionally, the p-value for the treatment effect in each model was computed twice:
once based on Wald’s z-test and once based on the χ² test in a (sequential) analysis of deviance in which the treatment effect was added last.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;h4 id=&quot;estimates-of-the-treatment-effect&quot;&gt;Estimates of the treatment effect&lt;/h4&gt;

&lt;p&gt;The first question is whether the logistic models are able to correctly estimate
the treatment effect underlying the simulated data (&lt;code&gt;b.condition&lt;/code&gt;).
For this comparison, &lt;code&gt;b.condition&lt;/code&gt; was fixed at 1.6, meaning that participants in the treatment group would be roughly 5 times (4.9530324) more likely to provide a correct translation than those in the control group.
The parameter &lt;code&gt;b.covariate&lt;/code&gt;, i.e. the underlying slope parameter of linking the covariate to the outcome in log-odds space, varied between 0 and 4 (0, 0.5, 1, 1.5 etc.).
The parameter &lt;code&gt;sd.lat&lt;/code&gt;, i.e. the standard deviation of the unexplained variability in the latent ‘translation skill’ variable in log-odds space, also varied between 0 and 4 in the same fashion.&lt;/p&gt;

&lt;p&gt;Figure 1 shows the average estimated treatment effect for the covariate-adjusted (blue) and unadjusted (red) logistic models:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-07-17-covariate-adjustment-logistic-regression/unnamed-chunk-3-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; shows the models’ mean estimation of the treatment effect according to the strength of the relationship between the dependent variable and the covariate and the standard deviation of the residual variability in the latent skill. The underlying treatment effect was fixed at &lt;code&gt;b.condition = 1.6&lt;/code&gt; (dashed line).
&lt;em&gt;Red:&lt;/em&gt; the estimate for the logistic model without the covariate.
&lt;em&gt;Blue:&lt;/em&gt; the estimate for the logistic model with the covariate.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I noticed four things when looking at these graphs:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Both the adjusted and unadjusted models massively underestimate the true treatment effect (dashed line at 1.6) in the presence of substantial residual variability in the latent skill unaccounted for by the model. &lt;strong&gt;The treatment estimate seems to be biased towards zero,&lt;/strong&gt; which is new to me.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As the variability in the latent skill increases due to a stronger effect of the covariate, the unadjusted model (blue) performs increasingly more poorly relative to the model that adjusts for the covariate effect (red). This can be understood in terms of point 1: The variability in the latent skill increases when &lt;code&gt;b.covariate&lt;/code&gt; increases. Since the unadjusted model does not account for this increase whereas the adjusted model does, the bias towards zero affects the unadjusted model.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The treatment effect is slightly but systematically overestimated when all the variability in the latent skill is accounted for by variables in the model: When &lt;code&gt;sd.lat&lt;/code&gt; is 0, the adjusted model always yields estimates that are slightly higher than 1.6, and the unadjusted model similarly yields an estimate that is slightly too high when both &lt;code&gt;sd.lat&lt;/code&gt; and &lt;code&gt;b.covariate&lt;/code&gt; are 0.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adjusting for an irrelevant covariate (&lt;code&gt;b.covariate = 0&lt;/code&gt;) does not noticeably affect the treatment estimate.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;When the goal is to estimate a treatment effect, then, covariate adjustment seems useful but cannot be counted on to yield an unbiased of the treatment effect.&lt;/p&gt;

&lt;h4 id=&quot;standard-errors-of-the-treatment-effect&quot;&gt;Standard errors of the treatment effect&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://www.jstor.org/stable/1403444&quot;&gt;Robinson and Jewell (1991)&lt;/a&gt; noted that adjusting for a covariate always decreases precision. To verify whether I’d understood this correctly,
I computed the mean standard error of the treatment estimate for each set of 10.000 models.
The results are shown in Figure 2:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-07-17-covariate-adjustment-logistic-regression/unnamed-chunk-4-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; shows the models’ mean standard error of the treatment effect according to the strength of the relationship between the dependent variable and the covariate and the standard deviation of the residual variability in the latent skill. The underlying treatment effect was fixed at &lt;code&gt;b.condition = 1.6&lt;/code&gt;.
&lt;em&gt;Red:&lt;/em&gt; the estimate for the logistic model without the covariate.
&lt;em&gt;Blue:&lt;/em&gt; the estimate for the logistic model with the covariate.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Two things were striking:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The standard error decreases as the unexplained variability in the latent skill increases.&lt;/strong&gt; This, too, is counter-intuitive and new to me.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The standard error is consistently larger when adjusting for a covariate,&lt;/strong&gt; even when the covariate is important. I assume it is this that &lt;a href=&quot;http://www.jstor.org/stable/1403444&quot;&gt;Robinson and Jewell (1991)&lt;/a&gt; mean when they state that adjusting for covariates reduces precision of the treatment effect estimate.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So the bias towards zero caused by variability in the latent skill that is unaccounted for in the statistical model and which would give rise to reduced statistical power is accompanied by smaller standard errors, which would increase statistical power.
Furthermore, the absolute estimates of the treatment effect are larger in adjusted models than in unadjusted models (which would yield greater statistical power), but on the other hand, the standard errors are larger in these models, too (which would reduce statistical power).&lt;/p&gt;

&lt;p&gt;The obvious question is whether adjusting for covariates increases statistical power giving these two opposite forces.&lt;/p&gt;

&lt;h4 id=&quot;statistical-power&quot;&gt;Statistical power&lt;/h4&gt;

&lt;p&gt;For these simulations, I computed the proportion of the models that returned a significant (&lt;em&gt;p&lt;/em&gt; &amp;lt; 0.05) treatment effect according to a Wald z-test and a χ²-test in a sequential analysis of deviance.
The differences in power between the Wald z-test and the χ²-test were largely negligible,
and only the power for the χ²-tests is reported.&lt;/p&gt;

&lt;p&gt;Figure 3 shows how the study’s power varies as a function of the impact of the covariate and the underlying treatment effect:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-07-17-covariate-adjustment-logistic-regression/unnamed-chunk-5-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt; shows the models’ power for rejecting the null hypothesis of ‘no treatment’ according to the strength of the relationship between the dependent variable and the covariate and the underlying treatment effect. The residual variability in the latent skill was fixed at &lt;code&gt;sd.lat = 1&lt;/code&gt;.
&lt;em&gt;Red:&lt;/em&gt; the estimate for the logistic model without the covariate.
&lt;em&gt;Blue:&lt;/em&gt; the estimate for the logistic model with the covariate.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I noticed three things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Unsurprisingly, power increases as the treatment effect increases.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adjusting for a covariate increases power when the covariate is strongly correlated with the outcome variable. It only has a negligible effect when the relationship is low, hower.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;With 80 participants, the loss of one degree of freedom for modelling an unimportant covariate (&lt;code&gt;b.covariate = 0&lt;/code&gt;) doesn’t affect the study’s power. For small samples, this may not be the case, though I haven’t run simulations to test this intuition.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In terms of power, then, adjusting for a covariate in a logistic model doesn’t hurt. Whether the benefit of including a covariate in the analysis outweighs the effort to collect these data may be debatable when the relationship between the covariate and the outcome isn’t too strong, however.&lt;/p&gt;

&lt;p&gt;Figure 4 shows how power varies according to unaccounted variability in the latent skill:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-07-17-covariate-adjustment-logistic-regression/unnamed-chunk-6-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt; shows the models’ power for rejecting the null hypothesis of ‘no treatment’ according to the strength of the relationship between the dependent variable and the covariate and the standard deviation of the residual variability in the latent skill. The underlying treatment effect was fixed at &lt;code&gt;b.condition = 1.6&lt;/code&gt;.
&lt;em&gt;Red:&lt;/em&gt; the estimate for the logistic model without the covariate.
&lt;em&gt;Blue:&lt;/em&gt; the estimate for the logistic model with the covariate.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Again, two points are noteworthy:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Adjusting for a covariate is especially useful if this covariate accounts for most of the variability in the latent skill (low &lt;code&gt;sd.lat&lt;/code&gt; values). &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;While unmodelled variability in the latent skill reduces both the treatment estimate and its standard error, the overall effect is a reduction in power.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;

&lt;p&gt;All in all, covariate adjustment seems beneficial in terms of power and ‘accuracy’ (but not precision!) of the treatment effect in logistic models.
That said, estimates of treatment effects seem bound to be underestimations when not all information relevant to the underlying data generating process can be brought under control, even in a randomized experiment.
I don’t fully grasp the intuition behind these findings, but being aware of them is a first step.&lt;/p&gt;

&lt;p&gt;Whether the effort of collecting a covariate so that it can be included in the model is worth it in terms of effort, time and cost would seem to depend on its potential to explain between-subjects differences that aren’t linked to the experimental condition.&lt;/p&gt;

&lt;p&gt;Most of this was new and surprising to me, so I can’t guarantee that something hasn’t horribly gone wrong in my simulations. Please let me know if you spot an error!
For a next post, I plan to take a look at covariate adjustment in logistic mixed-effects regression.&lt;/p&gt;

&lt;h3 id=&quot;r-code&quot;&gt;R code&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;simulate.logistic&lt;/code&gt; generates one data point each for &lt;code&gt;n&lt;/code&gt; participants.
The probability of a success (in log-odds) is a function of the participants’ &lt;code&gt;covariate&lt;/code&gt; scores (slope parameter: &lt;code&gt;b.covariate&lt;/code&gt;), the condition to which they were randomly assigned (&lt;code&gt;b.condition&lt;/code&gt;)
as well as normally distributed unexplained factors (with a standard deviation of &lt;code&gt;sd.lat&lt;/code&gt;).
Two models are computed for this dataset with &lt;code&gt;n&lt;/code&gt; observations: one without and one with a covariate.
For each model, the estimated treatment effect, its standard error and two p-values are computed.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;simulate.logistic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  
  &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runif&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;outcome.logodds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;-0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;outcome.binary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rbinom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plogis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outcome.logodds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Model without covariate
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;mod.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outcome.binary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;family&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;binomial&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Estimate of condition effect
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;estimate.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Standard error of estimate
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;sterror.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# P-value of Wald z
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;p.z.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# P-value of analysis of deviance
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;p.x2.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Chisq&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Model with covariates
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;mod.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outcome.binary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;family&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;binomial&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Estimate of condition effect
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;estimate.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Standard error of estimate
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;sterror.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# P-value of Wald z
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;p.z.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coefficients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# P-value of sequential analysis of deviance
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;p.x2.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Chisq&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimate.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;estimate.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;sterror.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sterror.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;p.z.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p.z.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;p.x2.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p.x2.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;code&gt;replicate.logistic&lt;/code&gt; takes the function &lt;code&gt;simulate.logistic&lt;/code&gt; and runs it a large number of times (&lt;code&gt;runs&lt;/code&gt;).
It then returns the average slope and standard error for each modelling approach
as well as their estimated power.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;replicate.logistic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# run simulate.logistic() a number of times
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;simulate.logistic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Compute average slope
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;slope.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;slope.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Compute average standard error
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;se.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;se.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Compute average power Wald
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;power.z.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;power.z.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Compute average power analysis of deviance
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;power.x2.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;power.x2.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Spit it all out
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;slope.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slope.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;slope.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slope.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;se.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;se.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;se.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;se.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;power.z.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;power.z.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;power.z.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;power.z.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;power.x2.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;power.x2.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;power.x2.cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;power.x2.cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;code&gt;replicate.logistic&lt;/code&gt; is then run 10.000 times for a combination of &lt;code&gt;b.covariate&lt;/code&gt; and &lt;code&gt;b.condition&lt;/code&gt; values.
For this simulation, &lt;code&gt;n&lt;/code&gt; is fixed at 80 and &lt;code&gt;sd.lat&lt;/code&gt; at 1.
For this, I use the &lt;code&gt;mcmapply()&lt;/code&gt; function in the &lt;code&gt;parallel&lt;/code&gt; package:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# This tabulates all relevant combinations of b.covariate and b.condition
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expand.grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Run replicate.logistic 10. 000for every combination of b.covariate and b.condition contained in &#39;grid&#39;
# I&#39;m not sure whether this works on Mac or Windows; perhaps use mapply instead of mcmapply.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mcmapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replicate.logistic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                             &lt;span class=&quot;c1&quot;&gt;# set fixed parameters
&lt;/span&gt;                             &lt;span class=&quot;n&quot;&gt;MoreArgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                             &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                             &lt;span class=&quot;c1&quot;&gt;# distribute work over CPU cores
&lt;/span&gt;                             &lt;span class=&quot;n&quot;&gt;mc.cores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detectCores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Output results (transposed for clarity)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;These results can’t directly be saved as a csv file because the underlying structure is still a list.
The &lt;a href=&quot;https://florencecraye.wordpress.com/2013/12/09/when-your-write-csv-wont-write/&quot;&gt;solution&lt;/a&gt; is to ‘unlist’ each column, e.g.:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;power.x2.nocov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;power.x2.nocov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;same&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and then save the file:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;write.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;simulatedResults.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row.names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I used the &lt;code&gt;simulatedResults&lt;/code&gt; data for Figure 3.
For Figures 1, 2 and 4, I varied &lt;code&gt;b.covariate&lt;/code&gt; and &lt;code&gt;sd.lat&lt;/code&gt;
and fixed &lt;code&gt;b.condition&lt;/code&gt; at 1.6:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;grid2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expand.grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;simulatedResults2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mcmapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replicate.logistic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b.covariate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sd.lat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;c1&quot;&gt;# set fixed parameters
&lt;/span&gt;                              &lt;span class=&quot;n&quot;&gt;MoreArgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b.condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                              &lt;span class=&quot;c1&quot;&gt;# distribute work over CPU cores
&lt;/span&gt;                              &lt;span class=&quot;n&quot;&gt;mc.cores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detectCores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Output results (transposed for clarity)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unlist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;save&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;above.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
              
        <entry>
            <title>Some tips on preparing your data for analysis</title>
            <link href="http://janhove.github.io/analysis/2015/06/18/preparing-data-for-analysis/" />
            <published>2015-06-18T00:00:00+02:00</published>
            <updated>2015-06-18T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2015/06/18/preparing-data-for-analysis/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2015/06/18/preparing-data-for-analysis/">&lt;p&gt;How to prepare your spreadsheets so that they can be analysed efficiently is something you tend to learn on the job.
In this blog post, I give some tips for organising datasets that I hope will be of use to students and researchers starting out in quantitative research.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;use-self-explanatory-names-and-labels-but-keep-them-short&quot;&gt;Use self-explanatory names and labels, but keep them short&lt;/h3&gt;

&lt;p&gt;Try to minimise the need to consult the project codebook during the analysis. To this end, name your variables and their values sensibly. If you’re analysing questionnaire data, for instance, a variable name like &lt;code&gt;Q3c&lt;/code&gt; means little to the analyst and requires them to refer back to the questionnaire or the codebook. Renaming this variable &lt;code&gt;DialectUse&lt;/code&gt; makes it immediately clear that the variable likely encodes the degree to which the informant claims to use a dialect. &lt;/p&gt;

&lt;p&gt;Similarly, a series of 0s and 1s in the &lt;code&gt;Sex&lt;/code&gt; variable is uninformative. Sure, one of them will mean ‘man’ and the other ‘woman’, but which is which? Using the labels &lt;code&gt;man&lt;/code&gt; and &lt;code&gt;woman&lt;/code&gt; instead avoids any misunderstandings. Also note that values don’t have to be labelled numerically.&lt;/p&gt;

&lt;p&gt;Lastly, use a consistent and unambiguous label to identify missing data. &lt;code&gt;NA&lt;/code&gt; is usually a good choice, but don’t use &lt;code&gt;0&lt;/code&gt; or &lt;code&gt;-99&lt;/code&gt; etc. Especially if you’re analysing numeric data, it may not be immediately obvious to the analyst that &lt;code&gt;0&lt;/code&gt; or &lt;code&gt;-99&lt;/code&gt; don’t refer to actual measurements. (See exercises 2 and 3 on page 77 in my introduction to statistics, if you can read German.)&lt;/p&gt;

&lt;p&gt;Transparent variables names and data labels facilitate the analysis because you don’t have to go back and forth between dataset and codebook to make sense of the data. A further benefit is that the code used for the analysis tends to be more readable, even months after the analysis has been conducted.&lt;/p&gt;

&lt;p&gt;That said, when coming up with descriptive names and labels, try to keep them short. A variable name like &lt;code&gt;HowOftenDoYouSpeakTheLocalDialectWithYourChild&lt;/code&gt; is self-explanatory but cumbersome to type repeatedly when analysing the data. &lt;code&gt;DialectChild&lt;/code&gt; might be less self-explanatory but is easier to use.&lt;/p&gt;

&lt;p&gt;Lastly, try to keep the following guidelines in mind:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Capitalisation matters. In R, an informant whose &lt;code&gt;Sex&lt;/code&gt; is &lt;code&gt;man&lt;/code&gt; is of a different gender than one whose &lt;code&gt;Sex&lt;/code&gt; is &lt;code&gt;Man&lt;/code&gt;. Any such confusions become clear soon enough when analysing the data and they&#39;re pretty easy to take care of. But avoiding them is better for the analyst&#39;s grumpiness level :)&lt;/li&gt;

&lt;li&gt;Special characters are tricky. German Umlaut characters and French accents may show up without problems on your computer, but may require the manual specification of a character encoding on a different system. Try to either avoid special characters or know which character encoding you saved the dataset in (see the &lt;a href=&quot;https://support.office.com/en-ca/article/Choose-text-encoding-when-you-open-and-save-files-60d59c21-88b5-4006-831c-d536d42fd861&quot;&gt;MS Office support page&lt;/a&gt; for Excel; LibreOffice users can just use the &#39;Save as&#39; function and will be asked which encoding they prefer).&lt;/li&gt;

&lt;li&gt;Don&#39;t use spaces, question marks or exclamation marks in variable names.&lt;/li&gt;

&lt;li&gt;Colour-coding is fine for your own use, but the colours get lost when the dataset is imported into a statistics program.&lt;/li&gt;

&lt;li&gt;&#39;Empty&#39; rows or columns may contain lingering spaces that mess up the dataset when it&#39;s imported into a statistics program. By way of example, the csv file &lt;code&gt;FormantMeasurements1.csv&lt;/code&gt; (available &lt;a href=&quot;http://janhove.github/io/downloads/FormantMeasurements1.csv&quot;&gt;here&lt;/a&gt;) looks fine when it&#39;s opened in a spreadsheet program:

&lt;img src=&quot;http://janhove.github.io/images/FormantMeasurements1.png&quot; alt=&quot;Example superfluous spaces&quot; /&gt;

When the dataset is imported into &lt;code&gt;R&lt;/code&gt;, however, there seem to be two additional variables (&lt;code&gt;X&lt;/code&gt; and &lt;code&gt;X.1&lt;/code&gt;), some missing values (&lt;code&gt;NA&lt;/code&gt;) and a &lt;code&gt;Speaker&lt;/code&gt; without an ID:



&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/downloads/FormantMeasurements1.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;





&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##  Speaker     Trial            Word          F1               F2        
##    : 2   Min.   : 1.00   baat   : 8   Min.   : 197.0   Min.   : 581.9  
##  S1:24   1st Qu.: 6.75   biet   : 8   1st Qu.: 278.5   1st Qu.: 899.7  
##  S2:24   Median :12.50   buut   : 8   Median : 350.2   Median :1544.8  
##  S3:24   Mean   :12.50   daat   : 8   Mean   : 488.0   Mean   :1557.3  
##  S4:24   3rd Qu.:18.25   diet   : 8   3rd Qu.: 772.2   3rd Qu.:2309.4  
##          Max.   :24.00   duut   : 8   Max.   :1031.1   Max.   :2773.7  
##          NA&#39;s   :2       (Other):50   NA&#39;s   :2        NA&#39;s   :2       
##     X             X.1         
##  Mode:logical   Mode:logical  
##  NA&#39;s:98        NA&#39;s:98       
##                               
##                               
##                               
##                               
##&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


The reason is that there are superfluous spaces in cells D99 and G9.
&lt;/li&gt;

&lt;li&gt;Similarly, a value label with a trailing space will be inconspicuous in your spreadsheet program but will affect how the dataset is read in into your statistics program.
The csv file &lt;code&gt;FormantMeasurements2.csv&lt;/code&gt; contains the same data as &lt;code&gt;FormantMeasurements1.csv&lt;/code&gt;, but when read into &lt;code&gt;R&lt;/code&gt;, there seem to be two &lt;code&gt;Speaker&lt;/code&gt;s with the same ID (&lt;code&gt;S2&lt;/code&gt;):



&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/downloads/FormantMeasurements2.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;





&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##  Speaker      Trial            Word          F1               F2        
##  S1 :24   Min.   : 1.00   baat   : 8   Min.   : 197.0   Min.   : 581.9  
##  S2 :23   1st Qu.: 6.75   biet   : 8   1st Qu.: 278.5   1st Qu.: 899.7  
##  S2 : 1   Median :12.50   buut   : 8   Median : 350.2   Median :1544.8  
##  S3 :24   Mean   :12.50   daat   : 8   Mean   : 488.0   Mean   :1557.3  
##  S4 :24   3rd Qu.:18.25   diet   : 8   3rd Qu.: 772.2   3rd Qu.:2309.4  
##           Max.   :24.00   duut   : 8   Max.   :1031.1   Max.   :2773.7  
##                           (Other):48&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


The reason is that there&#39;s a trailing space in cell A28.

Less obvious (because it doesn&#39;t show up in the &lt;code&gt;summary()&lt;/code&gt; output) is that there&#39;s also a superfluous space in the &lt;code&gt;Word&lt;/code&gt; column (the carrier word &lt;code&gt;tiet&lt;/code&gt; occurs twice, once with and once without trailing space):



&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;





&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##  [1] &quot;baat&quot;  &quot;biet&quot;  &quot;buut&quot;  &quot;daat&quot;  &quot;diet&quot;  &quot;duut&quot;  &quot;paat&quot;  &quot;piet&quot; 
##  [9] &quot;puut&quot;  &quot;taat&quot;  &quot;tiet&quot;  &quot;tiet &quot; &quot;tuut&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


As you can check for yourself, the trailing space is in cell C2.

Problems like inconsistent capitalisation or trailing spaces are pretty easy to fix when you know they&#39;re there, 
but they aren&#39;t always obvious.
&lt;/li&gt;

&lt;/ul&gt;

&lt;h3 id=&quot;a-long-data-format-is-usually-easier-to-manage-than-a-wide-one&quot;&gt;A ‘long’ data format is usually easier to manage than a ‘wide’ one&lt;/h3&gt;
&lt;p&gt;An example of a ‘wide’ dataset is &lt;code&gt;Cognates_wide.csv&lt;/code&gt; (available &lt;a href=&quot;http://janhove.github.io/downloads/Cognates_wide.csv&quot;&gt;here&lt;/a&gt;). The column &lt;code&gt;Subject&lt;/code&gt; contains the participants’ IDs and every other column expresses whether the participant  translated a given stimulus (e.g. ‘ägg’, ‘alltid’, ‘äta’ etc.) correctly. Every participant has their own row:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/downloads/Cognates_wide.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;fileEncoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   Subject agg alltid alska ata avskaffa bäbis bakgrund barn behärska bliva
## 1      64   0      0     1   1        0     0        1    0        0     0
## 2      78   0      0     0   0        0     0        1    0        0     0
## 3     134   0      0     0   0        0     0        1    0        0     0
## 4     230   0      0     0   0        0     0        1    0        0     0
## 5     288   0      0     0   0        0     0        1    0        0     0
## 6     326   0      0     0   0        0     1        1    1        0     0
##   blomma borgmästare borja branna butelj byrå choklad cyckel egenskap elev
## 1      1           0     0      1      0    0       0      0        0    0
## 2      1           0     0      1      0    0       0      1        0    0
## 3      1           0     0      1      0    0       0      0        0    0
## 4      0           1     0      1      0    0       0      0        0    0
## 5      0           0     0      1      0    0       0      0        0    0
## 6      1           0     0      1      0    0       0      1        0    1
##   ensam fåtölj fiende flicka fonster försiktig forsoka forst forsvinna
## 1     0      0      1      0       1         1       0     0         1
## 2     0      0      0      0       1         1       0     0         1
## 3     1      0      0      0       1         0       0     0         1
## 4     0      0      1      0       1         1       0     0         1
## 5     0      0      0      0       1         1       0     0         0
## 6     0      0      1      0       1         1       0     0         1
##   förutsättning fotboll fraga frasch full ga grupp hård häst hemlig
## 1             1       1     1      1    1  1     0    1    0      0
## 2             0       1     1      1    1  1     0    1    0      0
## 3             0       1     0      1    0  0     1    0    0      1
## 4             0       1     1      0    1  0     0    1    0      0
## 5             0       1     0      0    0  0     0    1    0      0
## 6             0       1     0      1    1  0     0    1    0      0
##   ingenjor intryck is kagel kanel karnkraftverk kejsar kniv konst
## 1        1       0  0     0     0             0      0    1     1
## 2        1       0  0     0     0             1      0    1     1
## 3        1       0  0     0     0             1      0    1     1
## 4        1       0  0     0     0             0      1    1     1
## 5        1       0  0     0     0             1      0    0     1
## 6        1       0  0     0     0             1      1    0     1
##   korruption kung kyrka kyssa lang larm leka löpa markvardig mjölk möjlig
## 1          0    0     1     1    1    1    0    0          1     0      0
## 2          0    0     1     1    1    0    0    0          0     1      0
## 3          0    0     0     0    0    1    0    0          1     1      0
## 4          0    0     1     1    1    0    0    0          0     1      1
## 5          0    0     0     0    0    1    0    0          1     0      0
## 6          0    0     1     1    1    0    0    0          1     1      0
##   mycket nackdel öppna ost overraska översätta paraply passiv potatis
## 1      0       0     1   1         0         0       1      1       1
## 2      0       0     1   1         0         0       1      1       1
## 3      0       1     1   1         0         1       1      1       1
## 4      0       0     1   1         0         0       1      0       0
## 5      0       0     0   0         0         0       0      1       0
## 6      0       0     0   1         0         0       0      1       1
##   rådhus rytmisk saliv sitta sjalvstandig skarm skola skön skriva skrubba
## 1      1       1     1     1            1     0     1    1      0       1
## 2      1       1     0     1            0     0     1    0      0       0
## 3      1       1     0     1            1     0     0    0      0       0
## 4      1       1     0     1            0     0     1    0      0       0
## 5      0       0     0     0            1     0     0    0      0       0
## 6      1       1     0     1            0     0     1    1      0       0
##   skyskrapa smart smink söka spegel språk städa stjärn sverige tanka tårta
## 1         1     1     0    0      1     1     0      0       0     1     1
## 2         0     0     1    0      1     1     0      1       0     0     1
## 3         1     0     1    0      0     0     0      1       0     1     0
## 4         1     1     0    1      1     1     0      1       0     0     1
## 5         1     1     0    0      1     0     0      1       0     0     0
## 6         0     1     1    0      1     1     0      1       0     1     1
##   torsdag trakig tunga tvivla tydlig ursprung värld varm vaxla viktig
## 1       1      0     0      1      0        1     0    1     1      1
## 2       0      0     0      0      0        1     0    1     1      1
## 3       1      0     0      0      0        1     0    1     1      0
## 4       1      0     0      0      0        1     0    1     0      1
## 5       1      0     0      0      0        0     0    1     1      1
## 6       1      0     1      0      0        1     0    1     1      1
##   ytterst
## 1       0
## 2       0
## 3       0
## 4       0
## 5       0
## 6       0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In a ‘long’ dataset (e.g. &lt;code&gt;Cognates_long.csv&lt;/code&gt;), the data are arranged differently, typically with one row per ‘observation unit’:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/downloads/Cognates_long.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;fileEncoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   Subject Stimulus Correct
## 1    1034      agg       0
## 2    2151      agg       0
## 3    9022      agg       0
## 4    7337      agg       0
## 5    8477      agg       0
## 6    6544      agg       0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##       Subject Stimulus Correct
## 16295    5290  ytterst       0
## 16296    3125  ytterst       0
## 16297    4137  ytterst       0
## 16298    1967  ytterst       0
## 16299    8942  ytterst       0
## 16300    9913  ytterst       0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I prefer long datasets for the following reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The statistical tools I usually work with (mixed-effects models) require data in a long format.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It’s easier to add information to a long than to a wide dataset. For instance, if I wanted to add the order in which the participants saw the stimuli to the wide format, I’d have to add 100 columns to save the trial numbers (i.e. &lt;code&gt;aggTrial&lt;/code&gt;, &lt;code&gt;alltidTrial&lt;/code&gt; etc.). I’d only have to add one column (&lt;code&gt;Trial&lt;/code&gt;) in the case of long data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;While wide datasets are useful for analytical techniques such as principal component analysis, factor analysis or structural equation modeling as well as paired t-tests, I find it easier to convert a long dataset to a wide dataset than vice versa, especially if the dataset contains additional information about the stimuli or trials.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A useful package for converting long data to wide data and vice versa is &lt;code&gt;reshape2&lt;/code&gt;, whose use is helpfully explained by &lt;a href=&quot;http://seananderson.ca/2013/10/19/reshape.html&quot;&gt;Sean Anderson&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;managing-several-smallish-datasets-and-then-joining-them-before-the-analysis-is-easier-than-handling-one-large-dataset&quot;&gt;Managing several smallish datasets and then joining them before the analysis is easier than handling one large dataset&lt;/h3&gt;
&lt;p&gt;Complex datasets often contain repeated data. For instance, we could add the participants’ age to &lt;code&gt;Cognates_long.csv&lt;/code&gt; above, but we’d have to repeat each participant’s age 100 times. Similarly, we could add information about the stimuli to &lt;code&gt;Cognates_long.csv&lt;/code&gt; (e.g. their length in phonemes), but we’d have to repeat each stimulus’s length 163 times (once for each participant). In such cases, I find it easiest to compile several smaller datasets with as little information repeated as possible and to combine them when needed. That way, if I make a mistake when entering the data, I’ll only have to correct it once and then recombine the datasets.&lt;/p&gt;

&lt;p&gt;Here’s an illustration of what I mean.
The participants’ accuracy per stimulus is stored in &lt;code&gt;Cognates_long.csv&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/downloads/Cognates_long.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;fileEncoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Background information about the participants is available in &lt;code&gt;ParticipantInformation.csv&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;participants&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/downloads/ParticipantInformation.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;fileEncoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;participants&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##     Subject         Sex          Age            NrLang     
##  Min.   :  64   female:90   Min.   :10.00   Min.   :1.000  
##  1st Qu.:2990   male  :73   1st Qu.:16.00   1st Qu.:2.000  
##  Median :5731               Median :39.00   Median :3.000  
##  Mean   :5317               Mean   :40.28   Mean   :3.067  
##  3rd Qu.:7769               3rd Qu.:59.50   3rd Qu.:4.000  
##  Max.   :9913               Max.   :86.00   Max.   :9.000  
##                                                            
##     DS.Span         DS.Total          GmVoc           Raven     
##  Min.   :2.000   Min.   : 2.000   Min.   : 4.00   Min.   : 0.0  
##  1st Qu.:4.000   1st Qu.: 5.000   1st Qu.:29.00   1st Qu.:12.0  
##  Median :4.000   Median : 6.000   Median :34.00   Median :19.0  
##  Mean   :4.613   Mean   : 6.374   Mean   :30.24   Mean   :17.8  
##  3rd Qu.:5.000   3rd Qu.: 7.500   3rd Qu.:36.00   3rd Qu.:24.0  
##  Max.   :8.000   Max.   :12.000   Max.   :41.00   Max.   :35.0  
##                                   NA&#39;s   :1                     
##   EnglishScore  
##  Min.   : 3.00  
##  1st Qu.:20.75  
##  Median :31.00  
##  Mean   :28.30  
##  3rd Qu.:37.00  
##  Max.   :44.00  
##  NA&#39;s   :3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The entries in the &lt;code&gt;Subject&lt;/code&gt; column in &lt;code&gt;Cognates_long.csv&lt;/code&gt; correspond to those in the same column in &lt;code&gt;ParticipantInformation.csv&lt;/code&gt;. Using &lt;code&gt;merge()&lt;/code&gt;, we can add the information in the latter dataset to the corresponding rows in the former:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;participants&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Subject&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   Subject      Stimulus Correct    Sex Age NrLang DS.Span DS.Total GmVoc
## 1      64         forst       0 female  27      4       6        7    34
## 2      64          löpa       0 female  27      4       6        7    34
## 3      64           ost       1 female  27      4       6        7    34
## 4      64         tunga       0 female  27      4       6        7    34
## 5      64 förutsättning       1 female  27      4       6        7    34
## 6      64         ensam       0 female  27      4       6        7    34
##   Raven EnglishScore
## 1    28           42
## 2    28           42
## 3    28           42
## 4    28           42
## 5    28           42
## 6    28           42&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##       Subject  Stimulus Correct    Sex Age NrLang DS.Span DS.Total GmVoc
## 16295    9913     grupp       1 female  40      3       5        8    29
## 16296    9913      kung       0 female  40      3       5        8    29
## 16297    9913     städa       0 female  40      3       5        8    29
## 16298    9913     tanka       1 female  40      3       5        8    29
## 16299    9913 skyskrapa       0 female  40      3       5        8    29
## 16300    9913   rytmisk       0 female  40      3       5        8    29
##       Raven EnglishScore
## 16295    17           17
## 16296    17           17
## 16297    17           17
## 16298    17           17
## 16299    17           17
## 16300    17           17&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Similarly, we can add information about the stimuli, available in &lt;code&gt;StimulusInformation.csv&lt;/code&gt;, to &lt;code&gt;dat&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;stimuli&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/downloads/StimulusInformation.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;fileEncoding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stimuli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##      Stimulus      Status      Duration          Swedish          German  
##  agg     : 1   profile:10   Min.   : 516.0   2st     : 1   abschaffen: 1  
##  alltid  : 1   target :90   1st Qu.: 708.8   2v@raska: 1   ai        : 1  
##  alska   : 1                Median : 869.5   alltid  : 1   aig@nSaft : 1  
##  ata     : 1                Mean   : 843.4   avskaffa: 1   aindruk   : 1  
##  avskaffa: 1                3rd Qu.: 929.8   b2rja   : 1   ainzam    : 1  
##  bäbis   : 1                Max.   :1264.0   babis   : 1   (Other)   :75  
##  (Other) :94                NA&#39;s   :50       (Other) :94   NA&#39;s      :20  
##        English        French       LevGer           LevEng      
##  ais       : 1   alarm   : 1   Min.   :0.1429   Min.   :0.0000  
##  b2rn      : 1   bebe    : 1   1st Qu.:0.4000   1st Qu.:0.4000  
##  baby      : 1   bureau  : 1   Median :0.5000   Median :1.0000  
##  background: 1   butEj   : 1   Mean   :0.5859   Mean   :0.6997  
##  blum      : 1   cannelle: 1   3rd Qu.:0.8333   3rd Qu.:1.0000  
##  (Other)   :42   (Other) :18   Max.   :1.0000   Max.   :1.0000  
##  NA&#39;s      :53   NA&#39;s    :77                                    
##      LevFre         FreqGerman        FreqEnglish       FreqFrench   
##  Min.   :0.0000   Min.   :   0.000   Min.   :   0.0   Min.   :    0  
##  1st Qu.:1.0000   1st Qu.:   0.932   1st Qu.:   0.0   1st Qu.:    0  
##  Median :1.0000   Median :  20.020   Median :   0.0   Median :    0  
##  Mean   :0.8529   Mean   : 109.714   Mean   : 119.4   Mean   :  237  
##  3rd Qu.:1.0000   3rd Qu.:  60.138   3rd Qu.:  43.6   3rd Qu.:    0  
##  Max.   :1.0000   Max.   :3460.090   Max.   :3793.0   Max.   :22823  
##&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The shared denominator of both datasets is stored in the column &lt;code&gt;Stimulus&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stimuli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Stimulus&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   Stimulus Subject Correct    Sex Age NrLang DS.Span DS.Total GmVoc Raven
## 1      agg    7479       0   male  25      4       8       11    38    34
## 2      agg    7337       0 female  49      3       4        5    36    19
## 3      agg    2846       0 female  11      3       4        6     4    15
## 4      agg    5153       0 female  51      3       4        6    37    18
## 5      agg    6510       0 female  41      2       5        8    34    30
## 6      agg    6329       0 female  56      3       5        6    37    21
##   EnglishScore Status Duration Swedish German English French LevGer LevEng
## 1           43 target      547      Eg     ai      Eg   &amp;lt;NA&amp;gt;      1      0
## 2           30 target      547      Eg     ai      Eg   &amp;lt;NA&amp;gt;      1      0
## 3            6 target      547      Eg     ai      Eg   &amp;lt;NA&amp;gt;      1      0
## 4           37 target      547      Eg     ai      Eg   &amp;lt;NA&amp;gt;      1      0
## 5           40 target      547      Eg     ai      Eg   &amp;lt;NA&amp;gt;      1      0
## 6           42 target      547      Eg     ai      Eg   &amp;lt;NA&amp;gt;      1      0
##   LevFre FreqGerman FreqEnglish FreqFrench
## 1      1      24.06       26.04          0
## 2      1      24.06       26.04          0
## 3      1      24.06       26.04          0
## 4      1      24.06       26.04          0
## 5      1      24.06       26.04          0
## 6      1      24.06       26.04          0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##       Stimulus Subject Correct    Sex Age NrLang DS.Span DS.Total GmVoc
## 16295  ytterst    1350       0   male  43      4       7       10    38
## 16296  ytterst    7337       0 female  49      3       4        5    36
## 16297  ytterst    8578       0   male  11      2       4        6     9
## 16298  ytterst     717       0 female  15      2       5        6    29
## 16299  ytterst    8805       0   male  70      4       4        4    35
## 16300  ytterst    9912       0   male  10      2       4        4     9
##       Raven EnglishScore Status Duration Swedish   German English French
## 16295    31           38 target       NA ytterst ausserst    &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;
## 16296    19           30 target       NA ytterst ausserst    &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;
## 16297    20           17 target       NA ytterst ausserst    &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;
## 16298    21           25 target       NA ytterst ausserst    &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;
## 16299    22           35 target       NA ytterst ausserst    &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;
## 16300    14            9 target       NA ytterst ausserst    &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt;
##       LevGer LevEng LevFre FreqGerman FreqEnglish FreqFrench
## 16295    0.5      1      1      23.19           0          0
## 16296    0.5      1      1      23.19           0          0
## 16297    0.5      1      1      23.19           0          0
## 16298    0.5      1      1      23.19           0          0
## 16299    0.5      1      1      23.19           0          0
## 16300    0.5      1      1      23.19           0          0&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;reading-tip&quot;&gt;Reading tip&lt;/h3&gt;
&lt;p&gt;Hadley Wickham’s &lt;a href=&quot;http://vita.had.co.nz/papers/tidy-data.pdf&quot;&gt;&lt;em&gt;Tidy data&lt;/em&gt;&lt;/a&gt;, while primarily geared towards software developers, is well worth a read.&lt;/p&gt;
</content>
        </entry>
                          
        <entry>
            <title>Power simulations for comparing independent correlations</title>
            <link href="http://janhove.github.io/design/2015/04/14/power-simulations-for-comparing-independent-correlations/" />
            <published>2015-04-14T00:00:00+02:00</published>
            <updated>2015-04-14T00:00:00+02:00</updated>
            <id>http://janhove.github.io/design/2015/04/14/power-simulations-for-comparing-independent-correlations/</id>
            <content type="html" xml:base="http://janhove.github.io/design/2015/04/14/power-simulations-for-comparing-independent-correlations/">&lt;p&gt;Every now and then, researchers want to compare the strength of a correlation between two samples or studies.
Just establishing that one correlation is significant while the other isn’t &lt;a href=&quot;/analysis/2014/10/28/assessing-differences-of-significance&quot;&gt;doesn’t work&lt;/a&gt; – 
what needs to be established is whether the &lt;em&gt;difference&lt;/em&gt; between the two correlations is significant.
I wanted to know how much power a comparison between correlation coefficients has,
so I wrote some simulation code to find out.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;the-results&quot;&gt;The results&lt;/h3&gt;

&lt;p&gt;The contour plots below show the power
of comparisons with sample sizes of 2×20, 2×40 and 2×80 observations for all combinations of population correlation coefficients.
For instance, the first contour plot shows
that you have about 90% power to find a significant difference between two correlation coefficients
if the true population correlation in population A (x-axis) is 0.4 and -0.6 in population B (y-axis)
and both sample contain 20 observations.
If the correlation in population B is -0.2, however, you have less than 50% power.
In blue is the contour line for 80% power for reference.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-04-14-power-simulations-for-comparing-independent-correlations/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;For unequal sample sizes, the contour plot might look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-04-14-power-simulations-for-comparing-independent-correlations/unnamed-chunk-3-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;
&lt;p&gt;Not really any new insights, but a good opportunity to stress once again that &lt;a href=&quot;http://www.tandfonline.com/doi/abs/10.1198/000313006X152649#.VEn854_sM7w&quot;&gt;&lt;em&gt;The difference between “significant” and “not significant” is not itself statistically significant&lt;/em&gt;&lt;/a&gt;. 
And I got to play around with the &lt;code&gt;outer&lt;/code&gt; and &lt;code&gt;mapply&lt;/code&gt; functions,
which are quite useful for avoiding for-loops in simulations (see below).&lt;/p&gt;

&lt;h3 id=&quot;caveat&quot;&gt;Caveat&lt;/h3&gt;
&lt;p&gt;These simulations estimate the power for comparisons of &lt;em&gt;independent&lt;/em&gt; correlations.
Independent correlations are correlations computed for different samples (or different studies).
An example of &lt;em&gt;dependent&lt;/em&gt; correlations would be when you measure a variable,
e.g. Italian proficiency, and correlate it to two other variables (e.g., French proficiency and Spanish proficiency) using the same participants.
Since you used the same participants, there will exist some intercorrelation between French proficiency and Spanish proficiency, which needs to be taken into account when comparing the correlations between Italian and French proficiency on the one hand and Italian and Spanish proficiency on the other.&lt;/p&gt;

&lt;h3 id=&quot;simulation-code&quot;&gt;Simulation code&lt;/h3&gt;

&lt;p&gt;First load the &lt;code&gt;MASS&lt;/code&gt; and &lt;code&gt;psych&lt;/code&gt; packages (run &lt;code&gt;install.packages(c(&quot;MASS&quot;, &quot;psych&quot;))&lt;/code&gt; if they aren’t installed yet).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MASS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;psych&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Using the &lt;code&gt;mvrnorm&lt;/code&gt; function from the &lt;code&gt;MASS&lt;/code&gt; package, 
we can generate samples drawn from a bivariate normal distribution with a specific population correlation coefficient (the numbers of the antidiagonal in the &lt;code&gt;Sigma&lt;/code&gt; parameter; in this example: 0.3).
With &lt;code&gt;cor&lt;/code&gt; we compute the &lt;em&gt;sample&lt;/em&gt; correlation coefficients for these samples;
these will differ from sample to sample.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Example
# Generate sample with n = 25 and r = 0.25
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample25&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvrnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# means of the populations, doesn&#39;t matter 
&lt;/span&gt;                    &lt;span class=&quot;n&quot;&gt;Sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                     &lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Compute correlation matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.3293883&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With the &lt;code&gt;r.test&lt;/code&gt; function from the &lt;code&gt;psych&lt;/code&gt; package,
we can compute the significance of the &lt;em&gt;difference&lt;/em&gt; between two sample correlation coefficients.
In this case, the correlation coefficients were computed for independent samples,
hence the &lt;code&gt;r12&lt;/code&gt; and &lt;code&gt;r34&lt;/code&gt; parameters are specified.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Example
# Compute p-value for difference btwn sample cors
# of 0.5 (n = 20) and 0.2 (n = 50)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r34&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.2207423&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With that out of the way, we now write a new function, &lt;code&gt;compute.p&lt;/code&gt;,
that generates two samples of sizes &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt;, respectively,
from bivariate normal distributions with &lt;em&gt;population&lt;/em&gt; correlations of &lt;code&gt;popr12&lt;/code&gt; and &lt;code&gt;popr34&lt;/code&gt;, respectively.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;compute.p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;r12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mvrnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
                                  &lt;span class=&quot;n&quot;&gt;Sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                                   &lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;r34&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mvrnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
                                  &lt;span class=&quot;n&quot;&gt;Sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                                   &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute.p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.6419873&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now we write another function, &lt;code&gt;compute.power&lt;/code&gt;, that takes &lt;code&gt;compute.p&lt;/code&gt;, runs it, say, 1000 times,
and returns how many p-values lie below 0.05 – i.e., the comparison’s estimated power.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;compute.power&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n.sims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n.sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                        &lt;span class=&quot;n&quot;&gt;compute.p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                  &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute.power&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n.sims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
              &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.252&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here’s where the R fun begins. 
I want to compute the power not only for a single comparison,
but for nearly the whole &lt;code&gt;popr12&lt;/code&gt; v. &lt;code&gt;popr34&lt;/code&gt; spectrum of possible comparisons:
-0.95 v. -0.90, -0.95 v. -0.85, …, 0.7 v. -0.3 etc.
All relevant correlations are stored in &lt;code&gt;corrs&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;corrs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Using the &lt;code&gt;outer&lt;/code&gt; function, I generate a grid featuring every possible combination of coefficients in &lt;code&gt;corrs&lt;/code&gt; and run &lt;code&gt;compute.power&lt;/code&gt; on each combination using &lt;code&gt;mapply&lt;/code&gt;.
Here, I estimate the power for a comparison with two samples of 20 observations.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;results20&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                   &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute.power&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                         &lt;span class=&quot;n&quot;&gt;popr12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;popr34&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                         &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                         &lt;span class=&quot;n&quot;&gt;n.sims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With &lt;code&gt;contour&lt;/code&gt;, the results matrix is then visualised:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;contour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlevels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;labcex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;gray26&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;n = 20 in both samples&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correlation in population A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correlation in population B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lwd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;lightgray&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lwd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;lightgray&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;contour&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;corrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;levels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;drawlabels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lwd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;steelblue3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This code could probably be optimised a bit;
the power for the comparison between -0.5 and 0.3 is obviously identical to
the power for the comparison between 0.5 and -0.3, for instance.&lt;/p&gt;

</content>
        </entry>
                              
        <entry>
            <title>Explaining key concepts using permutation tests</title>
            <link href="http://janhove.github.io/teaching/2015/02/26/explaining-key-concepts-using-permutation-tests/" />
            <published>2015-02-26T00:00:00+01:00</published>
            <updated>2015-02-26T00:00:00+01:00</updated>
            <id>http://janhove.github.io/teaching/2015/02/26/explaining-key-concepts-using-permutation-tests/</id>
            <content type="html" xml:base="http://janhove.github.io/teaching/2015/02/26/explaining-key-concepts-using-permutation-tests/">&lt;p&gt;It’s that time of year again where I have the honour of explaining the nuts and bolts of inferential statistics
in the optional introductory statistics class that I teach.
Two of my objectives are to familiarise my students with core concepts of statistical inference 
and to make sure that they don’t fall into the trap of &lt;a href=&quot;http://dx.doi.org/10.1053/j.seminhematol.2008.04.003&quot;&gt;reading too much into &lt;em&gt;p&lt;/em&gt;-values&lt;/a&gt;.
In addition to going through the traditional route based on the Central Limit Theorem,
I think that several key concepts can be also illustrated in a less math-intensive way – namely by exploring the logic of &lt;strong&gt;permutation tests&lt;/strong&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;My goal isn’t to make the case for a wholesale adoption of permuation tests (which I explain in more detail below).
Rather, I hope that by discussing permutation tests we can gain a better understanding of some key concepts in inferential statistics that are often neglected,
and that we can do so without too many distracting equations and assumptions.
Some of the points that a discussion of permutation tests raises are&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the basic logic of inferential (frequentist) statistics;&lt;/li&gt;
  &lt;li&gt;the principle that inference can and must be motivated by the experimental design (including the ‘independence assumption’ shared by most commonly taught statistical tests);&lt;/li&gt;
  &lt;li&gt;the validity of statistical tests in non-randomised designs;&lt;/li&gt;
  &lt;li&gt;the validity of statistical tests in the absence of random sampling.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But first, we need some fictitious data.&lt;/p&gt;

&lt;h3 id=&quot;a-small-scale-randomised-experiment&quot;&gt;A small-scale randomised experiment&lt;/h3&gt;

&lt;p&gt;Let’s say we want to investigate whether the kind of music you happen to listen to affects how intellectually fulfilling you perceive your life to be.
We design an experiment with two conditions:
in one condition, people are asked to listen to John Coltrane’s &lt;a href=&quot;https://www.youtube.com/watch?v=5Pi5ZJZ07ME&quot;&gt;&lt;em&gt;A Love Supreme&lt;/em&gt;&lt;/a&gt;;
in the other condition, they are asked to endure mind-numbing muzak,
viz. Kenny G dubbing himself over Louis Armstrong’s &lt;a href=&quot;https://www.youtube.com/watch?v=4NPc7Y829dE&quot;&gt;&lt;em&gt;What a Wonderful World&lt;/em&gt;&lt;/a&gt;.
After listening to the song, they are asked to rate how intellectually fulfilling their life is on a scale from 1 (very unfulfilling) to 7 (very fulfilling).&lt;/p&gt;

&lt;p&gt;We recruit 6 participants – that’s on the small side, of course, but it’ll keep things tractable.
We want to assign three participants to the Coltrane song and three to the Kenny G one,
and to avoid a systematic bias in the results, we &lt;strong&gt;randomly&lt;/strong&gt; divide the participant sample into two equal parts.&lt;/p&gt;

&lt;p&gt;The answers to the questionnaire item are shown in this dotplot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-26-explaining-key-concepts-using-permutation-tests/unnamed-chunk-1-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;It surely &lt;em&gt;seems&lt;/em&gt; that listening to John Coltrane is associated with higher intellectual fulfillment ratings than listening to Kenny G.
Moreover, since we got these results in a randomised experiment, we could even make causal claims,
namely that listening to Coltrane vs Kenny G &lt;em&gt;causes&lt;/em&gt; higher intellectual fulfillment ratings.&lt;/p&gt;

&lt;h3 id=&quot;the-null-hypothesis&quot;&gt;The null hypothesis&lt;/h3&gt;

&lt;p&gt;But before we draw such a conclusion, we need to address a more trivial explanation of these data:
perhaps they are just a fluke – perhaps the participants in the Coltrane condition happened to be the participants who tended to perceive their life to be more intellectually fulfilling anyway and we were just lucky to assign them to the Coltane condition.&lt;/p&gt;

&lt;p&gt;Fundamentally, it is this objection – that sheer randomness might also account for these data – that inferential statistics seeks to address.
This proposed explanation is known as the &lt;strong&gt;null hypothesis&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;(I’m delibrerately cutting corners here: the null hypothesis doesn’t always have to be ‘no effect – randomness only’.
In practice, though, you’d be hard-pressed to find other null hypotheses.)&lt;/p&gt;

&lt;p&gt;The way how inferential (frequentist) statistics usually proceeds is by &lt;strong&gt;arguing by contradiction&lt;/strong&gt;:
we try to calculate how surprising our results would be if randomness alone – and no systematic effect – were at play.
In other words, we compute the probability (&lt;em&gt;p&lt;/em&gt;) of our results (and even more staggering results) under the assumption that the null hypothesis is actually true.
If this probability is small (say smaller than an arbitrary probability of 10%), we’d conclude that ‘randomness alone’ isn’t a viable explanation of our results and that systematic effects are at play, too.&lt;/p&gt;

&lt;h3 id=&quot;why-random-assignment-works&quot;&gt;Why random assignment works&lt;/h3&gt;

&lt;p&gt;Typically, we would run an off-the-shelf statistical test (e.g. a &lt;em&gt;t&lt;/em&gt;-test) to calculate this probability.
Most of these tests derive from the Central Limit Theorem (CLT): 
if we’re willing to make some assumptions, the CLT tells us how the means from data points sampled randomly from a larger population are distributed.
From this knowledge, we can derive the probability that the means of our two groups would differ by at least as much as they do
if randomness were the only factor at play.
For the purposes of this blog post, however, I want to focus on an inferential technique 
that makes fewer assumptions than CLT-derived tests and that isn’t restricted to differences between means.&lt;/p&gt;

&lt;p&gt;Its logic is as follows.
If listening to the Coltrane vs Kenny G song didn’t affect the intellectual fulfillment ratings (= the null hypothesis),
then &lt;em&gt;any difference&lt;/em&gt; between the two groups must be &lt;strong&gt;due to the random assignment&lt;/strong&gt; of participants to conditions.
If this were the case, the data that we happened to observe (difference between group means: 2.67):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-26-explaining-key-concepts-using-permutation-tests/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;were as likely to occur as those where the assignment of participants to condition woud have turned out differently, say (difference between group means: 1.33): &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-26-explaining-key-concepts-using-permutation-tests/unnamed-chunk-3-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Rather than relying on the Central Limit Theorem,
we could write down &lt;strong&gt;every possible recombination&lt;/strong&gt; of the scores of 2, 7, 6, 1, 1 and 5 into two groups,
calculate the difference between the two group means for each possibility,
and see how unusual the result we actually got is.
(This, incidentally, is also the logic behind the graphical statistical inference tests I &lt;a href=&quot;/teaching/2014/09/12/a-graphical-explanation-of-p-values&quot;&gt;blogged&lt;/a&gt; about a while ago.)&lt;/p&gt;

&lt;h3 id=&quot;exhaustive-recombining&quot;&gt;Exhaustive recombining&lt;/h3&gt;

&lt;p&gt;For small samples, it is possible to list every possible combination of scores into two groups of equal size:&lt;/p&gt;

&lt;p&gt;2 observations can be allocated in 2 ways: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A / B&lt;/li&gt;
  &lt;li&gt;B / A&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4 observations can be allocated in 6 ways (note that the order within the groups doesn’t matter):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A, B / C, D &lt;/li&gt;
  &lt;li&gt;A, C / B, D&lt;/li&gt;
  &lt;li&gt;A, D / B, C&lt;/li&gt;
  &lt;li&gt;B, C / A, D&lt;/li&gt;
  &lt;li&gt;B, D / A, C&lt;/li&gt;
  &lt;li&gt;C, D / A, B&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;6 observations can be allocated in 20 ways:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A, B, C / D, E, F&lt;/li&gt;
  &lt;li&gt;A, B, D / C, E, F&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;8 observations can be allocated in 70 ways, etc.&lt;/p&gt;

&lt;p&gt;We can compute the number of possible combinations using R’s &lt;code&gt;choose()&lt;/code&gt; function, e.g.:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# How many ways to allocate 12 observations 
# to two groups of equal size (i.e. 6):
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 924&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;As you can imagine, the number of possible combinations sky-rockets as the sample size increases,
and it quickly becomes prohibitively computionally expensive to generate every single combination.
For small samples, though, it’s still pretty easy.
Using some relatively easy R code, 
we can recombine our 6 observations into two groups of 3 in each of 20 possible ways
and compute the difference between the group means.
If you’re not into R, feel free to skip the next few paragraphs – the rationale is more important than the actual computer code.&lt;/p&gt;

&lt;h4 id=&quot;skippable----r-code-computing-mean-difference-for-every-possible-recombination&quot;&gt;Skippable – R code: Computing mean difference for every possible recombination&lt;/h4&gt;

&lt;p&gt;First I define a function 
that takes a number of data points (‘vector’ in R-speak)
and a number of ‘indices’ that indicate which data points belong to Group 1 (the others belong to Group 2):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Define a function that computes the difference 
# in means (adaptable to other functions) 
# between one part of a vector (indices in Group1)
# and the remaining part (indices NOT in Group1)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean.diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;diff.mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff.mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To illustrate how this function works, we read in our actual data
and specify which data points belong to Group 1:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Read in actual data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actual.data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# The first, second and third data points 
# are in the &#39;Coltrane&#39; group:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coltrane&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Compute mean difference 
# between Coltrane group and rest:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean.diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actual.data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coltrane&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 2.67&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Of course, we could’ve computed this difference in an easier way, but defining this function makes the next couple of steps easier.&lt;/p&gt;

&lt;p&gt;Next, we generate a list of every possible way in which the Coltrane group could’ve been made up.
For this, I use the &lt;code&gt;combn()&lt;/code&gt; function; the numbers refer to the 1st, 2nd, …, 6th data point, not to the values of the data points themselves:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# For the 1st, 2nd ... 6th data points
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# Allocate 3 data points to Group 1
&lt;/span&gt;                      &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# (and return output as a list)
&lt;/span&gt;                      &lt;span class=&quot;n&quot;&gt;simplify&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# uncomment next line to show all 20 combinations
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now, we apply the &lt;code&gt;mean.diff()&lt;/code&gt; function that we wrote earlier to our data set (&lt;code&gt;actual.data&lt;/code&gt;)
for every possible combination of indices listed in &lt;code&gt;combinations&lt;/code&gt; (i.e., 1-2-3, 1-2-4, 1-2-5 etc.):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# apply function mean.diff
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean.diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# for every combination of indices in combinations
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# apply to actual.data 
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;MoreArgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actual.data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;results&quot;&gt;Results&lt;/h4&gt;

&lt;p&gt;We have now calculated &lt;em&gt;every possible difference in group means possible&lt;/em&gt;.
Here they are, sorted from lowest to highest:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-26-explaining-key-concepts-using-permutation-tests/unnamed-chunk-9-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;We actually observed a difference of 2.67 between the two group means;
the vertical red lines indicate an absolute group mean difference of 2.67.
As you can see, four out of 20 possible group mean differences have absolute values of 2.67 or higher.
Put differently, the probability to observe an absolute group mean difference of 2.67 or higher
&lt;em&gt;if randomness alone were at play&lt;/em&gt; is 4/20 = 20%.&lt;/p&gt;

&lt;p&gt;This is our &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;-value&lt;/strong&gt;: the probability with which we would have obtained our observed difference (or even more extreme ones)
if randomness alone were at play.
So even if no systematic effect exists, we would still obtain an absolute mean difference of 2.67 or larger in 20% of cases.
This isn’t terribly unlikely (and higher than the 10% threshold we specified above), 
so the null hypothesis that randomness alone is at play is still a viable explanation of our results.
Note that this doesn’t necessarily mean that the null hypothesis is the &lt;em&gt;correct&lt;/em&gt; explanation,
i.e. we haven’t in any way proven that there &lt;em&gt;isn’t&lt;/em&gt; a systematic effect.&lt;/p&gt;

&lt;h3 id=&quot;what-i-like-about-these-permutation-tests&quot;&gt;What I like about these ‘permutation tests’&lt;/h3&gt;

&lt;h4 id=&quot;less-restrictive-assumptions&quot;&gt;Less restrictive assumptions&lt;/h4&gt;

&lt;p&gt;First, from a practical perspective, these permutation tests are &lt;strong&gt;relatively assumption-free&lt;/strong&gt;.
Statistical tests derived from the Central Limit Theorem all need to assume that the sample mean distribution is well approximated by a normal distribution.
This needn’t be a problem for large samples, but it usually requires a leap of faith for small samples.
Permutation tests, by contrast, rely on the much weaker assumption that the data points are mutually interchangeable under the null hypothesis (i.e. come from the same distribution).
This may sound somewhat esoteric, 
but it essentially means that a participant who happened to be part of Group 1 could as easily have been part of Group 2.&lt;/p&gt;

&lt;h4 id=&quot;flexibility-with-respect-to-what-is-being-compared&quot;&gt;Flexibility with respect to what is being compared&lt;/h4&gt;

&lt;p&gt;Second, while we focused on the difference between the group &lt;em&gt;means&lt;/em&gt;, 
we could easily have use the difference between the group &lt;em&gt;medians&lt;/em&gt; as a test statistic, 
or pretty much every other test statistic imaginable – i.e. permutation tests are extremely &lt;strong&gt;flexible&lt;/strong&gt;.
This code, for instance, operates along exactly the same lines, but compares the &lt;em&gt;variances&lt;/em&gt; of the groups:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Define a function to compute 
# difference in group variances
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var.diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;diff.var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; 
               &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff.var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# apply function median.diff
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diffs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var.diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# for every combination of indices in combinations
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;Group1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# apply to actual.data
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;MoreArgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actual.data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 

&lt;span class=&quot;n&quot;&gt;dotchart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diffs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Group variance difference&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Group variance differences\n
                 for all possible combinations&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var.diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actual.data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coltrane&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
       &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var.diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actual.data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coltrane&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
       &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-26-explaining-key-concepts-using-permutation-tests/unnamed-chunk-10-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;So in 18 out of 20 cases, we would have observed variance differences as large as or larger than the difference we actually obtained.&lt;/p&gt;

&lt;h4 id=&quot;the-test-follows-from-the-design&quot;&gt;The test follows from the design&lt;/h4&gt;

&lt;p&gt;The first two points are primarily of practical importance.
But, more importantly, permutation tests also illustrate all-important theoretical concepts.
Specifically, they stress that there is a clear logical link between the statistical test we use 
and the &lt;strong&gt;experimental design&lt;/strong&gt; we opted for:
using a permutation test is entirely warranted by the random assignment of participants to two equal-sized groups.
Stressing the link between experimental design and statistical inference – rather than considering them separately – is of huge pedagogical, as well as practical, use, I believe.&lt;/p&gt;

&lt;p&gt;In fact, this link between design and analysis means that
it’s not so much the case that permutation tests are a substitute for more commonly used tests such as the &lt;em&gt;t&lt;/em&gt;-test,
it’s the other way round. 
As Fisher (1936; quoted by &lt;a href=&quot;http://projecteuclid.org/download/pdfview_1/euclid.ss/1113832732&quot;&gt;Ernst 2004&lt;/a&gt;) put it,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;the statistician does not carry out this very simple and very tedious process [i.e. running a permutation test, JV],
but his conclusions have no justification beyond the fact that they agree
with those which could have been arrived at by this elementary method.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In class, this point could segue into an interesting discussion about the value of &lt;em&gt;p&lt;/em&gt;-values in non-randomised (quasi-)experiments where randomisation isn’t available as the ultimate rationale for conducting statistical tests. &lt;/p&gt;

&lt;h4 id=&quot;the-test-has-to-follow-from-the-design&quot;&gt;The test &lt;em&gt;has&lt;/em&gt; to follow from the design&lt;/h4&gt;

&lt;p&gt;Permutation tests are eminently useful for illustrating why &lt;strong&gt;experimental design features matter&lt;/strong&gt;.
Let’s say that, in the example above, Elaine and Puddy, and Kramer and Newman were so inseparable 
that they wanted to listen to the same song.
Rather than being combinable in 20 different ways, the six data points would be combinable in only four ways:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;George, Newman, Kramer / Elaine, Puddy, Jerry (difference in means: 2.67)&lt;/li&gt;
  &lt;li&gt;George, Elaine, Puddy / Newman, Kramer, Jerry (difference: -4.67)&lt;/li&gt;
  &lt;li&gt;Elaine, Puddy, Jerry / George, Newman, Kramer (difference: -2.67)&lt;/li&gt;
  &lt;li&gt;Newman, Kramer, Jerry / George, Elaine, Puddy (difference: 4.67)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The 14 combinations where Newman and Kramer, and Elaine and Puddy aren’t in the same condition wouldn’t be part of the range of possible randomisations.
The observed absolute difference in group means of 2.67 wouldn’t then be associated with a &lt;em&gt;p&lt;/em&gt;-value of 20%, but with one of 100%!&lt;/p&gt;

&lt;p&gt;Less prohibitive restricting would also affect our inferences.
If, for instance, Jerry and Newman would refuse to listen to the same song,
only 12 possible randomisations remain, and we would have to draw our conclusions with respect to these 12 possibilities – not with respect to the full set of 20 possibilities.&lt;/p&gt;

&lt;p&gt;In both cases, some data points &lt;strong&gt;weren’t independent&lt;/strong&gt; of one another: the occurrence of one implied the occurrence (or absence) of some others, which can drastically affect our inferences.
This point is hugely relevant to many studies in applied linguistics where the participants cannot be allocated to experimental conditions on an individual basis but only in whole groups, e.g. classes or schools (so-called ‘cluster-randomised designs’).
This design feature, in fact, even occurs in some studies in not-so-applied linguistics and psychology,
and it has to be taken explicitly into account in the analysis.
Thus, not only &lt;em&gt;can&lt;/em&gt; design features motivate the specification of a statistical test, they &lt;em&gt;should&lt;/em&gt; do so – even when not using permutation tests (cf. the quote from Fisher above).&lt;/p&gt;

&lt;p&gt;A case more subtle than cluster-randomisation occurs when, for perfectly valid reasons,
researchers insist on equating two groups with respect to one variable.
If, for instance, 12 men and 20 women are available for an experiment, the researcher can randomise the participants
to two groups with the restriction that each group should have 6 men and 10 women so as to balance out the sex variable (so-called ‘block designs’).
This design feature, too, needs to be taken into account.&lt;/p&gt;

&lt;p&gt;For a more in-depth discussion, see my &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Vanhove_AnalyzingRandomizedInterventions.pdf&quot;&gt;&lt;em&gt;Analyzing randomized controlled interventions: Three notes for applied linguists&lt;/em&gt;&lt;/a&gt; (see pages 6-7 for block designs and pages 11ff. for cluster randomisation).&lt;/p&gt;

&lt;h4 id=&quot;random-assignment-vs-random-sampling&quot;&gt;Random assignment vs random sampling&lt;/h4&gt;

&lt;p&gt;Finally, the justification of the permutation test above was the random assignment of participants to experimental conditions – &lt;em&gt;not&lt;/em&gt; that the participants were randomly sampled from a larger population.
Consequently, the validity of the conclusions based on this permutation test (and, following Fisher, of other statistical tests, too) is restricted to the sample in question.&lt;/p&gt;

&lt;p&gt;While permutation tests can also be used when random sampling was used, they require a different sort of justification (see &lt;a href=&quot;http://projecteuclid.org/download/pdfview_1/euclid.ss/1113832732&quot;&gt;Ernst 2004&lt;/a&gt;).
This is beyond the scope of this (already way too long) blog post, 
but it can be useful for driving home the point that drawing inferences about an effect in a sample and drawing inferences about an effect in a larger population require different kinds of justification.
In plain and somewhat simplified terms, unless our participants were randomly sampled from a larger population – and they rarely if ever are – we are technically restricted to inferring whether an effect can be observed in the sample we’ve got.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;All in all, I think there are a lot of important principles that a discussion of permutation tests can generate.
Of course, the example I gave was rather simple (small sample size, straightforward design), but for pedagogical purposes, I think it is meaty enough.&lt;/p&gt;

&lt;h3 id=&quot;references-and-further-reading&quot;&gt;References and further reading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;R. A. Fisher’s &lt;a href=&quot;http://psycnet.apa.org/psycinfo/1939-04964-000&quot;&gt;&lt;em&gt;Design of experiments&lt;/em&gt;&lt;/a&gt; discusses randomisation as the ‘physical basis of the validity of the test’ (see Chapter 2 for the ‘lady tasting tea’ example).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Michael Ernst’s &lt;a href=&quot;http://projecteuclid.org/euclid.ss/1113832732&quot;&gt;&lt;em&gt;Permutation methods: A basis for exact inference&lt;/em&gt;&lt;/a&gt; illustrates basic permutation tests and covers the distinction between random assignment and random sampling.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Gary Oehlert’s &lt;a href=&quot;http://users.stat.umn.edu/~gary/book/fcdae.pdf&quot;&gt;&lt;em&gt;First course in design and analysis of experiments&lt;/em&gt;&lt;/a&gt; amply covers the rationale for random assignment and the importance of considering design features when analysing experiments.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;My paper on &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Vanhove_AnalyzingRandomizedInterventions.pdf&quot;&gt;&lt;em&gt;Analyzing randomized controlled interventions&lt;/em&gt;&lt;/a&gt; covers many of the points raised here, though not within a permutation-test framework.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
        </entry>
              
        <entry>
            <title>Thinking about graphs</title>
            <link href="http://janhove.github.io/reporting/2015/02/21/thinking-about-graphs/" />
            <published>2015-02-21T00:00:00+01:00</published>
            <updated>2015-02-21T00:00:00+01:00</updated>
            <id>http://janhove.github.io/reporting/2015/02/21/thinking-about-graphs/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2015/02/21/thinking-about-graphs/">&lt;p&gt;I firmly believe that research results are best communicated graphically.
Straightforward scatterplots, for instance, tend to be much more informative than correlation coefficients to both novices and dyed-in-the-wool scholars alike.
Often, however, it’s more challenging to come up with a graph that highlights the patterns (or lack thereof) that you want to highlight in your discussion 
and that your readership will understand both readily and accurately.
In this post, I ask myself whether I could have presented the results from an experiment I carried out last year any better in a paper to be published soon.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;the-plot&quot;&gt;The plot&lt;/h3&gt;

&lt;p&gt;Earlier this week, I received the page proofs of an article in which I report on a learning experiment in a context of receptive multilingualism (&lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Vanhove_CorrespondenceRules.pdf&quot;&gt;preprint&lt;/a&gt;).
In the experiment, 80 speakers of German were asked to translate words from a closely related language, viz. Dutch.
One of the goals of the experiment was to find out whether the participants could translate certain words (‘ij cognates’ and ‘oe cognates’; it doesn’t matter much for this blog post) more accurately when they occurred in the last part of the experiment (‘Block 3’) compared to in the first part (‘Block 1’).
Here is the code that you can use to reproduce the plot showing the results (‘Figure 2’):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Read in data from my institutional webpage:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/Data/CorrespondenceRules_Blocks.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# &#39;Block&#39; contains number but it&#39;s more useful to consider it a factor here:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Load the ggplot2 package for graphics
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Draw plot of &#39;CorrectVowel&#39; by &#39;Block&#39;:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CorrectVowel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;c1&quot;&gt;# draw boxplot, but don&#39;t draw outliers
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# because next line plots all datapoints individually
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outlier.shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;c1&quot;&gt;# add individual datapoints and label them
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# and jitter them horizontally (less overlap)
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  
            &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position_jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;c1&quot;&gt;# separately for each category
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# label axis
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correct vowel choices (%)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Warning: Removed 1 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Warning: Removed 1 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Warning: Removed 1 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-21-thinking-about-graphs/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Warning messages refer to suppressed outliers,
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;which&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;would&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;otherwise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;have&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;been&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plotted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;twice.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Percentage of correct vowel choices for each ‹ij› and ‹oe› cognate depending on whether it occurred in Block 1 or 3.
The boxplots mark the quartiles of each distribution. 
Only answers on untrained correspondences were considered, i.e., ‹ij› cognates for ‹oe› participants and vice versa.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Some of the labels overlap, and I used a vector graphics editor (&lt;a href=&quot;http://inkscape.org&quot;&gt;Inkscape&lt;/a&gt;) to move the labels horizontally to sort that out.
I think that this plot contains a lot of useful information, &lt;a href=&quot;/reporting/2015/01/07/some-alternatives-to-barplots&quot;&gt;especially compared to a run-of-the-mill barplot&lt;/a&gt;:
not only are the individual datapoints plotted, they are also labelled so that it’s relatively easy to see that &lt;em&gt;schoen&lt;/em&gt; was a particulary difficult word and that &lt;em&gt;wijze&lt;/em&gt; saw a 10pp-increase in accuracy from Block 1 to Block 3.&lt;/p&gt;

&lt;h3 id=&quot;other-options&quot;&gt;Other options?&lt;/h3&gt;

&lt;p&gt;‘Relatively’ is the operative word in the preceeding paragraph, though:
I don’t think I drew an &lt;em&gt;awful&lt;/em&gt; plot, 
but I now think I could’ve presented my readership with some better alternatives.
For instance, how about plotting the ‘before’ and ‘after’ scores in a slightly embellished scatterplot?&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# We need the data in a slightly different format;
# use dcast from the reshape2 package:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# see http://seananderson.ca/2013/10/19/reshape.html
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dcast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;value.var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;CorrectVowel&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Rename the columns
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Item&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Category&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Block1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Block3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# dat2 # uncomment to see the results
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Scatterplot 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# label the datapoints
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;c1&quot;&gt;# separate scatterplots for each category
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# label axes
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;scale_x_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correct vowel choices (%) in Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correct vowel choices (%) in Block 3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# add &#39;x = y&#39; line
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linetype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;dashed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-21-thinking-about-graphs/unnamed-chunk-3-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;The dashed line divides the scatterplot such that stimuli appearing above the line
are translated more accurately in Block 3 than in Block 1 and those that appear below it are translated less accurately in Block 3 than in Block 1.
This can give a rough-and-ready impression of how many items showed an increase in accuracy
as well as by what margin (vertical distance to the dashed line).&lt;/p&gt;

&lt;p&gt;Instead of plotting the two stimulus categories separately,
we could of course also plot them in the same graph.
Here’s the R code to draw such a plot (plot not displayed here).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_x_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correct vowel choices (%) in Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correct vowel choices (%) in Block 3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linetype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;dashed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I think these scatterplots are a step up from the original boxplot comparisons,
but they can still be criticised.
First, I think that the dashed ‘x = y’ line might somehow come across as the fit line from a linear regression. We could obviously spell it out in the caption that this isn’t the case, but it’d be better if it were immediately obvious.
Second, it is difficult to gauge distances with respect to a diagonal line:
the &lt;em&gt;vertical&lt;/em&gt; distance from the word &lt;em&gt;groet&lt;/em&gt; to the dashed line is fairly large, but
its &lt;em&gt;perpendicular&lt;/em&gt; distance to the line is necessarily smaller, which might convey a false impression.
Again, we could spell this out in the caption, but it’d be better if we didn’t have to.&lt;/p&gt;

&lt;!-- Such a plot could also be useful for identifying patterns in the data that aren&#39;t immediately obvious from boxplot comparisons.
For instance, these scatterplots show that _ijzer_, _schijf_, _hijt_ (left) and _schoen_ (right) are as difficult to translate in Block 3 as they were in Block 1.
Th --&gt;

&lt;p&gt;In view of these two criticisms, 
the following graph shows the &lt;em&gt;improvement&lt;/em&gt; in accuracy in Block 3 compared to Block 1 plotted against the baseline accuracies.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Calculate difference between 3 and 1
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Difference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Block3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Block1&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Draw scatterplot of baseline vs improvement
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_x_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correct vowel choices (%) in Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Improvement in vowel choice accuracy (pp)\nin Block 3 compared to Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linetype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;solid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-21-thinking-about-graphs/unnamed-chunk-5-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;The solid line again divides the stimuli that showed an improvement in accuracy and those that showed a decrease, but I think that a perfectly horizontal line is less readily mistaken for a regression fit line.
Additionally, the improvement in accuracy for each item can be gauged straightforwardly as the distance to the dividing line – without the need to specify that it’s the vertical distance rather than the perpendicular distance that’s important (they’re both the same).&lt;/p&gt;

&lt;p&gt;An additional benefit of this plot is that it can readily reveal peculiar patterns that might merit further investigation.
For instance, the effect of ‘Block’ on accuracy seems to depend on baseline accuracy (i.e. it doesn’t seem to be additive): there is a decreasing shape to the scatterplot.
We could highlight this trend by adding scatterplot smoothers to the panels, as in the graph below.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Block1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_x_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Correct vowel choices (%) in Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Improvement in vowel choice accuracy (pp)\nin Block 3 compared to Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linetype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;solid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# add loess scatterplot smoother; suppress confidence bands
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;loess&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;se&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-21-thinking-about-graphs/unnamed-chunk-6-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;A last alternative that I’ll mention is to plot boxplots of the accuracy improvements rather than of the raw accuracy scores separately for Blocks 1 and 3:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_boxplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outlier.shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position_jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Improvement in vowel choice accuracy (pp)\nin Block 3 compared to Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-02-21-thinking-about-graphs/unnamed-chunk-8-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;I don’t really like this plot as it throws away much of the information we could have gained by using scatterplots.
That said, highlighting a measure of the central tendency of the increases could be useful, 
so perhaps a combination of the scatterplots above and these boxplots could serve both purposes.&lt;/p&gt;

&lt;h3 id=&quot;open-questions&quot;&gt;Open questions&lt;/h3&gt;
&lt;p&gt;This blog posts merely serves as an illustration of how the same data can be visualised in sundry ways
and what factors go into choosing one graphic rather than the other options.
One hugely important factor that perhaps isn’t always fully considered is &lt;strong&gt;how the graph is likely to be perceived by the audience&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This entails anticipating misinterpretations that result from a cursory reading of the caption and the surrounding text (as I’ve tried to show above),
but on a more basic level it means taking into account the statistical literacy of your audience.
&lt;a href=&quot;http://www.itl.nist.gov/div898/handbook/eda/section3/qqplot.htm&quot;&gt;Quantile–quantile plots&lt;/a&gt;, for instance, are useful for comparing two samples,
but I don’t think the concept of quantiles is presently common currency for most readers.&lt;/p&gt;

&lt;p&gt;What is sorely lacking in this discussion is concrete &lt;strong&gt;evidence&lt;/strong&gt; about how easily and accurately graphical displays are interpreted by their intended audiences.
For instance, while I &lt;em&gt;think&lt;/em&gt; that a diagonal line in a scatterplot showing pre- and post-test data is often interpreted as a regression fit, I don’t actually know.
This lack of empirical data is also the reason why I’m hesitant to make sweeping recommendations about ‘best practices’ when it comes to drawing graphs.
A &lt;a href=&quot;http://dx.doi.org/10.1111/test.12032&quot;&gt;Bland–Altman (or Tukey mean-difference) plot&lt;/a&gt;, for instance, is easy enough to draw and explain (and similar to my second scatterplot; see R code below) and seems to be pretty common in the biomedical sciences.
But I don’t recall ever coming across one when when reading journals in linguistics, applied linguistics or psychology,
so most readers aren’t going to be familiar with it.
It might turn out that readers of applied linguistics journals can readily and accurately interpret Bland–Altman plots –
but it’s also possible that the additional – if simple – step of plotting differences against means rather than against baseline scores creates some sort of cognitive barrier.&lt;/p&gt;

&lt;p&gt;Actual studies on how applied linguists, educators, policy-makers etc. interpret common and not-so-common visualisations could only serve to improve the communicative quality of our research papers, and it’s something I might look into in the months to come.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# A Bland-Altmann plot plots the mean of two paired observations
# against the difference between them.
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# First compute mean:
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Block1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Block3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Then plot Bland-Altmann
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_x_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Overall correct vowel choices (mean %) in Blocks 1 and 3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Improvement in vowel choice accuracy (pp)\nin Block 3 compared to Block 1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;geom_abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intercept&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;slope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linetype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;solid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ggtitle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Tukey mean-difference plot&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
                      
        <entry>
            <title>Some alternatives to bar plots</title>
            <link href="http://janhove.github.io/reporting/2015/01/07/some-alternatives-to-barplots/" />
            <published>2015-01-07T00:00:00+01:00</published>
            <updated>2015-01-07T00:00:00+01:00</updated>
            <id>http://janhove.github.io/reporting/2015/01/07/some-alternatives-to-barplots/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2015/01/07/some-alternatives-to-barplots/">&lt;p&gt;Bar plots. They often deliver the main result of empirical studies, be it at conferences or in journal articles, by proudly showing that the mean score, reaction time etc. in one group is a notch higher than in the other.
But the information that bar plots convey is limited and sometimes downright misleading.
In this post, I suggest some alternatives you can use in your next presentation or paper.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;whats-wrong-with-bar-plots&quot;&gt;What’s wrong with bar plots?&lt;/h3&gt;

&lt;p&gt;Just to be clear: the bar plots I’m arguing against in this post are those that show the average result for each group, possibly complemented with confidence bars, but nothing more.
Below are three examples of such bar plots.
They summarise the results of one part of a learning experiment in which participants were assigned to one of two learning conditions (‘ij’ or ‘oe’, but it doesn’t really matter for this post) and then tried to translate a number of critical words in an unknown but related language.
The question of interest is whether participants in one learning condition outperform participants in the other.&lt;/p&gt;

&lt;p&gt;The bar plot on the left shows the mean percentage of correctly translated critical words per participant for each learning condition.
The plot in the middle additionally shows the upper limits of the means’ 95% confidence intervals; this type of plot is often referred to as a &lt;em&gt;dynamite plot&lt;/em&gt;.
The one on the right, finally, shows both the upper and lower limits of the 95% CIs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-01-07-some-alternatives-to-barplots/unnamed-chunk-2-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;While the tidiness of these three plots is appealing (you run your study, calculate the means and CIs, et voilà), the information they convey is limited to the group means and a measure of uncertainty about these means.
The bar plots don’t disclose several snippets of crucial information:
How many participants were there in each group?
Roughly how large is the overlap between the two groups?
And does the mean accurately convey the central tendency of the data?&lt;/p&gt;

&lt;p&gt;After all, mean percentages of roughly 30 and 40 can correspond to any of a well-nigh unlimited number of wildly different patterns in the data:
in principle, the bar plot on the left could correspond to a situation in which all participants have translated either 30 or 40% of the items correctly, to a situation in which 30 or 40% of the participants translated &lt;em&gt;all&lt;/em&gt; items correctly and 70 or 60% &lt;em&gt;none&lt;/em&gt; of them, and to pretty much anything in-between.
Even the variants with the error bars can correspond to pretty much anything from normally distributed data centred around 30 and 40%, over distributions with a couple of outliers to multimodal patterns (e.g. many participants with no correct translations, several participants around 50% and a handful with perfect scores).
The dynamite plot is particular is a perennial target of criticism for a &lt;a href=&quot;http://biostat.mc.vanderbilt.edu/wiki/pub/Main/TatsukiKoyama/Poster3.pdf&quot;&gt;host of additional reasons&lt;/a&gt;.
(Fittingly, it’s pretty difficult to get the &lt;code&gt;ggplot2&lt;/code&gt; graphical package for R to draw dynamite plots.)&lt;/p&gt;

&lt;h3 id=&quot;plot-the-raw-data&quot;&gt;Plot the raw data&lt;/h3&gt;
&lt;p&gt;The bar plot’s drawbacks can be avoided by adhering to one straightforward principle: &lt;strong&gt;show the raw data&lt;/strong&gt;.
You spent quite a bit of effort to collect it, so why not show it?
If your data set is fairly small, you could just plot the raw values, as in the plot on the left;
here, the data points are jittered horizontally to reduce the amount of overlap.&lt;/p&gt;

&lt;p&gt;An alternative that I quite like is shown on the right.
First, I draw &lt;a href=&quot;http://en.wikipedia.org/wiki/Box_plot&quot;&gt;boxplots&lt;/a&gt; (shown in the middle panel) for both groups 
and then I plot the individual data points on top of them. (If you do this, make sure you &lt;a href=&quot;http://www.zijdeman.nl/files/r_examples/boxplot_example.html&quot;&gt;don’t plot outliers twice&lt;/a&gt;!)
At a single glance, readers get an accurate sense of where the individual data points lie as well as where the quartiles of the data are situated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-01-07-some-alternatives-to-barplots/unnamed-chunk-3-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;The reason why I prefer to plot the individual data points rather than the naked box plots that more readers will be familiar with is that, much like bar plots, box plots can be deceptive.
As an example, consider the box plots below (data courtesy of my colleague Ladina). With median scores of about 45-50, first and third quartiles more or less symmetrically around the median, dito hinges and no outlying points, these box plots evoke symmetric, unimodal and well-behaved (if not quite normal) distributions.
On the basis of this plot, we’d be inclined to move on to &lt;em&gt;t&lt;/em&gt;-tests and the like for our inferences.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-01-07-some-alternatives-to-barplots/unnamed-chunk-4-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;However, the idea that these data are symmetrically and unimodally distributed is utterly wrong.
In fact, the box plots fail to convey the most striking aspect of these data, viz. that scores around 50% are entirely &lt;em&gt;atypical&lt;/em&gt;!
As the histograms shown below reveal, scores of 0 and 100 occur far more often than anything in-between,
so that both the mean and the median are poor summaries of the patterns in the data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-01-07-some-alternatives-to-barplots/unnamed-chunk-5-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;With nearly 3,000 observations, this data set is rather large, and plotting individual dots for each data point is probably inadvisable.
However, we don’t need to restrict ourselves to computing summary data and plotting those: here are some alternatives that stay true(r) to the original data.
The top left plot shows  &lt;a href=&quot;http://www.statmethods.net/graphs/boxplot.html&quot;&gt;&lt;em&gt;violin plots&lt;/em&gt;&lt;/a&gt; (which show the kernel density of the data) as well as the raw data as &lt;a href=&quot;http://stackoverflow.com/a/21314508/1331521&quot;&gt;transparent&lt;/a&gt; dots. This plot requires a bit of fiddling (&lt;em&gt;edit: This wasn’t intended as a pun, but it’s so bad I’ll keep it.&lt;/em&gt;) to underscore the heaps of observations at 0 and 100.&lt;/p&gt;

&lt;p&gt;The top right consists of &lt;a href=&quot;http://onlinestatbook.com/2/graphing_distributions/freq_poly.html&quot;&gt;&lt;em&gt;frequency polygons&lt;/em&gt;&lt;/a&gt;. These are essentially histograms in which the tops of the bars are connected and with the bars themselves removed. What I like about them in this case is that they convey the striking patterns in the data (the spikes at 0 and 100) and allow for a much better direct comparison of the two distributions than side-by-side histograms would.&lt;/p&gt;

&lt;p&gt;On the bottom row, the &lt;a href=&quot;http://r-dir.com/blog/2014/03/cdfs-in-r.html&quot;&gt;&lt;em&gt;empirical cumulative density functions&lt;/em&gt;&lt;/a&gt; of both conditions are directly compared. The left plot shows the default way of plotting ECDFs.
The spikes at 0 and 100 in the histogram show themselves as steep (in fact: vertical) increases in the graphs. From this graph, you can also glean that a score of 20 corresponds to roughly the 25th quantile of the data in Condition 2 (turquoise, or as we say in Flanders: ‘apple-blue-sea-green’), i.e. 25% of the observations in Condition 2 are lower than 20. The red line is a bit higher at this point, indicating that about 29% of the observations in Condition 1 are lower than 20.
Note that this means that the scores in Condition 1 tend to be &lt;em&gt;lower&lt;/em&gt; than those in Condition 2.&lt;/p&gt;

&lt;p&gt;As I find it counterintuitive that lower scores correspond to higher lines, the right plot shows the same ECDFs, but with the x- and y-axes flipped.
From this graph, you can easily glean that the median (cumulative density of 0.50) is higher in Condition 2, and that this is in fact pretty much the case for all quantiles: the red line lies consistently under the apple-blue-see-green one.
The spikes in the data now show themselves as flat (vertical) parts of the curves. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2015-01-07-some-alternatives-to-barplots/unnamed-chunk-6-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;These graphs probably aren’t optimal, but they illustrate that it isn’t necessary to stick to bar and box plots to visually report results.&lt;/p&gt;

&lt;h3 id=&quot;wrap-up&quot;&gt;Wrap-up&lt;/h3&gt;
&lt;p&gt;While tidy and familiar, bar plots reveal little information about the data we’ve worked hard to collect, and even the trusted box plot can conceal their most striking aspects. I don’t think we should to stick to the default ways of graphically conveying our results. As a rule, plots that stay true to the original data – ideally by plotting the raw data points – are better plots.&lt;/p&gt;

&lt;h3 id=&quot;code-and-links&quot;&gt;Code and links&lt;/h3&gt;
&lt;p&gt;I didn’t want to clutter this post with code block after code block. If you’re interested, you can download the R (and Markdown) code &lt;a href=&quot;http://janhove.github.io/downloads/2015-01-07-some-alternatives-to-barplots.Rmd&quot;&gt;here&lt;/a&gt; (open in RStudio).&lt;/p&gt;

&lt;p&gt;Also, as R help pages go, the &lt;code&gt;ggplot2&lt;/code&gt; &lt;a href=&quot;http://docs.ggplot2.org/0.9.3.1/index.html&quot;&gt;online documentation&lt;/a&gt; is unparallelled in terms of user-friendliness:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;how to draw &lt;a href=&quot;http://docs.ggplot2.org/0.9.3.1/geom_boxplot.html&quot;&gt;boxplots&lt;/a&gt; and &lt;a href=&quot;http://docs.ggplot2.org/0.9.3.1/geom_violin.html&quot;&gt;violin plots&lt;/a&gt; &lt;/li&gt;
  &lt;li&gt;how to draw &lt;a href=&quot;http://docs.ggplot2.org/0.9.3.1/geom_freqpoly.html&quot;&gt;frequency polygons&lt;/a&gt; &lt;/li&gt;
  &lt;li&gt;or &lt;a href=&quot;http://docs.ggplot2.org/current/stat_ecdf.html&quot;&gt;empirical cumulative density functions&lt;/a&gt; &lt;/li&gt;
  &lt;li&gt;how to &lt;a href=&quot;http://docs.ggplot2.org/0.9.3.1/coord_flip.html&quot;&gt;flip&lt;/a&gt; the x- and y-axes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Several other sites show you how to draw custom graphs, such as a &lt;a href=&quot;http://docs.ggplot2.org/0.9.3.1/geom_jitter.html&quot;&gt;boxplot that also shows&lt;/a&gt; &lt;a href=&quot;http://www.zijdeman.nl/files/r_examples/boxplot_example.html&quot;&gt;the individual data points&lt;/a&gt;.&lt;/p&gt;
</content>
        </entry>
                  
        <entry>
            <title>Assessing differences of significance</title>
            <link href="http://janhove.github.io/analysis/2014/10/28/assessing-differences-of-significance/" />
            <published>2014-10-28T00:00:00+01:00</published>
            <updated>2014-10-28T00:00:00+01:00</updated>
            <id>http://janhove.github.io/analysis/2014/10/28/assessing-differences-of-significance/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2014/10/28/assessing-differences-of-significance/">&lt;p&gt;When it comes to finding a powerful descriptive title for a research paper,
it’s hard to top Gelman and Stern’s 
&lt;a href=&quot;http://www.tandfonline.com/doi/abs/10.1198/000313006X152649#.VEn854_sM7w&quot;&gt;&lt;em&gt;The difference between “significant” and “not significant” is not itself statistically significant&lt;/em&gt;&lt;/a&gt;.
Yet, students and experienced researchers routinely draw substantial conclusions from effects being significant in one condition but not in the other.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Let’s say you recruit two groups – creatively named Group 1 and Group 2 – for an experiment.
In a between-subjects design, half of the participants in each group are tested in a control condition (Condition A) and half in an experimental condition (Condition B).
In Group 1, you observe what you’ve hoped for: a significant difference between Conditions A and B.
In Group 2, however, the effect of Condition isn’t significant.
Since you’re a creative researcher, your brain shifts into high gear and you can readily come up with a handful of interesting explanations as to why the effect can be observed in one group but not in the other. Perhaps the effect is moderated by the participants’ linguistic or cultural backgrounds, or perhaps the effect disappears in older participants?&lt;/p&gt;

&lt;p&gt;But let’s pause for a moment. As Gelman &amp;amp; Stern’s title says, “the difference between ‘significant’ and ‘not significant’ is not itself statistically significant”.
I take it that most researchers readily accept this when the &lt;em&gt;p&lt;/em&gt;-values involved hover around the 0.05 threshold.
For instance, with 25 observations, a correlation coefficient of 0.40 is statistically significant (&lt;em&gt;p&lt;/em&gt; = 0.048), whereas a correlation coefficient of 0.39 isn’t (&lt;em&gt;p&lt;/em&gt; = 0.061) – but it’s readily appreciated that the tiny difference between 0.39 and 0.40 probably isn’t meaningful.
After all, 0.05 is an arbitrary threshold.
But as Gelman &amp;amp; Stern explain with enviable clarity,
even more dramatic differences aren’t necessarily significant either.&lt;/p&gt;

&lt;p&gt;I think that researchers – both junior and more experienced ones – routinely read too much into comparisons of significance.
To be more specific, I think they play the ‘moderator’ card too quickly and don’t truly consider the more prosaic alternative: chance.
Obviously, the problem isn’t restricted to language-related research (see, e.g. &lt;a href=&quot;http://dx.doi.org/10.1038/nn.2886&quot;&gt;Nieuwenhuis et al. 2011 on neuroscience&lt;/a&gt;).
In this post, I discuss how to test whether the difference between a significant and a non-significant result really is significant for three types of tests: &lt;em&gt;t&lt;/em&gt;-tests, correlation coefficients, and χ²-tests.&lt;/p&gt;

&lt;h3 id=&quot;differences-between-mean-differences&quot;&gt;Differences between mean differences&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Example 1:&lt;/strong&gt; Two groups of 60 participants each are recruited. Half of the participants in each group are assigned to the control condition (Condition A), and half to the experimental condition (Condition B). The participants’ score on a continuous dependent variable is then compared between the conditions. In Group 1, the participants in Condition B (&lt;em&gt;n&lt;/em&gt; = 30, &lt;em&gt;M&lt;/em&gt; = 2.0, &lt;em&gt;SD&lt;/em&gt; = 1.7) significantly outperform those in Condition A (&lt;em&gt;n&lt;/em&gt; = 30, &lt;em&gt;M&lt;/em&gt; = 1.0, &lt;em&gt;SD&lt;/em&gt; = 1.6; &lt;em&gt;t&lt;/em&gt;(58) = 2.35, &lt;em&gt;p&lt;/em&gt; = 0.02).
In Group 2, by contrast, the difference between participants in Condition B (&lt;em&gt;n&lt;/em&gt; = 30, &lt;em&gt;M&lt;/em&gt; = 1.6, &lt;em&gt;SD&lt;/em&gt; = 1.8) and those in Condition A (&lt;em&gt;n&lt;/em&gt; = 30, &lt;em&gt;M&lt;/em&gt; = 1.2, &lt;em&gt;SD&lt;/em&gt; = 1.7) isn’t even approximately significant (&lt;em&gt;t&lt;/em&gt;(58) = 0.88, &lt;em&gt;p&lt;/em&gt; = 0.38).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-10-28-assessing-differences-of-significance/unnamed-chunk-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;In this example, researchers familiar with ANOVA will probably recognise that we can’t jump to conclusions about moderator variables just yet: we need to establish whether the effect of Condition is significantly different in the two groups. In other words, we need to investigate the interaction between Condition and Group. The (fictitious) data for this example are stored in the dataframe &lt;code&gt;df1&lt;/code&gt;, and the significance of the interaction term can easily be computed in R by running the &lt;code&gt;anova&lt;/code&gt; command on a linear model with Group, Condition and their interaction as predictors.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##     Outcome           Group          Condition 
##  Min.   :-2.820   Group 1:60   Condition A:60  
##  1st Qu.: 0.148   Group 2:60   Condition B:60  
##  Median : 1.482                                
##  Mean   : 1.450                                
##  3rd Qu.: 2.703                                
##  Max.   : 4.969&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Outcome&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Analysis of Variance Table
## 
## Response: Outcome
##                  Df Sum Sq Mean Sq F value Pr(&amp;gt;F)  
## Group             1      0    0.30    0.10  0.749  
## Condition         1     15   14.70    5.06  0.026 *
## Group:Condition   1      3    2.70    0.93  0.337  
## Residuals       116    337    2.91                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The effect of Condition, while significant in Group 1 and not significant in Group 2, 
does &lt;em&gt;not&lt;/em&gt; statistically differ between the groups (&lt;em&gt;F&lt;/em&gt;(1, 116) = 0.9, &lt;em&gt;p&lt;/em&gt; = 0.34).
Of course, that doesn’t mean that it &lt;em&gt;doesn’t&lt;/em&gt; differ from group to group (‘not significant’ ≠ ‘no effect’), 
but we can straightforwardly account for the observed data without invoking moderator variables.&lt;/p&gt;

&lt;h3 id=&quot;differences-between-correlation-coefficients&quot;&gt;Differences between correlation coefficients&lt;/h3&gt;
&lt;p&gt;In linguistic research, we’re often more interested in comparing the strength of the relationship between two (more or less) continuous variables measured in different samples (e.g. language learners at different levels; different language families etc.).
In this kind of enterprise, substantial conclusions are often drawn on the basis of significant vs. non-significant correlation coefficients (i.e. &lt;em&gt;r&lt;/em&gt;).&lt;/p&gt;

&lt;h4 id=&quot;independent-correlations&quot;&gt;Independent correlations&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Example 2:&lt;/strong&gt; We recruit two groups of 30 participants each (e.g. a group of French-speaking learners of German and a group of Dutch-speaking learners of German). All participants complete two tasks (e.g. an English vocabulary test and a German vocabulary test),
and we want to establish whether performance on the two tasks is correlated in the two groups.&lt;/p&gt;

&lt;p&gt;In the first group, we observe a significant correlation between the two variables (&lt;em&gt;r&lt;/em&gt; = 0.50, &lt;em&gt;p&lt;/em&gt; = 0.005),
whereas the correlation isn’t remotely significant in the second group (&lt;em&gt;r&lt;/em&gt; = 0.10, &lt;em&gt;p&lt;/em&gt; = 0.60).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-10-28-assessing-differences-of-significance/unnamed-chunk-4.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;It’s tempting to think that such a large difference must be significant,
but confidence intervals around correlation coefficients are ridiculously large.
For instance, the 90% confidence interval of &lt;em&gt;r&lt;/em&gt; in Group 1 is [0.17, 0.73],
and that in Group 2 [-0.27, 0.44], so the confidence intervals overlap considerably.
We need to test directly for the difference in the correlation coefficients.&lt;/p&gt;

&lt;p&gt;In this example, we compare correlation coefficients between groups,
i.e. the correlations are &lt;em&gt;independent&lt;/em&gt; of one another. 
Note that the fact that the variables are named identically in the two groups is of no consequence.
This is important since correlations can also be dependent, in which case a different analysis is needed (see below).
The significance of the &lt;em&gt;difference&lt;/em&gt; between two correlation coefficients is merely a function of (a) the correlation coefficients and (b) the sample sizes.
In R, the test for such a comparison is implemented in the &lt;code&gt;r.test()&lt;/code&gt; function in the &lt;code&gt;psych&lt;/code&gt; package (to download it, type &lt;code&gt;install.packages(&quot;psych&quot;)&lt;/code&gt; at the command prompt).
For this test, which is based on the Fisher &lt;em&gt;z&lt;/em&gt;-transformation, &lt;code&gt;r.test()&lt;/code&gt; takes the arguments &lt;code&gt;n&lt;/code&gt; (sample size in Group 1), &lt;code&gt;n2&lt;/code&gt; (sample size in Group 2), &lt;code&gt;r12&lt;/code&gt; (first correlation coefficient) and &lt;code&gt;r34&lt;/code&gt; (second correlation coefficient).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;psych&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;r.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
       &lt;span class=&quot;n&quot;&gt;n2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r34&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Correlation tests 
## Call:r.test(n = 30, r12 = 0.5, r34 = 0.1, n2 = 30)
## Test of difference between two independent correlations 
##  z value 1.65    with probability  0.1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Even though thedifference between the correlation coefficients for both groups is quite large (&lt;em&gt;r&lt;/em&gt; = 0.50 vs. 0.10), 
this difference isn’t itself statistically significant (&lt;em&gt;z&lt;/em&gt; = 1.65, &lt;em&gt;p&lt;/em&gt; = 0.10).&lt;/p&gt;

&lt;h4 id=&quot;dependent-correlations&quot;&gt;Dependent correlations&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Example 3:&lt;/strong&gt; Now imagine that rather than recruiting two groups of participants, we recruited just one group of 30 participants (e.g. Flemish learners of German). Each participant completes three tasks (e.g. an English, a French and a German vocabulary test), and we’re interested in comparing which of the two first tasks (English or French) is the better predictor of performance on the third task (German).&lt;/p&gt;

&lt;p&gt;We observe a significant correlation between (say) English and German test performance (&lt;em&gt;r&lt;/em&gt; = 0.50, &lt;em&gt;p&lt;/em&gt; = 0.005) on the one hand,
and a non-significant correlation between (say) French and German test performance (&lt;em&gt;r&lt;/em&gt; = 0.10, &lt;em&gt;p&lt;/em&gt; = 0.60) on the other hand.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-10-28-assessing-differences-of-significance/unnamed-chunk-6.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;This time, however, the correlations aren’t independent of one another: since the participants took all three tests, it’s likely that the two ‘independent’ variables correlate with one another, too. In this example, the correlation between English and French vocabulary test performance is &lt;em&gt;r&lt;/em&gt; = 0.70. This dependence needs to be taken into account when testing the significance of the difference between &lt;em&gt;r&lt;/em&gt; = 0.50 vs. 0.10. We can use the same &lt;code&gt;r.test()&lt;/code&gt; function as above but now we have to specify &lt;code&gt;r12&lt;/code&gt; (correlation between independent variable 1 and the dependent variable), &lt;code&gt;r13&lt;/code&gt; (correlation between independent variable 2 and the dependent variable) as well as &lt;code&gt;r23&lt;/code&gt; (the intercorrelation between the independent variables):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;r.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r23&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Correlation tests 
## Call:[1] &quot;r.test(n =  30 ,  r12 =  0.5 ,  r23 =  0.7 ,  r13 =  0.1 )&quot;
## Test of difference between two correlated  correlations 
##  t value 3.38    with probability &amp;lt; 0.0021&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this case, the difference between &lt;em&gt;r&lt;/em&gt; = 0.50 vs. 0.10 &lt;em&gt;is&lt;/em&gt; significant (&lt;em&gt;t&lt;/em&gt;(28) = 3.38, &lt;em&gt;p&lt;/em&gt; = 0.002).
The outcome of this test crucially depends on the intercorrelation between the two independent variables, e.g.:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;r.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r23&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Correlation tests 
## Call:[1] &quot;r.test(n =  30 ,  r12 =  0.5 ,  r23 =  0.1 ,  r13 =  0.1 )&quot;
## Test of difference between two correlated  correlations 
##  t value 1.76    with probability &amp;lt; 0.09&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;r.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r23&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Correlation tests 
## Call:[1] &quot;r.test(n =  30 ,  r12 =  0.5 ,  r23 =  0.8 ,  r13 =  0.1 )&quot;
## Test of difference between two correlated  correlations 
##  t value 4.64    with probability &amp;lt; 7.4e-05&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Incidentally, the above also applies when comparing the strength of the relationship between one indepedent variable and two dependent variables.
In addition, the intercorrelation should be taken into account even if it isn’t significant.&lt;/p&gt;

&lt;p&gt;For a more detailed treatment of comparing correlation coefficients, see Olkin &amp;amp; Finn’s (1995) &lt;a href=&quot;http://ripl.faculty.asu.edu/wp-content/uploads/2013/01/Olkin-Finn-1995.pdf&quot;&gt;&lt;em&gt;Correlation redux&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;differences-between-proportion-differences&quot;&gt;Differences between proportion differences&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Example 4:&lt;/strong&gt; We recruit two groups of 120 participants each and randomly assign half of the participants in each group to Condition A and half to Condition B. We present each participant with a dilemma, to which they must answer by either “yes” or “no”.&lt;/p&gt;

&lt;p&gt;In Group 1, we find a significant effect of Condition: of the 60 participants in Condition A, 35 answered “yes”, whereas only 20 participants answered “yes” in Condition B (χ²(1) = 7.6, &lt;em&gt;p&lt;/em&gt; = 0.006).
In Group 2, 30 out of 60 participants in Condition A responded positively, and 23 out of 37 participants in Condition B did likewise – a non-significant difference (χ²(1) = 1.7, &lt;em&gt;p&lt;/em&gt; = 0.20).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-10-28-assessing-differences-of-significance/unnamed-chunk-9.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;As in the examples above, it would be premature to start looking for moderator variables just yet.
What we need to investigate is the interaction between Condition and Group.
To that end, let’s first reconstruct the summary table with the number of positive and negative answers per Condition per Group (this, incidentally, can often be done even if you don’t have access to the raw data):&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;B&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;positive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df4&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   positive negative condition group
## 1       35       25         A     1
## 2       30       30         A     2
## 3       20       40         B     1
## 4       23       37         B     2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We have all the information we need to compute the significance of the interaction:
we can combine the columns with the positive and negative responses and feed it to a logistic regression model as the dependent variable;
the independent variables are Condition and Group, which are allowed to interact with one another.
(Sociolinguists already know a form of logistic regression (complemented with stepwise variable selection) as ‘variable rules analysis’ or Varbrul.)
We first construct the model (a logistic/binomial generalized linear model, hence &lt;code&gt;glm()&lt;/code&gt;),
and then compute an analysis of deviance table for the three terms in the model (two main effects and the interaction).
(Analysis of deviance is like ANOVA but for generalized models; here, we ask R to compute χ²-tests.)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;mod.glm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;positive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
               &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
               &lt;span class=&quot;n&quot;&gt;family&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;binomial&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod.glm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Chisq&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: cbind(positive, negative)
## 
## Terms added sequentially (first to last)
## 
## 
##                 Df Deviance Resid. Df Resid. Dev Pr(&amp;gt;Chi)   
## NULL                                3       9.36            
## condition        1     8.20         2       1.17   0.0042 **
## group            1     0.07         1       1.10   0.7918   
## condition:group  1     1.10         0       0.00   0.2950   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;While the effect of Condition is significant in Group 1 and not in Group 2, the Condition effect isn’t significant different between Groups 1 and 2 (χ²(1) = 1.1, &lt;em&gt;p&lt;/em&gt; = 0.29). &lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;p&gt;Most quantitatively-oriented researchers are familiar with investigating interaction effects when comparing mean differences.
For the same reason that we’re not content with computing two &lt;em&gt;t&lt;/em&gt;-tests and comparing their &lt;em&gt;p&lt;/em&gt;-values,
comparing the &lt;em&gt;p&lt;/em&gt;-values associated with correlation coefficients or χ²-tests doesn’t suffice.
It’s questionable to draw strong conclusions merely on the basis of an effect being significant in one condition/group/study and not in the other – even when the &lt;em&gt;p&lt;/em&gt;-values differ substantially.&lt;/p&gt;
</content>
        </entry>
                      
        <entry>
            <title>Silly significance tests: Balance tests</title>
            <link href="http://janhove.github.io/reporting/2014/09/26/balance-tests/" />
            <published>2014-09-26T00:00:00+02:00</published>
            <updated>2014-09-26T00:00:00+02:00</updated>
            <id>http://janhove.github.io/reporting/2014/09/26/balance-tests/</id>
            <content type="html" xml:base="http://janhove.github.io/reporting/2014/09/26/balance-tests/">&lt;p&gt;It’s something of a pet peeve of mine that your average research paper contains way too many statistical tests.
I’m all in favour of reporting research and analyses meticulously, but it’d make our papers easier to read – and ultimately more impactful – if we were to cut down on silly, superfluous significance tests.
Under scrutiny today: &lt;em&gt;balance tests&lt;/em&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;The term ‘silly significance test’ in the title comes from Abelson’s &lt;a href=&quot;http://books.google.ch/books?id=TgmbosIA7N0C&quot;&gt;&lt;em&gt;Statistics as principled argument&lt;/em&gt;&lt;/a&gt;
and refers to tests that don’t contribute anything to a research report other than making it harder to read.
I’d distinguish at least four kinds of ‘silly tests’ that we can largely do without – in this post, I focus on &lt;em&gt;balance tests&lt;/em&gt; in randomised experiments.&lt;/p&gt;

&lt;h3 id=&quot;what-are-balance-tests&quot;&gt;What are balance tests?&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Balance tests&lt;/em&gt;, also called &lt;em&gt;randomisation checks&lt;/em&gt;, are a ubiquitous type of significance test.
As an example of a balance test, consider a researcher who wants to compare a new vocabulary learning method to an established one. She randomly assigns forty participants to either the control group (established method) or the experimental group (new method). After four weeks, she tests the participants’ vocabulary knowledge – and let’s pretend she finds a significant difference in favour of the experimental group (e.g. t(38) = 2.7, p = 0.01).&lt;/p&gt;

&lt;p&gt;To pre-empt criticisms that the difference between the two groups could be due to factors other than the learning method,
the conscientious research also runs a t-test to verify that the control and experimental group don’t differ significantly in terms of age
as well as a Χ²-test to check whether the proportion of men and women in approximately the same in both groups.
The goal of these tests is to enable the researcher to argue that the randomisation gave rise to groups that are balanced with respect to these variables and that the observed difference between the two groups therefore can’t be due to these possible confounds.
If a balance test comes out significant, the researcher could be tempted to run another analysis with the possible confound as a covariate.&lt;/p&gt;

&lt;h3 id=&quot;why-are-they-superfluous&quot;&gt;Why are they superfluous?&lt;/h3&gt;

&lt;p&gt;Reasonable though this strategy may appear to be, balance tests are problematic in several respects.
The following list is based on a paper by &lt;a href=&quot;http://www.math.upenn.edu/~pemantle/papers/Preprints/perils.pdf&quot;&gt;Mutz and Pemantle (2013)&lt;/a&gt;.
This discussion gives you the short version;
for a somewhat more detailed treatment of balanced tests geared towards applied linguists, see the first section of my (as yet unpublished) paper on &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Unpublished/AnalyzingRandomizedInterventions.pdf&quot;&gt;analysing randomised controlled interventions&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;balance-tests-are-uninformative&quot;&gt;Balance tests are uninformative…&lt;/h4&gt;
&lt;p&gt;Statistical tests are used to draw inferences about a &lt;em&gt;population&lt;/em&gt; rather than about a specific &lt;em&gt;sample&lt;/em&gt;.
Sure, it’s possible to end up with 3 men in the experimental group and 14 in the control group; a Χ²-test would then produce a significance result.
But would we seriously go on to argue that men are more likely to end up in the control group than in the experimental group? 
Of course not!
We &lt;em&gt;know&lt;/em&gt; men were equally likely to end up in the control or experimental group because we randomly assigned all participants to the conditions – we &lt;em&gt;know&lt;/em&gt; the null hypothesis (no difference between the groups) is true with respect to this variable.
Consequently, every significant balance test is a false alarm that has come about due to sheer randomness.
A balance test can’t tell us anything we don’t know already.&lt;/p&gt;

&lt;h4 id=&quot;as-well-as-unnecessary&quot;&gt;… as well as unnecessary…&lt;/h4&gt;
&lt;p&gt;Researchers that concede the first point may go on to argue 
that their use of balance tests isn’t intended to make inferences about populations,
but to give an idea about the magnitude of the unbalancedness between the groups.
However, perfectly balanced groups are not a prerequisite for making valid statistical inferences.
Thus, balance tests are also unnecessary.&lt;/p&gt;

&lt;p&gt;To elaborate on this point, randomisation guarantees that all possible confounds – both the ones we had &lt;em&gt;and those we hadn’t&lt;/em&gt; thought of –
are balanced out on average, i.e. in the infamous long run.
A given randomisation may give rise to an experimental group that is older
or that has more women, or has a higher proportion of &lt;em&gt;MasterChef&lt;/em&gt; fans – 
and, yes, unbalancedness with respect to such variables could conceivably give rise to a larger or smaller observed treatment effect in any given study.
But the distribution of such fluke findings follows the laws of probability.
The &lt;em&gt;p&lt;/em&gt;-value for the main analysis already takes such flukes into account
and doesn’t need to be ‘corrected’ for an unbalanced distribution of possible confound variables.&lt;/p&gt;

&lt;h4 id=&quot;and-they-invalidate-significance-tests&quot;&gt;… and they invalidate significance tests.&lt;/h4&gt;

&lt;p&gt;Since &lt;em&gt;p&lt;/em&gt;-values have their precise meaning when no balance test is carried out, it follows that they don’t have their precise meaning when a balanced test &lt;em&gt;is&lt;/em&gt; carried out.
&lt;em&gt;p&lt;/em&gt;-values are conditional probability statements (‘the probability of observing data at least this extreme if the null hypothesis were true’), but by using balance tests, we add a condition to this statement: ‘the probability of observing data at least this extreme if the null hypothesis were true and if the balance test yields a particular result’.
This doesn’t seem like much, but it is a form of &lt;strong&gt;data-dependent analysis&lt;/strong&gt;, which invalidates significance tests. (For a more general discussion of data-dependent analyses, see &lt;a href=&quot;http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf&quot;&gt;Gelman &amp;amp; Loken 2013&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;A demonstration of this point seems in order.
I ran a small simulation (R code below) of the following scenario.
We want to test an experimental effect and randomly assign 40 participants to an experimental or a control condition.
The participants vary in age between 20 and 40.
The age variable doesn’t interest us so much, but it is linearly related to the outcome variable.
However, the treatment effect is 0, i.e. the null hypothesis is true.
Our analytical strategy is as follows:
We run a significance test on the age variable to see whether the experimental and control groups are ‘balanced’ in terms of age.
If this test comes back non-significant, we conclude that we have balanced groups and run a t-test on the outcome variable;
if the test comes back significant, we run an ANCOVA with age as a covariate.
I simulated this scenario 10,000 times and compared the distribution of the &lt;em&gt;p&lt;/em&gt;-values for the treatment effect resulting from this ‘conditional’ analytical strategy with those provided by t-tests and ANCOVAs that were run regardless of the outcome of the balance test. The histograms below show the distributions of &lt;em&gt;p&lt;/em&gt;-values for these three testing strategies.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-09-26-balance-tests/unnamed-chunk-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Since the null hypothesis is true in this case, the distribution of &lt;em&gt;p&lt;/em&gt;-values should be uniform, i.e. all bars should be roughly equally as high. This is the case in the left and middle histograms, showing that &lt;em&gt;p&lt;/em&gt;-values are correctly distributed when the analysis is not affected by balance tests.
Put simply, &lt;em&gt;p&lt;/em&gt;-values have their intended meaning in these cases.
The right histogram shows that low &lt;em&gt;p&lt;/em&gt;-values are too rare when the analysis is affected by balance tests: the test of the treatment effect is too conservative, i.e. its &lt;em&gt;p&lt;/em&gt;-value doesn’t have its intended meaning.&lt;/p&gt;

&lt;p&gt;Recent blogs and articles have highlighted the fact that data-dependent analysis yields anti-conservative &lt;em&gt;p&lt;/em&gt;-values, i.e. that it is too likely to observe a significant effect where none exists (e.g. &lt;a href=&quot;http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf&quot;&gt;Gelman &amp;amp; Loken 2013&lt;/a&gt; and &lt;a href=&quot;http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1850704&quot;&gt;Simmons et al. 2011&lt;/a&gt;).
It may therefore seem strange to highlight that data-dependent analysis can produce overconservative results, too.
My main point, however, is that balance tests produce &lt;em&gt;inaccurate&lt;/em&gt; results that can easily be avoided – regardless of the direction of the error.
That said, overconservatism has a practical downside as well, namely lower power: it’s less likely to observe a statistically significant effect when the effect does in fact exist.
The following histograms show the &lt;em&gt;p&lt;/em&gt;-value distribution when there is a relatively small effect (see also R code below).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-09-26-balance-tests/unnamed-chunk-2.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Clearly, the ANCOVA-only strategy wins hands-down in terms of power, whereas the balance test strategy doesn’t even compare favourably to the &lt;em&gt;t&lt;/em&gt;-test-only approach.&lt;/p&gt;

&lt;h3 id=&quot;solutions&quot;&gt;Solutions&lt;/h3&gt;
&lt;p&gt;The solution to simple: &lt;strong&gt;just don’t use balance tests&lt;/strong&gt;.
They clutter up the research report and don’t have any obvious advantages when analysing randomised experiments.
When there are good reasons to assume that a covariate affects the results, it’s a good idea to include it in the main analysis &lt;em&gt;regardless&lt;/em&gt; of whether the experimental and control groups are balanced with respect to this variable.
In fact, &lt;a href=&quot;http://www.math.upenn.edu/~pemantle/papers/Preprints/perils.pdf&quot;&gt;Mutz and Pemantle (2013)&lt;/a&gt; show that including a covariate in the analysis is slightly &lt;em&gt;more&lt;/em&gt; effective when the groups are in fact balanced.
While this post is strictly on &lt;em&gt;randomised&lt;/em&gt; experiments, I would think that this is also the most sensible strategy when analysing non-randomised quasi-experiments.&lt;/p&gt;

&lt;p&gt;Alternatively, it can make sense to consider the covariate in the design of the study, i.e. before randomising (see the part in my &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/Unpublished/AnalyzingRandomizedInterventions.pdf&quot;&gt;analysis paper&lt;/a&gt; on ‘blocking’, pp. 6-7).&lt;/p&gt;

&lt;h3 id=&quot;r-code&quot;&gt;R code&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;simulate.balance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;effect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covar.effect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length.out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covar.effect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;effect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# t-test regardless of balancedness
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;test1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var.equal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p.value&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# balance test
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t.test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var.equal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p.value&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# conditional analysis
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Pr(&amp;gt;F)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test1&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# ancova regardless of balancedness
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;test3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;age&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Pr(&amp;gt;F)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;test2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;test3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;simulate.balance2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;effect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covar.effect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Settings for histograms above: &lt;code&gt;effect = 0&lt;/code&gt; and &lt;code&gt;effect = 1&lt;/code&gt;.&lt;/p&gt;

</content>
        </entry>
              
        <entry>
            <title>A purely graphical explanation of p-values</title>
            <link href="http://janhove.github.io/teaching/2014/09/12/a-graphical-explanation-of-p-values/" />
            <published>2014-09-12T00:00:00+02:00</published>
            <updated>2014-09-12T00:00:00+02:00</updated>
            <id>http://janhove.github.io/teaching/2014/09/12/a-graphical-explanation-of-p-values/</id>
            <content type="html" xml:base="http://janhove.github.io/teaching/2014/09/12/a-graphical-explanation-of-p-values/">&lt;p&gt;&lt;em&gt;p&lt;/em&gt;-values are confusing creatures–not just to students taking their first statistics course but to seasoned researchers, too.
To fully understand how &lt;em&gt;p&lt;/em&gt;-values are calculated, you need to know a good deal of mathematical and statistical concepts (e.g. probability distributions, standard deviations, the central limit theorem, null hypotheses), and these take a while to settle in.
But to explain the &lt;em&gt;meaning&lt;/em&gt; of &lt;em&gt;p&lt;/em&gt;-values, I think we can get by without such sophistication.
So here you have it, a purely graphical explanation of &lt;em&gt;p&lt;/em&gt;-values.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;a-graphical-t-test--anova&quot;&gt;A graphical &lt;em&gt;t&lt;/em&gt;-test / ANOVA&lt;/h3&gt;

&lt;p&gt;The statistical tests you’re most likely to run into are the two-sample &lt;em&gt;t&lt;/em&gt;-test and its big brother, analysis of variance (ANOVA).
These tests are used to establish whether the difference between two or more group averages are due to chance or whether their is some underlying system to them.&lt;/p&gt;

&lt;p&gt;For this example, I use data from my Ph.D. project.
The goal of this analysis (not of my thesis, though) is to establish whether men and women differ in their ability to understand spoken words in an unknown but related foreign language.
The following R code reads in the data, tabulates the number of men and women (&lt;code&gt;table()&lt;/code&gt;) and shows the distribution of the participants’ scores on the listening test (&lt;code&gt;hist()&lt;/code&gt;).
To reproduce this analysis, you’ll need to install R, which is freely available from &lt;a href=&quot;http://r-project.org/&quot;&gt;http://r-project.org/&lt;/a&gt;–and while you’re at it, download a graphical user interface like &lt;a href=&quot;http://rstudio.com/&quot;&gt;RStudio&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://janhove.github.io/datasets/sinergia.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
## female   male 
##     90     73&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Spoken&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Histogram&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Score&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lightblue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-09-12-a-graphical-explanation-of-p-values/unnamed-chunk-2.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To establish whether men and women differ ‘significantly’ from one another, we’d usually plot the data, run a &lt;em&gt;t&lt;/em&gt;-test, and check the reported &lt;em&gt;p&lt;/em&gt;-value,
but an alternative approach is discussed by &lt;a href=&quot;http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=5613434&quot;&gt;Wickham and colleagues&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;basic idea&lt;/strong&gt; is as follows.
If there is a systematic relationship between two variables (e.g. a difference in group averages), then we ought to be able to tell the &lt;em&gt;real&lt;/em&gt; dataset from &lt;em&gt;fake&lt;/em&gt; datasets that were randomly generated without an underlying systematic relationship.
To generate fake but ‘realistic’ datasets, we can permute the real data, i.e., randomly switch the datapoints between the groups.
Then, we organise a line-up (like in the movies!) with the real dataset hidden among several fake datasets.
If we can distinguish the real dataset from the fake ones, we have some evidence that there is some degree of system in the real data that is not present in the fake data.&lt;/p&gt;

&lt;p&gt;This procedure is implemented in the &lt;code&gt;nullabor&lt;/code&gt; package for R, which relies on the &lt;code&gt;ggplot2&lt;/code&gt; package.
Make sure you have these two packages installed on your machine (&lt;code&gt;install.packages()&lt;/code&gt;).&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Remove the # before the two next lines to install the ggplot2 and nullabor packages.
# install.packages(&quot;ggplot2&quot;)
# install.packages(&quot;nullabor&quot;)
# Load packages
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nullabor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The following code plots the listening scores for all participants according to whether they’re male or female,
but the real dataset is hidden among 19 fake (permuted) datasets.
The crosshairs mark the means for each sex in each dataset.
Can you pick out the real dataset?
(The code to generate this plot is somewhat complicated but is of no consequence to the argument; don’t lose yourself in it.)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Spoken&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%+%&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;lineup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;null_permute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Spoken&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
      &lt;span class=&quot;c1&quot;&gt;#geom_boxplot(outlier.shape = NA, na.rm = TRUE) +
&lt;/span&gt;      &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;position_jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;stat_summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fun.y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                   &lt;span class=&quot;n&quot;&gt;geom&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;point&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                   &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;guides&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colour&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;.sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## decrypt(&quot;42Dm dbSb 8o Kpq8S8po Y&quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-09-12-a-graphical-explanation-of-p-values/unnamed-chunk-4.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Most sample means are pretty similar, but not entirely identical, to each other.
Due to the randomness inherent in generating permutations, some differences between the sample means for men and women are in fact expected.
This is known as &lt;strong&gt;sampling error&lt;/strong&gt;.
If men’s and women’s listening scores didn’t differ systematically from one another, we wouldn’t be able to pick out the real dataset with &lt;strong&gt;above-chance accuracy&lt;/strong&gt;, i.e., we would only have a 1 in 20 (5%) chance of picking the right answer.&lt;/p&gt;

&lt;p&gt;If there were some systematic difference between the two groups, however, we would be able to beat those odds.
Eye-balling these plots, I’d say that Panel 3 stands out in that the difference between men and women is larger than in the other panels.
Using the encrypted code provided above, we can check whether this hunch is correct:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;decrypt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;42Dm dbSb 8o Kpq8S8po Y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] &quot;True data in position 3&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It is.
If there were no systematic difference between the two groups (``if the null hypothesis were correct’’, in statistics parlance), I’d only have had a 1-in-20 chance of picking the right answer, yet I managed to do so.
Put differently, it’s pretty unlikely (5%) to observe this noticeable a difference between the two groups if no systematic pattern existed, and from this we’d usually conclude that there &lt;em&gt;is&lt;/em&gt; some systematic pattern.
This, in effect, is what is expressed by ‘&lt;em&gt;p&lt;/em&gt; = 0.05’.
To establish ‘&lt;em&gt;p&lt;/em&gt; = 0.01’ using this procedure, you’d have to be able to pick out the actual dataset when it’s hidden among 99 fake datasets – but that wouldn’t work now since you already know how it looks.&lt;/p&gt;

&lt;p&gt;A cautionary note, though: While we’ve established with some confidence that women have differerent (higher) listening scores from men, we’ve not demonstrated that it’s the sex difference that &lt;em&gt;causes&lt;/em&gt; this difference.
In this study, the men were on average somewhat older than the women, for instance.&lt;/p&gt;

&lt;h3 id=&quot;a-graphical-correlation-test&quot;&gt;A graphical correlation test&lt;/h3&gt;

&lt;p&gt;The graphical test can also be applied to the relationship between two continuous variables.
Usually, we’d compute a correlation test or fit a regression model to get a &lt;em&gt;p&lt;/em&gt;-value for such a situation.&lt;/p&gt;

&lt;p&gt;The following plot shows the relationship between a measure of intelligence (‘Raven’) and the participants’ performance on a reading task.
The real dataset is again hidden among 19 fake datasets that were generated without an underlying pattern.
Can you spot the real dataset?&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Raven&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Written&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%+%&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;lineup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;null_permute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Raven&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;.sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## decrypt(&quot;42Dm dbSb 8o Kpq8S8po u9&quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-09-12-a-graphical-explanation-of-p-values/unnamed-chunk-6.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;You might be able to spot the real dataset, but I had to peek at the right answer to know it was Panel 16.
In this case, I wasn’t able to beat the odds since the real data look too similar to the fake data, suggesting that ‘no systematic pattern’ is a more parsimonious relationship.&lt;/p&gt;

&lt;p&gt;Compare this to the following plot, which shows the participants’ reading scores in function of their English skills.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;English&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Written&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%+%&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;lineup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;null_permute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;English&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;facet_wrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;.sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## decrypt(&quot;42Dm dbSb 8o Kpq8S8po k&quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-09-12-a-graphical-explanation-of-p-values/unnamed-chunk-7.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;If you picked Panel 2 because its discernible positive trend, you’d be right. A statistical test would likely yield a &lt;em&gt;p&lt;/em&gt;-value lower than 0.05. In fact, in this case, you’d probably be able to pick out the real data from among a much larger number of fake datasets.&lt;/p&gt;

&lt;h3 id=&quot;concluding-remarks&quot;&gt;Concluding remarks&lt;/h3&gt;
&lt;p&gt;Obviously there’s some subjectivity inherent in this type of analysis,
and the procedure breaks down when you already know the shape of the actual data.
To increase its reliability, you could try to enlist the help of a panel of independent judges who are not involved in the research project.
That said, the goal of this post was to clarify what enigmatic phrases like ‘&lt;em&gt;p&lt;/em&gt; &amp;lt; 0.05’ express: the degree of unusualness of the data at hand compared to data with no underlying systematic pattern.&lt;/p&gt;
</content>
        </entry>
                  
        <entry>
            <title>Calibrating p-values in &#39;flexible&#39; piecewise regression models</title>
            <link href="http://janhove.github.io/analysis/2014/08/20/adjusted-pvalues-breakpoint-regression/" />
            <published>2014-08-20T00:00:00+02:00</published>
            <updated>2014-08-20T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2014/08/20/adjusted-pvalues-breakpoint-regression/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2014/08/20/adjusted-pvalues-breakpoint-regression/">&lt;p&gt;Last year, I published an &lt;a href=&quot;http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0069172&quot;&gt;article&lt;/a&gt; in which I critiqued the statistical tools used to assess the hypothesis that ultimate second-language (L2) proficiency is non-linearly related to the age of onset of L2 acquisition.
Rather than using ANOVAs or correlation coefficient comparisons, I argued, breakpoint (or piecewise) regression should be used.
But unless the breakpoint is specified in advance, such models are demonstrably anti-conservative.
Here I outline a simulation-based approach for calibrating the &lt;em&gt;p&lt;/em&gt;-values of such models to take their anti-conservatism into account.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;piecewise-regression&quot;&gt;Piecewise regression&lt;/h3&gt;
&lt;p&gt;Piecewise (or breakpoint) regression is a pretty self-descriptive term:
it’s a regression model with an elbow in the function.
For instance, in the graph below, the function relating &lt;em&gt;x&lt;/em&gt; to &lt;em&gt;y&lt;/em&gt; flattens for &lt;em&gt;x&lt;/em&gt; values higher than 0.5.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-20-adjusted-pvalues-breakpoint-regression/unnamed-chunk-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;What is important here is that the analyst has to specify at which &lt;em&gt;x&lt;/em&gt; point the regression curve is allowed to change slopes – in the graph above, I had to specify the breakpoint parameter myself (see my &lt;a href=&quot;http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0069172&quot;&gt;article&lt;/a&gt; on how this can be done).&lt;/p&gt;

&lt;h3 id=&quot;the-problem-increased-type-i-error-rates&quot;&gt;The problem: increased Type-I error rates&lt;/h3&gt;

&lt;p&gt;Language researchers may be familiar with piecewise regression
thanks to Harald Baayen’s excellent &lt;a href=&quot;http://www.cambridge.org/us/academic/subjects/languages-linguistics/grammar-and-syntax/analyzing-linguistic-data-practical-introduction-statistics-using-r&quot;&gt;&lt;em&gt;Analyzing linguistic data&lt;/em&gt;&lt;/a&gt;,
in which he illustrates a method to automate the selection of the breakpoint.
Briefly, this method consists of looping through all possible breakpoints and fitting a piecewise regression model for each of them.
Then, the best-fitting model is retained.&lt;/p&gt;

&lt;p&gt;In my article on analyses in critical period research, I too adopted this procedure in order to illustrate that the data in the two studies that I scrutinised were not characterised by the predicted non-linearities.
What I may have underemphasised in that article, however, is that this breakpoint selection procedure yields a &lt;strong&gt;higher-than-nominal Type-I error rate&lt;/strong&gt; of finding a non-linearity.
In plain language, looping through several possible breakpoints increases your risk of finding non-linearities when in fact none exist.&lt;/p&gt;

&lt;p&gt;The intuition behind this is probably (hopefully) dealt with in every introductory statistics course. If you run a two-samples &lt;em&gt;t&lt;/em&gt;-test with an alpha level of 0.05, you accept a 5% risk to find a significant difference between the two groups even if the populations do not differ. If you run five &lt;em&gt;t&lt;/em&gt;-tests on unrelated data, each with an alpha level of 0.05, the risk of finding a non-existing difference is still 5% for each test considered individually – but the global risk (‘familywise Type-I error rate’) is now about 23%:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;^&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## [1] 0.2262&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Similarly, if you loop through, say, 5 possible breakpoints to establish whether a non-linearity exists using piecewise regression, your Type-I error rate goes up.
But it won’t be as high as 23% since you’re not conducting the same analysis on unrelated data.
It’d be nice if we could calibrate the &lt;em&gt;p&lt;/em&gt;-values from a piecewise regression model that suffers from this multiple comparison problem,
but I wouldn’t know how to go about it analytically.
Instead, I suggest a &lt;strong&gt;simulation-based approach&lt;/strong&gt;.
But first, let’s make the problem a bit more concrete by turning to the actual datasets.&lt;/p&gt;

&lt;h3 id=&quot;the-data&quot;&gt;The data&lt;/h3&gt;
&lt;p&gt;In my CPH article, I re-analysed two datasets from &lt;a href=&quot;http://dx.doi.org/10.1017/S0142716410000056&quot;&gt;DeKeyser et al. (2010)&lt;/a&gt;.
The specifics of these two datasets aren’t too important for our present purposes, so I’ll skip them.
The two datasets are available &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/CPH/DeKeyser2010Israel.csv&quot;&gt;here&lt;/a&gt; (Israel data) and &lt;a href=&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/CPH/DeKeyser2010NorthAmerica.csv&quot;&gt;here&lt;/a&gt; (North America data); the following plots show the relationship between the AOA (age of onset of L2 acquisition) and GJT (a measure of L2 proficiency) variables in both datasets.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-20-adjusted-pvalues-breakpoint-regression/unnamed-chunk-3.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Piecewise regressions carried out using the a priori cut-off AOA values specified by DeKeyser et al. (AOA = 18) did not yield significant improvements over straightforward linear models ( &lt;em&gt;p&lt;/em&gt; = 0.98 and 0.07 for the Israel and North America data, respectively).
In a second series of analyses, I determined the optimal breakpoints following the approach suggested by Baayen. 
For the Israel data, the optimal breakpoint was located at AOA 6 but a piecewise model still failed to yield a significant improvement over a linear model ( &lt;em&gt;p&lt;/em&gt; = 0.62). For the North America data, fitting a breakpoint at AOA 16 did yield such an improvement ( &lt;em&gt;p&lt;/em&gt; = 0.047).&lt;/p&gt;

&lt;p&gt;As I looped through several breakpoints (from AOA 5 till 19), however, these &lt;em&gt;p&lt;/em&gt;-values will be anti-conservative.&lt;/p&gt;

&lt;h3 id=&quot;computing-adjusted-p-values&quot;&gt;Computing adjusted &lt;em&gt;p&lt;/em&gt;-values&lt;/h3&gt;

&lt;p&gt;As always, a &lt;em&gt;p&lt;/em&gt;-value is supposed to express the probability of finding a significant result &lt;em&gt;if the null hypothesis were true&lt;/em&gt;.
When fitting piecewise regressions, the &lt;strong&gt;null hypothesis&lt;/strong&gt; is that the relationship between the two variables is &lt;strong&gt;linear&lt;/strong&gt;.
We don’t know precisely how a linear relationship between our two variables looks like under the null hypothesis (intercept, slope and dispersion parameters) but a reasonable starting point is to &lt;strong&gt;fit a linear model&lt;/strong&gt; to the data we have and take its parameters as the population parameters. After all, they’re our best guess. We’re then going to &lt;strong&gt;simulate new datasets&lt;/strong&gt; based on this model.&lt;/p&gt;

&lt;p&gt;By way of illustration, the following R code reads in the Israel data and uses it to create 9 linear AOA-GJT relationships with similar properties.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Read in Israel data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/CPH/DeKeyser2010Israel.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Fit linear model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GJT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Create grid for 9 plots
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;par&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mfrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;oma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# room for title
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;las&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Draw 9 plots with simulated data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plots&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;AOA&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;simulated GJT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;9 simulated datasets&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-20-adjusted-pvalues-breakpoint-regression/unnamed-chunk-4.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;As you can see, some of the simulated GJT values lie outside the range of the original GJT data. DeKeyser et al. used a test that consisted of 204 yes/no items, so values higher than 204 are impossible whereas a score of 102 corresponds to random guessing.
Our regression model doesn’t know that 102 and 204 represent the de facto limits of the GJT variable, and while we could try to use &lt;a href=&quot;http://en.wikipedia.org/wiki/Tobit_model#Variations_of_the_Tobit_model&quot;&gt;censored regression models&lt;/a&gt; to deal with that, I’m just going to tell R to set values higher than 204 to 204 and values lower than 102 to 102.
The following function, &lt;code&gt;generateBreakpointData.fnc&lt;/code&gt;, does just that and, while we’re at it, rounds off the simulated values to integers.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;straight.lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GJT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AOAvals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;generateBreakpointData.fnc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AOAvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;straight.lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;204&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;204&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;102&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;102&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next, we’re going to &lt;strong&gt;fit a piecewise model with a specified breakpoint to the simulated data&lt;/strong&gt;. Here, the breakpoint is at AOA 12.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;fitBreakpoint.fnc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;with.lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;with.lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Pr(&amp;gt;F)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deviance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;with.lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here’s the outcome of running the two commands after each other:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;http://homeweb.unifr.ch/VanhoveJ/Pub/papers/CPH/DeKeyser2010Israel.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;straight.lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GJT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AOAvals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateBreakpointData.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AOAvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fitBreakpoint.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##    pval   dev
## 1 0.575 12091&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The values that are returned are the &lt;em&gt;p&lt;/em&gt;-value of the test whether the slope is different before from after the breakpoint and the model’s deviance (i.e. lack of fit).&lt;/p&gt;

&lt;p&gt;Next, we’re going to &lt;strong&gt;loop through all possible breakpoints&lt;/strong&gt; while jotting down the &lt;em&gt;p&lt;/em&gt;-values and deviances. 
I say ‘loop’, but in R you really want to &lt;a href=&quot;http://www.noamross.net/blog/2014/4/16/vectorization-in-r--why.html&quot;&gt;vectorise&lt;/a&gt; your repeated calculations as much as possible. 
This is what the &lt;code&gt;mapply&lt;/code&gt; line below does.
The &lt;code&gt;generateFitBreakpoint.fnc&lt;/code&gt; (among other programming-related stuff, I’m terrible at naming functions) takes two arguments,
the lowest considered breakpoint value and the higher considered breakpoint value, and returns the &lt;em&gt;p&lt;/em&gt;-value associated with the optimal breakpoint model as well as the location of said breakpoint.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;generateFitBreakpoint.fnc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MinBreakpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AOAvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                      &lt;span class=&quot;n&quot;&gt;MaxBreakpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateBreakpointData.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fitBreakpoint.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinBreakpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxBreakpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;MoreArgs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Summary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinBreakpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxBreakpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;PValues&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;pval&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,]),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;Deviances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;dev&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,]))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;BestP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Summary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PValues&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;which.min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Summary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Deviances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;BestBP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Summary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;which.min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Summary&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Deviances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OptimalBP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BestBP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;OptimalP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BestP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;All that is left to do now is to repeat that process a couple of thousand times and inspect the distribution of the recorded &lt;em&gt;p&lt;/em&gt;-values.
The code below simulates 10,000 datasets based on DeKeyser et al.’s Israel data, loops through each of them to determine the individual best-fitting breakpoint models (possible breakpoints between AOA 5 and 19) and saves the associated &lt;em&gt;p&lt;/em&gt;-values.&lt;/p&gt;

&lt;p&gt;(I ran this code on a Linux terminal. It may not work on other systems, in which case you can let me know.)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Load &#39;parallel&#39; package for faster computing.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Distribute the job among a couple of CPU cores
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;makeCluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detectCores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Supply the other cores with the information necessary 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clusterExport&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dat&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;straight.lm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;AOAvals&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;s2&quot;&gt;&quot;generateBreakpointData.fnc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;s2&quot;&gt;&quot;fitBreakpoint.fnc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;s2&quot;&gt;&quot;generateFitBreakpoint.fnc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Run 10000 times
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReplicateResults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parSapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generateFitBreakpoint.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Save to disk
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReplicateResults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;breakpointsimulationIsrael.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row.names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;
&lt;p&gt;If the null hypothesis is true, &lt;em&gt;p&lt;/em&gt;-values should be distributed uniformly between 0 and 1. As the following graph shows, however, by looping through several possible breakpoints, the &lt;em&gt;p&lt;/em&gt;-value distribution is skewed towards 0.
Out of 10,000 datasets simulated under the null,
1270 produced a significant but spurious non-linearity – more than double the nominal Type-I error rate of 5%.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Set graphical parameters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;par&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mfrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;las&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Read in data (and transpose for clarity&#39;s sake)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resIsr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read.csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/home/jan/breakpointsimulationIsrael.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Draw histogram of p-values
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resIsr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lightblue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;breaks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;p value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Frequency&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Distribution of p-values under the null\n(Israel data)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-20-adjusted-pvalues-breakpoint-regression/unnamed-chunk-11.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;To calibrate the observed &lt;em&gt;p&lt;/em&gt;-value against this skewed distribution, we just look up the proportion of &lt;em&gt;p&lt;/em&gt;-values generated under the null equal to or lower than the observed &lt;em&gt;p&lt;/em&gt;-value.
I observed a &lt;em&gt;p&lt;/em&gt;-value of 0.62 after looping through breakpoints from AOA 5 till 19.
0.62 lies in the 96th quantile of the simulated &lt;em&gt;p&lt;/em&gt;-value distribution (i.e. about 96% of &lt;em&gt;p&lt;/em&gt;-values are lower than 0.62), so the calibrated &lt;em&gt;p&lt;/em&gt;-value is 0.96 rather than 0.62:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ecdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resIsr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;observed p-value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cumulative probability&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Cumulative probability of p-values under the null\n(Israel data)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.62&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lightblue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lwd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resIsr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.62&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## 
## FALSE  TRUE 
##   420  9580&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;abline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9580&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lightblue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lwd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-20-adjusted-pvalues-breakpoint-regression/unnamed-chunk-12.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;I’ll skip the code for simulating the &lt;em&gt;p&lt;/em&gt;-value distribution for the North America analyses (just read in the other dataset and go through the same steps) and get straight to the simulated distribution:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-20-adjusted-pvalues-breakpoint-regression/unnamed-chunk-13.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;For the North America data, the estimated Type-I error rate is about 10.5%, which is pretty similar to the one for the Israel data. (Not surprisingly, since the linear models for both datasets are remarkably similar.) The observed &lt;em&gt;p&lt;/em&gt;-value of 0.047 lies in the 10th quantile of the simulated distribution, so the calibrated &lt;em&gt;p&lt;/em&gt;-value is 0.10 rather than 0.047.&lt;/p&gt;

&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Looping through different breakpoints increases the Type-I error rate of piecewise regression models.&lt;br /&gt;
The observed &lt;em&gt;p&lt;/em&gt;-values can be calibrated against the distribution of &lt;em&gt;p&lt;/em&gt;-values under the simulated null.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The distribution of simulated &lt;em&gt;p&lt;/em&gt;-values will &lt;strong&gt;vary&lt;/strong&gt; from &lt;strong&gt;dataset&lt;/strong&gt; to dataset and will depend on the &lt;strong&gt;range of breakpoints considered&lt;/strong&gt; (the smaller the range, the smaller the skew). Lastly, multiple comparison problem &lt;strong&gt;doesn’t only apply when following the automatised procedure&lt;/strong&gt; suggested by Baayen: even if you look at the data first and then decide which breakpoint to fit, your &lt;em&gt;p&lt;/em&gt;-values will be off if you don’t take into account on which breakpoints you &lt;em&gt;could&lt;/em&gt; have decided had the data come out differently (see &lt;a href=&quot;http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf&quot;&gt;Gelman and Loken&lt;/a&gt; for a treatment of a more general version of this problem).&lt;/p&gt;
</content>
        </entry>
                  
        <entry>
            <title>Analysing pretest/posttest data</title>
            <link href="http://janhove.github.io/analysis/2014/08/14/pretest-posttest-ancova/" />
            <published>2014-08-14T00:00:00+02:00</published>
            <updated>2014-08-14T00:00:00+02:00</updated>
            <id>http://janhove.github.io/analysis/2014/08/14/pretest-posttest-ancova/</id>
            <content type="html" xml:base="http://janhove.github.io/analysis/2014/08/14/pretest-posttest-ancova/">&lt;p&gt;Assigning participants randomly to the control and experimental programmes and testing them before and after the programme is the gold standard for determining the efficacy of pedagogical interventions. But the analyses reported in research articles are often needlessly complicated and may be suboptimal in terms of statistical power.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;a-randomised-pretestposttest-control-group-study&quot;&gt;A randomised pretest/posttest control group study&lt;/h3&gt;
&lt;p&gt;Say you’ve developed a new method for autonomously learning to read a related foreign language and you want to establish if your method is more efficient than the one currently used.
To address this question, you design an experiment along the following lines:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You recruite 40 motivated students and randomly assign half of them to the control group (current method) and half to the experimental group (new method).&lt;/li&gt;
  &lt;li&gt;To take pre-existing differences in foreign-language reading skills into account, you administer a pretest to all participants.&lt;/li&gt;
  &lt;li&gt;Six weeks into the programme, the participants are tested again.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There you have it – a classic randomised pretest/posttest control group experiment! But how do you go about analysing the data?&lt;/p&gt;

&lt;h3 id=&quot;four-analytical-options&quot;&gt;Four analytical options&lt;/h3&gt;
&lt;p&gt;By and large, analyses of pretest/posttest experiments in the literature fall into four categories: ANOVAs on the posttest scores only, repeated-measures ANOVAs, ANOVAs on the pretest/posttest differences, and ANCOVAs.
The first two are underpowered and overcomplicated, respectively, whereas the third is subject to an assumption that is likely to be violated in real data.
The points I want to make aren’t new (see &lt;a href=&quot;http://www.jstor.org/stable/20151&quot;&gt;Hendrix et al. 1978&lt;/a&gt;; &lt;a href=&quot;http://dx.doi.org/10.1037/h0076767&quot;&gt;Huck &amp;amp; McLean, 1975&lt;/a&gt;), but it can’t hurt to reiterate them – especially since I wasn’t aware of them myself until a couple of days ago.&lt;/p&gt;

&lt;h4 id=&quot;anova-on-the-posttest-scores&quot;&gt;ANOVA on the posttest scores&lt;/h4&gt;
&lt;p&gt;One (thankfully infrequent) option is to compare the control and experimental groups by running an ANOVA or, equivalently, a t-test on the posttest scores whilst disregarding the pretest scores.
This amounts to pretending you’ve ran a posttest-only experiment and forgoes the benefits afforded by the pretest/posttest design:
Since the participants have been randomly assigned to the conditions, your estimate of the new method’s effect will be correct &lt;em&gt;on average&lt;/em&gt; 
(as they would’ve been in a posttest-only experiment).
But by not taking into account pre-existing individual differences,
the uncertainty about this estimate (i.e. its standard error) is larger than it needs to be,
resulting in a loss of statistical power, as the simulations below show.&lt;/p&gt;

&lt;p&gt;Sometimes, the pretest scores are used in a complementary ANOVA or t-test that is intended to verify whether the two groups were comparable at the start of the programme.
A discussion of such ‘randomisation checks’ or ‘balance tests’ could be the topic of another blog post; 
suffice it to say for now that such additional analyses are completely superfluous and uninformative in randomised experiments and that acting on them can &lt;a href=&quot;http://www.math.upenn.edu/~pemantle/papers/Preprints/perils.pdf&quot;&gt;invalidate&lt;/a&gt; the p-values of the main analysis.&lt;/p&gt;

&lt;h4 id=&quot;repeated-measures-anova&quot;&gt;Repeated-measures ANOVA&lt;/h4&gt;
&lt;p&gt;A far superior alternative is to take both the pretest and the posttest into account in the main analysis.
This is often accomplished by fitting a 2 (control vs experimental group) × 2 (pretest vs posttest) repeated-measures ANOVA.
This method is superior to merely using the posttest scores as every participant now serves as their own control, which reduced the error variance and hence the statistical power.&lt;/p&gt;

&lt;p&gt;As &lt;a href=&quot;http://dx.doi.org/10.1037/h0076767&quot;&gt;Huck &amp;amp; McLean (1975)&lt;/a&gt; point out, however, it is also needlessly complicated:
the RM-ANOVA table features 3 effects (main effect of condition, main effect of test as well as the interaction between condition and test), only one of which (the interaction) is relevant to the research question.
The other two terms provide either irrelevant (main effect of condition) or trivial (main effect of test) information and are bound to lead to faulty interpretations.
In short, RM-ANOVAs is likely to cause information overload for both researchers and readers.&lt;/p&gt;

&lt;h4 id=&quot;anova-on-the-gain-scores&quot;&gt;ANOVA on the gain scores&lt;/h4&gt;
&lt;p&gt;An altogether more straightforward and more reader-friendly tack is to compute gain scores by subtracting the pretest scores from the posttest scores and running a one-way ANOVA (or t-test) on them.
The p value associated with the effect of condition will be &lt;em&gt;identical&lt;/em&gt; to the one associated with the interaction term in the RM-ANOVA.
In a nutshell, RM-ANOVAs don’t offer anything relevant over and beyond an ordinary ANOVA or a simple t-test when analysing simple pretest/posttest data.&lt;/p&gt;

&lt;h4 id=&quot;were-not-there-yet-pretest-scores-as-a-covariate-ancova&quot;&gt;We’re not there yet: Pretest scores as a covariate (ANCOVA)&lt;/h4&gt;
&lt;p&gt;RM-ANOVAs or, equivalently, one-way ANOVAs on gain scores come with an assumption that I don’t think is widely appreciated – viz. that the pretest and posttest scores are linearly related with a slope equal to 1 (see &lt;a href=&quot;http://www.jstor.org/stable/20151&quot;&gt;Hendrix et al. 1978&lt;/a&gt;; &lt;a href=&quot;http://dx.doi.org/10.1037/h0076767&quot;&gt;Huck &amp;amp; McLean, 1975&lt;/a&gt;).
At least, I wasn’t aware of this assumption until a while ago!
The ‘slope = 1’ assumption is clearly violated when the pretest and posttest scores are on different scales, e.g. a 7-point scale pretest and a 100-point scale posttest.
Less obviously, the assumption can be violated by mere everyday &lt;strong&gt;measurement error&lt;/strong&gt; that results in &lt;a href=&quot;http://en.wikipedia.org/wiki/Regression_toward_the_mean&quot;&gt;&lt;strong&gt;regression to the mean&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When the construct of, say, foreign-language reading skills is operationalised by means of a necessarily imperfect test,
the test result will overestimate some participants’ true skills and underestimate others’ due to extraneous factors such as form on the day, topic of the reading test etc. – in a word: luck.
When the same participants are tested again at posttest,
participants who over- or underperformed by a wide margin at pretest aren’t likely to be as lucky or unlucky at posttest.
The result is that the slope of the linear relationship between pretest and posttest scores will tend to be less than 1, 
even if both tests are scored on the same scale.&lt;/p&gt;

&lt;p&gt;With ANCOVA (analysis of covariance), we can bring the pretest scores into the model as a covariate.
Unlike when using RM-ANOVAs or gain score ANOVAs, 
we wouldn’t have to &lt;em&gt;assume&lt;/em&gt; that the slope linking the pretest and the posttest scores was 1: we can estimate the slope from the data.
This, in principle, would make for more accurate inferences with regard to the effect of condition, but at the cost of one degree of freedom.
So how do the two methods (ANOVA and ANCOVA) compare in terms of statistical power and Type-I error rate?&lt;/p&gt;

&lt;h3 id=&quot;a-simulation&quot;&gt;A simulation&lt;/h3&gt;
&lt;p&gt;To get an idea of the Type-I error rate and statistical power associated with posttest score ANOVAs, gain score ANOVAs and ANCOVAs, I programmed a simulation of the hypothetical study described above (R code below).&lt;/p&gt;

&lt;p&gt;The participants pretest ability (the underlying construct) is programmed to be normally distributed with a to-be-specified standard deviation (&lt;code&gt;sdPretestAbility&lt;/code&gt;).
The average expected improvement due to the control method and the experimental method are specified as &lt;code&gt;ControlEffect&lt;/code&gt; and &lt;code&gt;ExperimentEffect&lt;/code&gt;, respectively.
Additionally, participants are allowed to differ in their learning progress; their learning aptitude, if you will, is normally distributed with a standard deviation set in &lt;code&gt;sdSensitivity&lt;/code&gt;.
Lastly, the pre- and posttests have independent but identically distributed measurement errors, whose standard deviation is set in &lt;code&gt;sdMeasurement&lt;/code&gt;. This means that the tests are equally accurate but that ‘being lucky’ on the pretest shouldn’t be associated with being lucky on the posttest.
(If pretest ability is distributed with a standard deviation of 2 and the standard deviation of the measurement errors is 1, the pretest scores account for 80% of the variance in pretest ability (R² = 2² / (2² + 1²) = 80%). For &lt;code&gt;sdMeasurement&lt;/code&gt; values of 0, 2 and 4, the R² values are 100%, 50% and 20%, respectively.)&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# Parameters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of participants in each condition
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sdPretestAbility&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# standard deviation of ABILITY at pretest
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ControlEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# average improvement in ABILITY for control group
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# average improvement in ABILITY for experimental group
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sdSensitivity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# standard deviation of the participants&#39; sensitivity to the treatment
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;standard&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deviation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;measurement&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;posttest&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The function &lt;code&gt;simulatePrePost.fnc()&lt;/code&gt; simulates a single experiment and conducts three analyses on it: a one-way ANOVA on the posttest scores, a one-way ANOVA on the gain scores (again, this is equivalent to running a RM-ANOVA) and an ANCOVA on the posttest scores with the pretest scores as a covariate.
The p values associated with the effect of condition in the three analyses are then returned.
&lt;code&gt;replicatePrePost.fnc()&lt;/code&gt; runs &lt;code&gt;simulatePrePost.fnc()&lt;/code&gt; a number of times (e.g. 1000 times) and returns the proportion of significant p values for each analysis type as well as some additional bits and pieces (e.g. the average slope linking pretest and posttest scores in the simulations).&lt;/p&gt;

&lt;p&gt;The parameters for the simulation were set as specified above with the exception of &lt;code&gt;ExperimentEffect&lt;/code&gt; and &lt;code&gt;sdMeasurement&lt;/code&gt;, which varied between 1 and 2.6 (as effective to more than twice as effective as the control) and 0 and 4 (no measurement error to only a very rough approximation of reading skills), respectively.
For every combination of &lt;code&gt;ExperimentEffect&lt;/code&gt; and &lt;code&gt;sdMeasurement&lt;/code&gt; I simulated 1000 datasets, which were analysed by means of posttest score ANOVA, gain score ANOVA and ANCOVA.
The results of this simulation are available &lt;a href=&quot;/datasets/simulation_PrePost.csv&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;type-i-error-rate&quot;&gt;Type-I error rate&lt;/h4&gt;
&lt;p&gt;‘Type-I error rate’ is just stats speak for ‘How often do we find a significant effect when there isn’t any?’
By tradition, we typically accept a nominal Type-I error rate of 5%, meaning that &lt;em&gt;even if&lt;/em&gt; the control and experimental treatments are equally effective, we expect to find a significant difference in our sample in about 50 out of 1000 runs.&lt;/p&gt;

&lt;p&gt;To investigate the Type-I error rate, I just consider the simulation runs for which I set &lt;code&gt;ExperimentEffect&lt;/code&gt; to the same value as &lt;code&gt;ControlEffect&lt;/code&gt; (i.e. 1).
The following graph plots the observed Type-I error rate by analysis method and measurement error.
The solid horizontal line represents the nominal 5% Type-I error rate; the dashed lines give you an idea by how much the error rate can vary due to random sampling: if the true Type-I error rate is 0.05, the points will lie between the dashed lines in 95% of cases.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-14-pretest-posttest-ancova/unnamed-chunk-2.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;All methods perform on par in terms of Type-I error rate – any differences between them don’t seem to be systematic and can likely be accounted for by sampling error.&lt;/p&gt;

&lt;h4 id=&quot;statistical-power&quot;&gt;Statistical power&lt;/h4&gt;
&lt;p&gt;‘Statistical power’ refers to your chances of finding a significant effect when the treatments do differ in efficacy.
Power increases with increasing effects and more precise measurement – a truism that is reflected in the graphs below.
As is also obvious, posttest-only ANOVAs compare poorly to analyses that take the pretest scores into consideration.
For datasets characterised by substantial measurement error, ANCOVAs outperform gain score ANOVAs fairly systematically,
but for datasets with negligible measurement error, both methods are roughly equally as good.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/2014-08-14-pretest-posttest-ancova/unnamed-chunk-3.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;
&lt;p&gt;Here’s the tl;dr summary:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Use pretest scores if available.&lt;br /&gt;
Repeated-measures ANOVA is too fancy-shmancy for a pretest/posttest design.&lt;br /&gt;
ANCOVA is (a bit) more powerful.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My intuition is that gain score ANOVAs will outperform ANCOVAs in &lt;em&gt;very small samples&lt;/em&gt; when the measurement errors are negligible (due to the loss of one degree of freedom that goes into estimating the slope parameter).
That said, one advantage of ANCOVAs that we haven’t looked at is that they don’t require that the pre- and posttests be measured on the same scale.
Additionally, they can account for non-linear relationships between pretest and posttest scores by adding higher-order terms.
But that’ll be for another time.&lt;/p&gt;

&lt;h3 id=&quot;simulation-code&quot;&gt;Simulation code&lt;/h3&gt;

&lt;p&gt;To run these simulations yourself or extend them, you can use the following &lt;a href=&quot;http://r-project.org/&quot;&gt;R&lt;/a&gt; code:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;simulatePrePost.fnc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;sdPretestAbility&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;ControlEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;sdSensitivity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Simulate pretest ability
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;PretestAbility&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdPretestAbility&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Control and experiment effects
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;InterventionEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ControlEffect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# control group
&lt;/span&gt;                          &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# intervention group 
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Individual sensitivity to the effects
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;InterventionSensitivity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdSensitivity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Add group labels
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Control&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;rep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Intervention&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  
  &lt;span class=&quot;c1&quot;&gt;# Pretest scores (with measurement error)
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Pretest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PretestAbility&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Posttest scores: pretest ability + effect * sensitivity + measurement error
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Posttest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PretestAbility&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InterventionEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InterventionSensitivity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# p-value ANOVA on posttests
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;pANOVAPost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Posttest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Pr(&amp;gt;F)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# p-value ANOVA on gain scores
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;pANOVAGain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Posttest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pretest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Pr(&amp;gt;F)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# p-value ANCOVA
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;pANCOVA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;anova&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Posttest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pretest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Pr(&amp;gt;F)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# slope between pretest and posttest
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;slope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Posttest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pretest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Pretest&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# spit it all out
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pANOVAPost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pANOVAPost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;pANOVAGain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pANOVAGain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;pANCOVA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pANCOVA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;slope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;replicatePrePost.fnc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;sdPretestAbility&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;ControlEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;sdSensitivity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# run simulatePrePost.fnc() n times
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;simulatePrePost.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;sdPretestAbility&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;ControlEffect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;sdSensitivity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# Compute proportion of significant results and average slope
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;sigANOVAPost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;sigANOVAGain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;sigANCOVA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;meanSlope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,]))&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# Spit it all out
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigANOVAPost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigANOVAPost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;sigANOVAGain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigANOVAGain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;sigANCOVA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigANCOVA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;Effect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ControlEffect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;meanSlope&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;meanSlope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# This tabulates all relevant combinations of sdMeasurement and ExperimentEffect
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expand.grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load parallel package to speed up computations
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Run replicatePrePost.fnc for every combination of sdMeasurement and ExperimentEffect contained in &#39;grid&#39;
# I&#39;m not sure whether this works on Mac or Windows; perhaps use mapply instead of mcmapply.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mcmapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replicatePrePost.fnc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sdMeasurement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExperimentEffect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;c1&quot;&gt;# set fixed parameters
&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;MoreArgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;ControlEffect&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;sdPretestAbility&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;sdSensitivity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
       &lt;span class=&quot;c1&quot;&gt;# distribute work over CPU cores
&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;mc.cores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detectCores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Output results (transposed for clarity)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simulatedResults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
        </entry>
          
    </feed>
