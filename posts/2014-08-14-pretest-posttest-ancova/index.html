<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jan Vanhove">
<meta name="dcterms.date" content="2014-08-14">

<title>Jan Vanhove :: Blog - Analysing pretest/posttest data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jan Vanhove :: Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../archive.html" rel="" target="">
 <span class="menu-text">Blog archive</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resources.html" rel="" target="">
 <span class="menu-text">Teaching resources</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publications.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../archive.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#a-randomised-pretestposttest-control-group-study" id="toc-a-randomised-pretestposttest-control-group-study" class="nav-link active" data-scroll-target="#a-randomised-pretestposttest-control-group-study">A randomised pretest/posttest control group study</a></li>
  <li><a href="#four-analytical-options" id="toc-four-analytical-options" class="nav-link" data-scroll-target="#four-analytical-options">Four analytical options</a>
  <ul class="collapse">
  <li><a href="#anova-on-the-posttest-scores" id="toc-anova-on-the-posttest-scores" class="nav-link" data-scroll-target="#anova-on-the-posttest-scores">ANOVA on the posttest scores</a></li>
  <li><a href="#repeated-measures-anova" id="toc-repeated-measures-anova" class="nav-link" data-scroll-target="#repeated-measures-anova">Repeated-measures ANOVA</a></li>
  <li><a href="#anova-on-the-gain-scores" id="toc-anova-on-the-gain-scores" class="nav-link" data-scroll-target="#anova-on-the-gain-scores">ANOVA on the gain scores</a></li>
  <li><a href="#were-not-there-yet-pretest-scores-as-a-covariate-ancova" id="toc-were-not-there-yet-pretest-scores-as-a-covariate-ancova" class="nav-link" data-scroll-target="#were-not-there-yet-pretest-scores-as-a-covariate-ancova">We’re not there yet: Pretest scores as a covariate (ANCOVA)</a></li>
  </ul></li>
  <li><a href="#a-simulation" id="toc-a-simulation" class="nav-link" data-scroll-target="#a-simulation">A simulation</a>
  <ul class="collapse">
  <li><a href="#type-i-error-rate" id="toc-type-i-error-rate" class="nav-link" data-scroll-target="#type-i-error-rate">Type-I error rate</a></li>
  <li><a href="#statistical-power" id="toc-statistical-power" class="nav-link" data-scroll-target="#statistical-power">Statistical power</a></li>
  </ul></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions">Conclusions</a></li>
  <li><a href="#simulation-code" id="toc-simulation-code" class="nav-link" data-scroll-target="#simulation-code">Simulation code</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Analysing pretest/posttest data</h1>
  <div class="quarto-categories">
    <div class="quarto-category">significance</div>
    <div class="quarto-category">power</div>
    <div class="quarto-category">simplicity</div>
    <div class="quarto-category">R</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jan Vanhove </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 14, 2014</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Assigning participants randomly to the control and experimental programmes and testing them before and after the programme is the gold standard for determining the efficacy of pedagogical interventions. But the analyses reported in research articles are often needlessly complicated and may be suboptimal in terms of statistical power.</p>
<section id="a-randomised-pretestposttest-control-group-study" class="level2">
<h2 class="anchored" data-anchor-id="a-randomised-pretestposttest-control-group-study">A randomised pretest/posttest control group study</h2>
<p>Say you’ve developed a new method for autonomously learning to read a related foreign language and you want to establish if your method is more efficient than the one currently used. To address this question, you design an experiment along the following lines:</p>
<ul>
<li>You recruite 40 motivated students and randomly assign half of them to the control group (current method) and half to the experimental group (new method).</li>
<li>To take pre-existing differences in foreign-language reading skills into account, you administer a pretest to all participants.</li>
<li>Six weeks into the programme, the participants are tested again.</li>
</ul>
<p>There you have it – a classic randomised pretest/posttest control group experiment! But how do you go about analysing the data?</p>
</section>
<section id="four-analytical-options" class="level2">
<h2 class="anchored" data-anchor-id="four-analytical-options">Four analytical options</h2>
<p>By and large, analyses of pretest/posttest experiments in the literature fall into four categories: ANOVAs on the posttest scores only, repeated-measures ANOVAs, ANOVAs on the pretest/posttest differences, and ANCOVAs. The first two are underpowered and overcomplicated, respectively, whereas the third is subject to an assumption that is likely to be violated in real data. The points I want to make aren’t new (see <a href="http://www.jstor.org/stable/20151">Hendrix et al.&nbsp;1978</a>; <a href="http://dx.doi.org/10.1037/h0076767">Huck &amp; McLean, 1975</a>), but it can’t hurt to reiterate them – especially since I wasn’t aware of them myself until a couple of days ago.</p>
<section id="anova-on-the-posttest-scores" class="level3">
<h3 class="anchored" data-anchor-id="anova-on-the-posttest-scores">ANOVA on the posttest scores</h3>
<p>One (thankfully infrequent) option is to compare the control and experimental groups by running an ANOVA or, equivalently, a t-test on the posttest scores whilst disregarding the pretest scores. This amounts to pretending you’ve ran a posttest-only experiment and forgoes the benefits afforded by the pretest/posttest design: Since the participants have been randomly assigned to the conditions, your estimate of the new method’s effect will be correct <em>on average</em> (as they would’ve been in a posttest-only experiment). But by not taking into account pre-existing individual differences, the uncertainty about this estimate (i.e.&nbsp;its standard error) is larger than it needs to be, resulting in a loss of statistical power, as the simulations below show.</p>
<p>Sometimes, the pretest scores are used in a complementary ANOVA or t-test that is intended to verify whether the two groups were comparable at the start of the programme. A discussion of such ‘randomisation checks’ or ‘balance tests’ could be the topic of another blog post; suffice it to say for now that such additional analyses are completely superfluous and uninformative in randomised experiments and that acting on them can <a href="http://www.math.upenn.edu/~pemantle/papers/Preprints/perils.pdf">invalidate</a> the p-values of the main analysis.</p>
</section>
<section id="repeated-measures-anova" class="level3">
<h3 class="anchored" data-anchor-id="repeated-measures-anova">Repeated-measures ANOVA</h3>
<p>A far superior alternative is to take both the pretest and the posttest into account in the main analysis. This is often accomplished by fitting a 2 (control vs experimental group) × 2 (pretest vs posttest) repeated-measures ANOVA. This method is superior to merely using the posttest scores as every participant now serves as their own control, which reduced the error variance and hence the statistical power.</p>
<p>As <a href="http://dx.doi.org/10.1037/h0076767">Huck &amp; McLean (1975)</a> point out, however, it is also needlessly complicated: the RM-ANOVA table features 3 effects (main effect of condition, main effect of test as well as the interaction between condition and test), only one of which (the interaction) is relevant to the research question. The other two terms provide either irrelevant (main effect of condition) or trivial (main effect of test) information and are bound to lead to faulty interpretations. In short, RM-ANOVAs is likely to cause information overload for both researchers and readers.</p>
</section>
<section id="anova-on-the-gain-scores" class="level3">
<h3 class="anchored" data-anchor-id="anova-on-the-gain-scores">ANOVA on the gain scores</h3>
<p>An altogether more straightforward and more reader-friendly tack is to compute gain scores by subtracting the pretest scores from the posttest scores and running a one-way ANOVA (or t-test) on them. The p value associated with the effect of condition will be <em>identical</em> to the one associated with the interaction term in the RM-ANOVA. In a nutshell, RM-ANOVAs don’t offer anything relevant over and beyond an ordinary ANOVA or a simple t-test when analysing simple pretest/posttest data.</p>
</section>
<section id="were-not-there-yet-pretest-scores-as-a-covariate-ancova" class="level3">
<h3 class="anchored" data-anchor-id="were-not-there-yet-pretest-scores-as-a-covariate-ancova">We’re not there yet: Pretest scores as a covariate (ANCOVA)</h3>
<p>RM-ANOVAs or, equivalently, one-way ANOVAs on gain scores come with an assumption that I don’t think is widely appreciated – viz.&nbsp;that the pretest and posttest scores are linearly related with a slope equal to 1 (see <a href="http://www.jstor.org/stable/20151">Hendrix et al.&nbsp;1978</a>; <a href="http://dx.doi.org/10.1037/h0076767">Huck &amp; McLean, 1975</a>). At least, I wasn’t aware of this assumption until a while ago! The ‘slope = 1’ assumption is clearly violated when the pretest and posttest scores are on different scales, e.g.&nbsp;a 7-point scale pretest and a 100-point scale posttest. Less obviously, the assumption can be violated by mere everyday <strong>measurement error</strong> that results in <a href="http://en.wikipedia.org/wiki/Regression_toward_the_mean"><strong>regression to the mean</strong></a>.</p>
<p>When the construct of, say, foreign-language reading skills is operationalised by means of a necessarily imperfect test, the test result will overestimate some participants’ true skills and underestimate others’ due to extraneous factors such as form on the day, topic of the reading test etc. – in a word: luck. When the same participants are tested again at posttest, participants who over- or underperformed by a wide margin at pretest aren’t likely to be as lucky or unlucky at posttest. The result is that the slope of the linear relationship between pretest and posttest scores will tend to be less than 1, even if both tests are scored on the same scale.</p>
<p>With ANCOVA (analysis of covariance), we can bring the pretest scores into the model as a covariate. Unlike when using RM-ANOVAs or gain score ANOVAs, we wouldn’t have to <em>assume</em> that the slope linking the pretest and the posttest scores was 1: we can estimate the slope from the data. This, in principle, would make for more accurate inferences with regard to the effect of condition, but at the cost of one degree of freedom. So how do the two methods (ANOVA and ANCOVA) compare in terms of statistical power and Type-I error rate?</p>
</section>
</section>
<section id="a-simulation" class="level2">
<h2 class="anchored" data-anchor-id="a-simulation">A simulation</h2>
<p>To get an idea of the Type-I error rate and statistical power associated with posttest score ANOVAs, gain score ANOVAs and ANCOVAs, I programmed a simulation of the hypothetical study described above (R code below).</p>
<p>The participants pretest ability (the underlying construct) is programmed to be normally distributed with a to-be-specified standard deviation (<code>sdPretestAbility</code>). The average expected improvement due to the control method and the experimental method are specified as <code>ControlEffect</code> and <code>ExperimentEffect</code>, respectively. Additionally, participants are allowed to differ in their learning progress; their learning aptitude, if you will, is normally distributed with a standard deviation set in <code>sdSensitivity</code>. Lastly, the pre- and posttests have independent but identically distributed measurement errors, whose standard deviation is set in <code>sdMeasurement</code>. This means that the tests are equally accurate but that ‘being lucky’ on the pretest shouldn’t be associated with being lucky on the posttest. (If pretest ability is distributed with a standard deviation of 2 and the standard deviation of the measurement errors is 1, the pretest scores account for 80% of the variance in pretest ability (R² = 2² / (2² + 1²) = 80%). For <code>sdMeasurement</code> values of 0, 2 and 4, the R² values are 100%, 50% and 20%, respectively.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">20</span> <span class="co"># number of participants in each condition</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>sdPretestAbility <span class="ot">=</span> <span class="dv">2</span> <span class="co"># standard deviation of ABILITY at pretest</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>ControlEffect <span class="ot">=</span> <span class="dv">1</span> <span class="co"># average improvement in ABILITY for control group</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>ExperimentEffect <span class="ot">=</span> <span class="dv">1</span> <span class="co"># average improvement in ABILITY for experimental group</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>sdSensitivity <span class="ot">=</span> <span class="fl">0.5</span> <span class="co"># standard deviation of the participants' sensitivity to the treatment</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>sdMeasurement <span class="ot">=</span> <span class="dv">0</span> <span class="co"># standard deviation of measurement error at pre- and posttest</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The function <code>simulatePrePost.fnc()</code> simulates a single experiment and conducts three analyses on it: a one-way ANOVA on the posttest scores, a one-way ANOVA on the gain scores (again, this is equivalent to running a RM-ANOVA) and an ANCOVA on the posttest scores with the pretest scores as a covariate. The p values associated with the effect of condition in the three analyses are then returned. <code>replicatePrePost.fnc()</code> runs <code>simulatePrePost.fnc()</code> a number of times (e.g.&nbsp;1000 times) and returns the proportion of significant p values for each analysis type as well as some additional bits and pieces (e.g.&nbsp;the average slope linking pretest and posttest scores in the simulations).</p>
<p>The parameters for the simulation were set as specified above with the exception of <code>ExperimentEffect</code> and <code>sdMeasurement</code>, which varied between 1 and 2.6 (as effective to more than twice as effective as the control) and 0 and 4 (no measurement error to only a very rough approximation of reading skills), respectively. For every combination of <code>ExperimentEffect</code> and <code>sdMeasurement</code> I simulated 1000 datasets, which were analysed by means of posttest score ANOVA, gain score ANOVA and ANCOVA. The results of this simulation are available <a href="../../datasets/simulation_PrePost.csv">here</a>.</p>
<section id="type-i-error-rate" class="level3">
<h3 class="anchored" data-anchor-id="type-i-error-rate">Type-I error rate</h3>
<p>‘Type-I error rate’ is just stats speak for ‘How often do we find a significant effect when there isn’t any?’ By tradition, we typically accept a nominal Type-I error rate of 5%, meaning that <em>even if</em> the control and experimental treatments are equally effective, we expect to find a significant difference in our sample in about 50 out of 1000 runs.</p>
<p>To investigate the Type-I error rate, I just consider the simulation runs for which I set <code>ExperimentEffect</code> to the same value as <code>ControlEffect</code> (i.e.&nbsp;1). The following graph plots the observed Type-I error rate by analysis method and measurement error. The solid horizontal line represents the nominal 5% Type-I error rate; the dashed lines give you an idea by how much the error rate can vary due to random sampling: if the true Type-I error rate is 0.05, the points will lie between the dashed lines in 95% of cases.</p>
<p><img src="../../figs/2014-08-14-pretest-posttest-ancova/unnamed-chunk-2.png" class="img-fluid"></p>
<p>All methods perform on par in terms of Type-I error rate – any differences between them don’t seem to be systematic and can likely be accounted for by sampling error.</p>
</section>
<section id="statistical-power" class="level3">
<h3 class="anchored" data-anchor-id="statistical-power">Statistical power</h3>
<p>‘Statistical power’ refers to your chances of finding a significant effect when the treatments do differ in efficacy. Power increases with increasing effects and more precise measurement – a truism that is reflected in the graphs below. As is also obvious, posttest-only ANOVAs compare poorly to analyses that take the pretest scores into consideration. For datasets characterised by substantial measurement error, ANCOVAs outperform gain score ANOVAs fairly systematically, but for datasets with negligible measurement error, both methods are roughly equally as good.</p>
<p><img src="../../figs/2014-08-14-pretest-posttest-ancova/unnamed-chunk-3.png" class="img-fluid"></p>
</section>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>Here’s the tl;dr summary:</p>
<blockquote class="blockquote">
<p>Use pretest scores if available.<br>
Repeated-measures ANOVA is too fancy-shmancy for a pretest/posttest design.<br>
ANCOVA is (a bit) more powerful.</p>
</blockquote>
<p>My intuition is that gain score ANOVAs will outperform ANCOVAs in <em>very small samples</em> when the measurement errors are negligible (due to the loss of one degree of freedom that goes into estimating the slope parameter). That said, one advantage of ANCOVAs that we haven’t looked at is that they don’t require that the pre- and posttests be measured on the same scale. Additionally, they can account for non-linear relationships between pretest and posttest scores by adding higher-order terms. But that’ll be for another time.</p>
</section>
<section id="simulation-code" class="level2">
<h2 class="anchored" data-anchor-id="simulation-code">Simulation code</h2>
<p>To run these simulations yourself or extend them, you can use the following <a href="http://r-project.org/">R</a> code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>simulatePrePost.fnc <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">n =</span> <span class="dv">20</span>,</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>                                <span class="at">sdPretestAbility =</span> <span class="dv">3</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                                <span class="at">ExperimentEffect =</span> <span class="dv">2</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                                <span class="at">ControlEffect =</span> <span class="dv">2</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                                <span class="at">sdSensitivity =</span> <span class="dv">1</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                                <span class="at">sdMeasurement =</span> <span class="dv">1</span>) {</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Simulate pretest ability</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  PretestAbility <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n<span class="sc">*</span><span class="dv">2</span>, <span class="dv">10</span>, sdPretestAbility)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Control and experiment effects</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  InterventionEffect <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(ControlEffect, n), <span class="co"># control group</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                          <span class="fu">rep</span>(ExperimentEffect, n)) <span class="co"># intervention group </span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Individual sensitivity to the effects</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  InterventionSensitivity <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n<span class="sc">*</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="at">sd =</span> sdSensitivity)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add group labels</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  Group <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Control"</span>, n),</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>             <span class="fu">rep</span>(<span class="st">"Intervention"</span>, n))  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Pretest scores (with measurement error)</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  Pretest <span class="ot">&lt;-</span> PretestAbility <span class="sc">+</span> <span class="fu">rnorm</span>(n<span class="sc">*</span><span class="dv">2</span>, <span class="dv">0</span>, sdMeasurement)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Posttest scores: pretest ability + effect * sensitivity + measurement error</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  Posttest <span class="ot">&lt;-</span> PretestAbility <span class="sc">+</span> InterventionEffect <span class="sc">*</span> InterventionSensitivity <span class="sc">+</span> <span class="fu">rnorm</span>(n<span class="sc">*</span><span class="dv">2</span>, <span class="dv">0</span>, sdMeasurement)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># p-value ANOVA on posttests</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  pANOVAPost <span class="ot">=</span> <span class="fu">anova</span>(<span class="fu">lm</span>(Posttest <span class="sc">~</span> Group))<span class="sc">$</span><span class="st">'Pr(&gt;F)'</span>[[<span class="dv">1</span>]]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># p-value ANOVA on gain scores</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>  pANOVAGain <span class="ot">=</span> <span class="fu">anova</span>(<span class="fu">lm</span>(<span class="fu">I</span>(Posttest<span class="sc">-</span>Pretest) <span class="sc">~</span> Group))<span class="sc">$</span><span class="st">'Pr(&gt;F)'</span>[[<span class="dv">1</span>]]</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># p-value ANCOVA</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  pANCOVA <span class="ot">=</span>  <span class="fu">anova</span>(<span class="fu">lm</span>(Posttest <span class="sc">~</span> Pretest <span class="sc">+</span> Group))<span class="sc">$</span><span class="st">'Pr(&gt;F)'</span>[[<span class="dv">2</span>]]</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># slope between pretest and posttest</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  slope <span class="ot">=</span> <span class="fu">coef</span>(<span class="fu">lm</span>(Posttest <span class="sc">~</span> Pretest <span class="sc">+</span> Group))[<span class="st">'Pretest'</span>]</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># spit it all out</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">pANOVAPost =</span> pANOVAPost,</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>              <span class="at">pANOVAGain =</span> pANOVAGain,</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>              <span class="at">pANCOVA =</span> pANCOVA,</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>              slope))</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>replicatePrePost.fnc <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">runs =</span> <span class="dv">1000</span>,</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">n =</span> <span class="dv">200</span>,</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">sdPretestAbility =</span> <span class="dv">3</span>,</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">ExperimentEffect =</span> <span class="dv">3</span>,</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">ControlEffect =</span> <span class="dv">2</span>,</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">sdSensitivity =</span> <span class="dv">1</span>,</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">sdMeasurement =</span> <span class="dv">1</span>) {</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>  <span class="co"># run simulatePrePost.fnc() n times</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>  sims <span class="ot">&lt;-</span> <span class="fu">replicate</span>(runs, <span class="fu">simulatePrePost.fnc</span>(n,</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>                                              sdPretestAbility,</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>                                              ExperimentEffect,</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>                                              ControlEffect,</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>                                              sdSensitivity,</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>                                              sdMeasurement))</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute proportion of significant results and average slope</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>  sigANOVAPost <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">unlist</span>(sims[<span class="dv">1</span>,])<span class="sc">&lt;=</span><span class="fl">0.05</span>)</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>  sigANOVAGain <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">unlist</span>(sims[<span class="dv">2</span>,])<span class="sc">&lt;=</span><span class="fl">0.05</span>)</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>  sigANCOVA <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">unlist</span>(sims[<span class="dv">3</span>,])<span class="sc">&lt;=</span><span class="fl">0.05</span>)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>  meanSlope <span class="ot">=</span> <span class="fu">mean</span>(<span class="fu">unlist</span>(sims[<span class="dv">4</span>,]))</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Spit it all out</span></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">sigANOVAPost =</span> sigANOVAPost,</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>              <span class="at">sigANOVAGain =</span> sigANOVAGain,</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>              <span class="at">sigANCOVA =</span> sigANCOVA,</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>              <span class="at">sdMeasurement =</span> sdMeasurement,</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>              <span class="at">Effect =</span> ExperimentEffect <span class="sc">-</span> ControlEffect,</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>              <span class="at">meanSlope =</span> meanSlope))</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a><span class="co"># This tabulates all relevant combinations of sdMeasurement and ExperimentEffect</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">sdMeasurement =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="fl">0.5</span>),</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ExperimentEffect =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="fl">2.6</span>, <span class="fl">0.2</span>))</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Load parallel package to speed up computations</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Run replicatePrePost.fnc for every combination of sdMeasurement and ExperimentEffect contained in 'grid'</span></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a><span class="co"># I'm not sure whether this works on Mac or Windows; perhaps use mapply instead of mcmapply.</span></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>simulatedResults <span class="ot">&lt;-</span> <span class="fu">mcmapply</span>(replicatePrePost.fnc,</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>       <span class="at">sdMeasurement =</span> grid<span class="sc">$</span>sdMeasurement,</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>       <span class="at">ExperimentEffect =</span> grid<span class="sc">$</span>ExperimentEffect,</span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>       <span class="co"># set fixed parameters</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>       <span class="at">MoreArgs =</span> <span class="fu">list</span>(<span class="at">runs =</span> <span class="dv">1000</span>,</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>                       <span class="at">ControlEffect =</span> <span class="dv">1</span>,</span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>                       <span class="at">sdPretestAbility =</span> <span class="dv">2</span>,</span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>                       <span class="at">sdSensitivity =</span> <span class="fl">0.5</span>,</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>                       <span class="at">n =</span> <span class="dv">20</span>),</span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>       <span class="co"># distribute work over CPU cores</span></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>       <span class="at">mc.cores =</span> <span class="fu">detectCores</span>())</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Output results (transposed for clarity)</span></span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>simulatedResults <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">t</span>(simulatedResults))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>